{"file_contents":{"main.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nUltra High-Performance Telegram Video Downloader Bot\nMain entry point for the application\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nimport sys\nfrom pathlib import Path\n\n# Add project root to Python path\nproject_root = Path(__file__).parent\nsys.path.insert(0, str(project_root))\n\nfrom config.settings import Settings\nfrom core.bot import VideoDownloaderBot\nfrom database.connection import DatabaseManager\nfrom services.cache_manager import CacheManager\nfrom utils.helpers import setup_logging, cleanup_temp_files\n\n# Configure logging\nsetup_logging()\nlogger = logging.getLogger(__name__)\n\nasync def startup_checks():\n    \"\"\"Perform startup checks and initialization\"\"\"\n    logger.info(\"üöÄ Starting Ultra High-Performance Video Downloader Bot\")\n    \n    # Verify environment variables\n    settings = Settings()\n    if not settings.validate():\n        logger.error(\"‚ùå Configuration validation failed\")\n        sys.exit(1)\n    \n    # Create necessary directories\n    os.makedirs(\"temp\", exist_ok=True)\n    os.makedirs(\"logs\", exist_ok=True)\n    \n    # Clean up any leftover temporary files\n    await cleanup_temp_files()\n    \n    logger.info(\"‚úÖ Startup checks completed successfully\")\n\nasync def shutdown_cleanup():\n    \"\"\"Cleanup resources on shutdown\"\"\"\n    logger.info(\"üõë Shutting down bot...\")\n    \n    # Cleanup temporary files\n    await cleanup_temp_files()\n    \n    # Close database connections\n    db_manager = DatabaseManager()\n    await db_manager.close_all_connections()\n    \n    # Close cache connections\n    cache_manager = CacheManager()\n    await cache_manager.close()\n    \n    logger.info(\"‚úÖ Shutdown cleanup completed\")\n\nasync def main():\n    \"\"\"Main application entry point\"\"\"\n    try:\n        # Startup initialization\n        await startup_checks()\n        \n        # Initialize and start the bot\n        bot = VideoDownloaderBot()\n        await bot.initialize()\n        \n        # Start the bot\n        logger.info(\"ü§ñ Bot is now running...\")\n        await bot.start()\n        \n    except KeyboardInterrupt:\n        logger.info(\"üì± Received keyboard interrupt\")\n    except Exception as e:\n        logger.error(f\"‚ùå Fatal error: {e}\", exc_info=True)\n        sys.exit(1)\n    finally:\n        await shutdown_cleanup()\n\nif __name__ == \"__main__\":\n    # Check if event loop is already running (Replit environment)\n    try:\n        loop = asyncio.get_running_loop()\n        logger.info(\"üîÑ Using existing event loop\")\n        # Schedule the main coroutine\n        asyncio.create_task(main())\n    except RuntimeError:\n        # No running loop, create new one\n        logger.info(\"üîÑ Creating new event loop\")\n        asyncio.run(main())\n","size_bytes":2696},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"aiohttp>=3.12.15\",\n    \"asyncpg>=0.30.0\",\n    \"loguru>=0.7.3\",\n    \"pillow>=11.3.0\",\n    \"psutil>=7.0.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"python-magic>=0.4.27\",\n    \"python-telegram-bot>=22.3\",\n    \"redis>=6.4.0\",\n    \"requests>=2.32.5\",\n    \"sqlalchemy>=2.0.43\",\n    \"telethon>=1.40.0\",\n    \"uvloop>=0.21.0\",\n    \"yt-dlp>=2025.8.22\",\n]\n","size_bytes":488},"replit.md":{"content":"# Ultra High-Performance Telegram Video Downloader Bot\n\n## Overview\n\nThis is an ultra high-performance Telegram bot designed for downloading videos from 1500+ platforms including YouTube, TikTok, Instagram, Facebook, and Twitter. The bot is built with Python using python-telegram-bot and Telethon for handling large file uploads (up to 2GB), and leverages yt-dlp for video extraction. The architecture prioritizes performance, scalability, and reliability with features like concurrent downloads/uploads, intelligent caching, real-time progress tracking, and comprehensive rate limiting.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Core Architecture Pattern\n- **Modular Service Architecture**: The application follows a clean separation of concerns with distinct modules for bot handling, video downloading, file management, database operations, and caching\n- **Async/Await Concurrency**: Built entirely on asyncio for high-performance concurrent operations with semaphore-controlled resource management\n- **Dual Telegram Client Strategy**: Uses both python-telegram-bot for user interactions and Telethon for high-performance file operations and 2GB file support\n\n### Bot Framework Integration\n- **python-telegram-bot**: Primary framework for handling user interactions, commands, and callback queries\n- **Telethon**: Secondary client specifically for file uploads, leveraging MTProto for faster transfers and larger file support\n- **Handler-based Routing**: Organized into command handlers, callback handlers, and message handlers for clean request processing\n\n### Video Processing Pipeline\n- **yt-dlp Integration**: Uses yt-dlp as the core video extraction engine supporting 1500+ platforms\n- **Format Selection**: Intelligent format detection and user-selectable quality options\n- **Concurrent Downloads**: Semaphore-controlled concurrent downloads with configurable limits\n- **Progress Tracking**: Real-time download and upload progress with Redis-based state management\n\n### Database Design\n- **PostgreSQL with SQLAlchemy**: Uses async SQLAlchemy with connection pooling for optimal database performance\n- **User Management**: Tracks users, download history, analytics, and user preferences\n- **Statistics Tracking**: Comprehensive system statistics, user analytics, and error logging\n- **Connection Pooling**: Optimized connection pool settings for high-throughput operations\n\n### Caching Strategy\n- **Redis Cache Manager**: High-performance Redis caching for video metadata, user sessions, and temporary data\n- **Intelligent Cache Keys**: Strategic caching of video information to reduce API calls and improve response times\n- **TTL Management**: Automatic cache expiration and cleanup for optimal memory usage\n\n### File Management System\n- **Temporary File Handling**: Secure temporary file management with automatic cleanup\n- **Upload Optimization**: Chunked uploads with progress tracking and error recovery\n- **File Size Management**: Support for files up to 2GB using Telethon's large file capabilities\n- **Format Processing**: Automatic file format detection and optimization\n\n### Security and Access Control\n- **Chat-based Authorization**: Restricts bot access to specific chat IDs and authorized users\n- **Rate Limiting**: Multi-level rate limiting (global, per-user, per-operation) to prevent abuse\n- **Input Validation**: Comprehensive URL validation and sanitization\n- **Error Handling**: Robust error handling with logging and user-friendly error messages\n\n### Performance Optimizations\n- **Connection Pooling**: Both database and Redis connections use optimized pooling\n- **Concurrent Processing**: Configurable semaphores for downloads, uploads, and processing operations\n- **Memory Management**: Efficient temporary file handling and automatic cleanup\n- **Fast Telethon**: Optional FastTelethon integration for enhanced upload speeds\n\n### Monitoring and Analytics\n- **Progress Tracking**: Real-time progress updates stored in Redis for fast access\n- **System Statistics**: Comprehensive tracking of downloads, success rates, and system performance\n- **User Analytics**: Per-user statistics and usage patterns\n- **Error Logging**: Detailed error tracking and logging for debugging and monitoring\n\n## External Dependencies\n\n### Core Dependencies\n- **python-telegram-bot**: Primary Telegram bot framework for user interactions\n- **Telethon**: Secondary Telegram client for file operations and large file support\n- **yt-dlp**: Video extraction engine supporting 1500+ platforms\n- **asyncio**: Python's built-in asynchronous programming framework\n\n### Database and Caching\n- **PostgreSQL**: Primary database for persistent data storage with asyncpg driver\n- **Redis**: High-performance caching and session management\n- **SQLAlchemy**: ORM with async support for database operations\n- **aioredis**: Async Redis client for optimal performance\n\n### Utilities and Support\n- **psutil**: System monitoring and resource tracking\n- **pathlib**: Modern file path handling\n- **mimetypes**: File type detection and validation\n- **hashlib**: File integrity verification and caching keys\n\n### Development and Deployment\n- **logging**: Comprehensive logging throughout the application\n- **dataclasses**: Type-safe data structures for configuration and models\n- **typing**: Type hints for better code maintainability\n- **json**: Data serialization for caching and API responses\n\n### Platform-Specific Integrations\n- **YouTube API**: Enhanced metadata extraction (optional)\n- **Platform-specific extractors**: Specialized handlers for different video platforms\n- **Cookie support**: For platforms requiring authentication\n- **Proxy support**: For geo-restricted content access\n\n### Performance Libraries\n- **concurrent.futures**: Thread pool execution for CPU-bound tasks\n- **multiprocessing**: Process-based parallelism for intensive operations\n- **FastTelethon**: Optional performance enhancement for Telethon uploads\n- **uvloop**: Optional event loop optimization for better performance","size_bytes":6057},"config/__init__.py":{"content":"\"\"\"Configuration module for the video downloader bot\"\"\"\n\nfrom .settings import settings, Settings\n\n__all__ = ['settings', 'Settings']\n","size_bytes":134},"config/settings.py":{"content":"\"\"\"\nConfiguration settings for the video downloader bot\nAll settings loaded from environment variables with secure defaults\n\"\"\"\n\nimport os\nimport logging\nfrom typing import List, Optional\nfrom dataclasses import dataclass, field\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass Settings:\n    \"\"\"Bot configuration settings\"\"\"\n    \n    # Telegram Bot Configuration\n    BOT_TOKEN: str = os.getenv(\"BOT_TOKEN\", \"\")\n    API_ID: int = int(os.getenv(\"API_ID\", \"0\"))\n    API_HASH: str = os.getenv(\"API_HASH\", \"\")\n    \n    # Telethon Session Configuration  \n    SESSION_STRING: str = os.getenv(\"SESSION_STRING\", \"\")\n    PHONE_NUMBER: str = os.getenv(\"PHONE_NUMBER\", \"\")\n    \n    # Group/Chat Configuration\n    ALLOWED_CHAT_IDS: List[int] = field(default_factory=lambda: [\n        int(x.strip()) for x in os.getenv(\"ALLOWED_CHAT_IDS\", \"6602517122\").split(\",\") \n        if x.strip().lstrip('-').isdigit()\n    ])\n    UPLOAD_CHAT_ID: int = int(os.getenv(\"UPLOAD_CHAT_ID\", \"6602517122\"))\n    \n    # Database Configuration\n    DATABASE_URL: str = os.getenv(\"DATABASE_URL\", \"postgresql://postgres:password@localhost:5432/video_bot\")\n    REDIS_URL: str = os.getenv(\"REDIS_URL\", \"redis://localhost:6379/0\")\n    \n    # Redis Configuration Details\n    REDIS_HOST: str = os.getenv(\"REDIS_HOST\", \"localhost\")\n    REDIS_PORT: int = int(os.getenv(\"REDIS_PORT\", \"6379\"))\n    REDIS_PASSWORD: str = os.getenv(\"REDIS_PASSWORD\", \"\")\n    REDIS_DB: int = int(os.getenv(\"REDIS_DB\", \"0\"))\n    \n    # Performance Settings\n    MAX_CONCURRENT_DOWNLOADS: int = int(os.getenv(\"MAX_CONCURRENT_DOWNLOADS\", \"5\"))\n    MAX_CONCURRENT_UPLOADS: int = int(os.getenv(\"MAX_CONCURRENT_UPLOADS\", \"5\"))  # Increased for faster throughput\n    CHUNK_SIZE: int = int(os.getenv(\"CHUNK_SIZE\", \"524288\"))  # 512KB (max allowed by Telethon)\n    MAX_FILE_SIZE: int = int(os.getenv(\"MAX_FILE_SIZE\", \"2147483648\"))  # 2GB\n    \n    # File Management\n    TEMP_DIR: str = os.getenv(\"TEMP_DIR\", \"./temp\")\n    MAX_TEMP_AGE: int = int(os.getenv(\"MAX_TEMP_AGE\", \"3600\"))  # 1 hour\n    AUTO_CLEANUP: bool = os.getenv(\"AUTO_CLEANUP\", \"true\").lower() == \"true\"\n    \n    # Speed Optimization\n    USE_FAST_TELETHON: bool = os.getenv(\"USE_FAST_TELETHON\", \"true\").lower() == \"true\"\n    BANDWIDTH_LIMIT: int = int(os.getenv(\"BANDWIDTH_LIMIT\", \"50000000\"))  # 50MB/s increased limit\n    CONNECTION_RETRIES: int = int(os.getenv(\"CONNECTION_RETRIES\", \"3\"))  # Reduced for faster failures\n    REQUEST_TIMEOUT: int = int(os.getenv(\"REQUEST_TIMEOUT\", \"900\"))  # 15 minutes optimized\n    UPLOAD_WORKERS: int = int(os.getenv(\"UPLOAD_WORKERS\", \"8\"))  # Multiple workers for parallel uploads\n    \n    # Feature Flags\n    ENABLE_ANALYTICS: bool = os.getenv(\"ENABLE_ANALYTICS\", \"true\").lower() == \"true\"\n    ENABLE_RATE_LIMITING: bool = os.getenv(\"ENABLE_RATE_LIMITING\", \"true\").lower() == \"true\"\n    ENABLE_USER_STATISTICS: bool = os.getenv(\"ENABLE_USER_STATISTICS\", \"true\").lower() == \"true\"\n    \n    # Security Settings\n    MAX_USERS_PER_MINUTE: int = int(os.getenv(\"MAX_USERS_PER_MINUTE\", \"100\"))\n    MAX_DOWNLOADS_PER_USER: int = int(os.getenv(\"MAX_DOWNLOADS_PER_USER\", \"10\"))\n    ADMIN_USER_IDS: List[int] = field(default_factory=lambda: [\n        int(x.strip()) for x in os.getenv(\"ADMIN_USER_IDS\", \"\").split(\",\") \n        if x.strip().lstrip('-').isdigit()\n    ])\n    \n    # Logging Configuration\n    LOG_LEVEL: str = os.getenv(\"LOG_LEVEL\", \"INFO\")\n    LOG_FILE: str = os.getenv(\"LOG_FILE\", \"./logs/bot.log\")\n    \n    # YT-DLP Configuration\n    YTDL_FORMAT: str = os.getenv(\"YTDL_FORMAT\", \"best\")\n    YTDL_EXTRACTORS: List[str] = field(default_factory=lambda: [\n        \"youtube\", \"facebook\", \"instagram\", \"tiktok\", \"twitter\", \n        \"generic\", \"dailymotion\", \"vimeo\", \"twitch\"\n    ])\n    \n    # API Keys for enhanced platform support\n    INSTAGRAM_ACCESS_TOKEN: str = os.getenv(\"INSTAGRAM_ACCESS_TOKEN\", \"\")\n    FACEBOOK_ACCESS_TOKEN: str = os.getenv(\"FACEBOOK_ACCESS_TOKEN\", \"\")\n    \n    # Instagram Cookies Configuration\n    INSTAGRAM_SESSIONID: str = os.getenv(\"INSTAGRAM_SESSIONID\", \"\")\n    INSTAGRAM_CSRFTOKEN: str = os.getenv(\"INSTAGRAM_CSRFTOKEN\", \"\")\n    \n    # YouTube Cookies Configuration\n    YOUTUBE_COOKIES: str = os.getenv(\"YOUTUBE_COOKIES\", \"YSC=S2HI9zX0Wec; PREF=tz=Asia.Riyadh; VISITOR_INFO1_LIVE=XokcjcRzkoQ\")\n    YOUTUBE_SESSION_TOKEN: str = os.getenv(\"YOUTUBE_SESSION_TOKEN\", \"\")\n    YOUTUBE_AUTH_TOKEN: str = os.getenv(\"YOUTUBE_AUTH_TOKEN\", \"\")\n    \n    def validate(self) -> bool:\n        \"\"\"Validate critical configuration settings\"\"\"\n        errors = []\n        \n        if not self.BOT_TOKEN:\n            errors.append(\"BOT_TOKEN is required\")\n        \n        if not self.API_ID or self.API_ID == 0:\n            errors.append(\"API_ID is required\")\n            \n        if not self.API_HASH:\n            errors.append(\"API_HASH is required\")\n            \n        if not self.ALLOWED_CHAT_IDS:\n            errors.append(\"ALLOWED_CHAT_IDS is required\")\n            \n        if not self.UPLOAD_CHAT_ID:\n            errors.append(\"UPLOAD_CHAT_ID is required\")\n        \n        if errors:\n            for error in errors:\n                logger.error(f\"Configuration error: {error}\")\n            return False\n        \n        logger.info(\"‚úÖ Configuration validation passed\")\n        return True\n    \n    def get_ytdl_opts(self) -> dict:\n        \"\"\"Get optimized yt-dlp options\"\"\"\n        return {\n            'format': 'best[height<=1080]/best',\n            'noplaylist': True,\n            'extract_flat': False,\n            'writethumbnail': False,  # Disable automatic thumbnail download to avoid confusion\n            'writeinfojson': False,   # Disable info.json to reduce clutter\n            'ignoreerrors': True,\n            'no_warnings': False,\n            'retries': 3,\n            'fragment_retries': 3,\n            'socket_timeout': 30,\n            'prefer_free_formats': True,\n            'merge_output_format': 'mp4',\n            'concurrent_fragments': 8,  # Increased for faster downloads\n            'http_chunk_size': self.CHUNK_SIZE,\n            'outtmpl': f\"{self.TEMP_DIR}/%(title)s.%(ext)s\",\n            'restrictfilenames': True,\n            'windowsfilenames': True,\n        }\n    \n    def __post_init__(self):\n        \"\"\"Post-initialization setup\"\"\"\n        # Create temp directory if it doesn't exist\n        os.makedirs(self.TEMP_DIR, exist_ok=True)\n        os.makedirs(os.path.dirname(self.LOG_FILE), exist_ok=True)\n\n# Global settings instance\nsettings = Settings()\n","size_bytes":6445},"core/__init__.py":{"content":"\"\"\"Core module for bot functionality\"\"\"\n\nfrom .bot import VideoDownloaderBot\nfrom .telethon_client import TelethonManager\n\n__all__ = ['VideoDownloaderBot', 'TelethonManager']\n","size_bytes":175},"core/bot.py":{"content":"\"\"\"\nMain bot class that orchestrates the entire video downloading system\nHandles initialization, routing, and high-level bot operations\n\"\"\"\n\nimport asyncio\nimport logging\nimport time\nfrom typing import Dict, Any, Optional\nfrom telegram import Update\nfrom telegram.ext import (\n    Application, CommandHandler, MessageHandler, CallbackQueryHandler,\n    filters, ContextTypes\n)\n\nfrom config.settings import settings\nfrom core.telethon_client import TelethonManager\nfrom database.connection import DatabaseManager\nfrom services.cache_manager import CacheManager\nfrom services.downloader import VideoDownloader\nfrom services.file_manager import FileManager\nfrom services.progress_tracker import ProgressTracker\nfrom handlers.commands import CommandHandlers\nfrom handlers.callbacks import CallbackHandlers\nfrom handlers.messages import MessageHandlers\nfrom middlewares.auth import AuthMiddleware\nfrom middlewares.rate_limit import RateLimitMiddleware\nfrom utils.helpers import create_error_message\n\nlogger = logging.getLogger(__name__)\n\nclass VideoDownloaderBot:\n    \"\"\"Ultra high-performance video downloader bot\"\"\"\n    \n    def __init__(self):\n        self.application: Optional[Application] = None\n        self.telethon_manager: Optional[TelethonManager] = None\n        self.db_manager: Optional[DatabaseManager] = None\n        self.cache_manager: Optional[CacheManager] = None\n        self.downloader: Optional[VideoDownloader] = None\n        self.file_manager: Optional[FileManager] = None\n        self.progress_tracker: Optional[ProgressTracker] = None\n        \n        # Handler instances\n        self.command_handlers: Optional[CommandHandlers] = None\n        self.callback_handlers: Optional[CallbackHandlers] = None\n        self.message_handlers: Optional[MessageHandlers] = None\n        \n        # Middleware\n        self.auth_middleware: Optional[AuthMiddleware] = None\n        self.rate_limit_middleware: Optional[RateLimitMiddleware] = None\n        \n        # Performance tracking\n        self.active_downloads: Dict[str, Any] = {}\n        self.active_uploads: Dict[str, Any] = {}\n        \n    async def initialize(self):\n        \"\"\"Initialize all bot components\"\"\"\n        logger.info(\"üîß Initializing bot components...\")\n        \n        try:\n            # Initialize core services\n            await self._initialize_core_services()\n            \n            # Initialize handlers\n            await self._initialize_handlers()\n            \n            # Initialize middleware\n            await self._initialize_middleware()\n            \n            # Setup telegram application\n            await self._setup_application()\n            \n            logger.info(\"‚úÖ Bot initialization completed successfully\")\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Bot initialization failed: {e}\", exc_info=True)\n            raise\n    \n    async def _initialize_core_services(self):\n        \"\"\"Initialize core services and managers\"\"\"\n        # Database manager\n        self.db_manager = DatabaseManager()\n        await self.db_manager.initialize()\n        \n        # Cache manager  \n        self.cache_manager = CacheManager()\n        await self.cache_manager.initialize()\n        \n        # Telethon manager\n        self.telethon_manager = TelethonManager()\n        await self.telethon_manager.initialize()\n        \n        # Progress tracker\n        self.progress_tracker = ProgressTracker(self.cache_manager)\n        \n        # File manager\n        self.file_manager = FileManager(\n            self.telethon_manager, \n            self.progress_tracker\n        )\n        \n        # Video downloader\n        self.downloader = VideoDownloader(\n            self.file_manager,\n            self.progress_tracker,\n            self.cache_manager\n        )\n        \n        logger.info(\"‚úÖ Core services initialized\")\n    \n    async def _initialize_handlers(self):\n        \"\"\"Initialize message and callback handlers\"\"\"\n        self.command_handlers = CommandHandlers(\n            self.downloader,\n            self.file_manager,\n            self.db_manager,\n            self.cache_manager\n        )\n        \n        self.callback_handlers = CallbackHandlers(\n            self.downloader,\n            self.file_manager,\n            self.progress_tracker,\n            self.db_manager,\n            self.cache_manager\n        )\n        \n        self.message_handlers = MessageHandlers(\n            self.downloader,\n            self.cache_manager,\n            self.progress_tracker\n        )\n        \n        logger.info(\"‚úÖ Handlers initialized\")\n    \n    async def _initialize_middleware(self):\n        \"\"\"Initialize middleware components\"\"\"\n        self.auth_middleware = AuthMiddleware()\n        self.rate_limit_middleware = RateLimitMiddleware(self.cache_manager)\n        \n        logger.info(\"‚úÖ Middleware initialized\")\n    \n    async def _setup_application(self):\n        \"\"\"Setup Telegram Bot API application\"\"\"\n        # Create application with ultra-fast settings\n        builder = Application.builder()\n        builder.token(settings.BOT_TOKEN)\n        builder.concurrent_updates(True)\n        builder.pool_timeout(5)  # Ultra fast\n        builder.connect_timeout(3)  # Ultra fast\n        builder.read_timeout(3)  # Ultra fast\n        builder.write_timeout(3)  # Ultra fast\n        builder.get_updates_pool_timeout(0.1)  # Instant polling\n        builder.get_updates_read_timeout(2)  # Fast polling\n        builder.get_updates_connect_timeout(2)  # Fast connection\n        \n        self.application = builder.build()\n        \n        # Add error handler\n        self.application.add_error_handler(self._error_handler)\n        \n        # Add command handlers\n        await self._register_handlers()\n        \n        logger.info(\"‚úÖ Telegram application configured\")\n    \n    async def _register_handlers(self):\n        \"\"\"Register all bot handlers with middleware\"\"\"\n        # Command handlers\n        self.application.add_handler(\n            CommandHandler(\"start\", self._with_middleware(self.command_handlers.start_command))\n        )\n        self.application.add_handler(\n            CommandHandler(\"help\", self._with_middleware(self.command_handlers.help_command))\n        )\n        self.application.add_handler(\n            CommandHandler(\"stats\", self._with_middleware(self.command_handlers.stats_command))\n        )\n        self.application.add_handler(\n            CommandHandler(\"status\", self._with_middleware(self.command_handlers.status_command))\n        )\n        self.application.add_handler(\n            CommandHandler(\"cancel\", self._with_middleware(self.command_handlers.cancel_command))\n        )\n        self.application.add_handler(\n            CommandHandler(\"settings\", self._with_middleware(self.command_handlers.settings_command))\n        )\n        \n        # Message handlers  \n        self.application.add_handler(\n            MessageHandler(\n                filters.TEXT & ~filters.COMMAND,\n                self._with_middleware(self.message_handlers.handle_url_message)\n            )\n        )\n        \n        # Master callback query handler\n        self.application.add_handler(\n            CallbackQueryHandler(\n                self._with_middleware(self.callback_handlers.handle_callback_query)\n            )\n        )\n        \n        logger.info(\"‚úÖ All handlers registered\")\n    \n    def _with_middleware(self, handler):\n        \"\"\"Ultra-fast middleware wrapper\"\"\"\n        async def wrapped_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):\n            # Quick user validation\n            user = update.effective_user\n            if not user:\n                return\n            \n            user_id = user.id\n            current_time = time.time()\n            \n            # In-memory auth cache for instant access\n            if not hasattr(self, '_auth_cache'):\n                self._auth_cache = {}\n            \n            # Check auth (cached in memory for 10 minutes)\n            if user_id not in self._auth_cache or (current_time - self._auth_cache[user_id]) > 600:\n                if not await self.auth_middleware.check_access(update):\n                    await update.effective_message.reply_text(\"‚ùå Access denied.\")\n                    return\n                self._auth_cache[user_id] = current_time\n            \n            # Ultra-light rate limiting (in-memory only)\n            if not hasattr(self, '_last_requests'):\n                self._last_requests = {}\n            \n            last_request = self._last_requests.get(user_id, 0)\n            if current_time - last_request < 0.1:  # 100ms minimum only\n                return  # Silent rate limiting for ultra-fast UX\n            \n            self._last_requests[user_id] = current_time\n            \n            # Execute handler immediately\n            try:\n                await handler(update, context)\n            except Exception as e:\n                logger.error(f\"Handler error: {e}\", exc_info=True)\n                await self._send_error_message(update, e)\n        \n        return wrapped_handler\n    \n    async def _error_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Global error handler\"\"\"\n        logger.error(f\"Update {update} caused error {context.error}\", exc_info=context.error)\n        \n        if update and update.effective_message:\n            await self._send_error_message(update, context.error)\n    \n    async def _send_error_message(self, update: Update, error: Exception):\n        \"\"\"Send user-friendly error message\"\"\"\n        error_msg = create_error_message(error)\n        \n        try:\n            if update.callback_query:\n                await update.callback_query.message.reply_text(error_msg)\n            else:\n                await update.effective_message.reply_text(error_msg)\n        except Exception as e:\n            logger.error(f\"Failed to send error message: {e}\")\n    \n    async def start(self):\n        \"\"\"Start the bot\"\"\"\n        try:\n            logger.info(\"üöÄ Starting bot polling...\")\n            \n            # Initialize application\n            await self.application.initialize()\n            \n            # Start polling in a way compatible with existing event loop\n            await self.application.updater.start_polling(\n                allowed_updates=[\"message\", \"callback_query\"],\n                drop_pending_updates=True\n            )\n            \n            # Start the application\n            await self.application.start()\n            \n            logger.info(\"‚úÖ Bot is now running and ready to receive messages!\")\n            \n            # Keep the bot running\n            try:\n                # In Replit, we don't want to block, just keep alive\n                while True:\n                    await asyncio.sleep(1)\n            except KeyboardInterrupt:\n                logger.info(\"üì± Received stop signal\")\n                \n        except Exception as e:\n            logger.error(f\"‚ùå Bot polling failed: {e}\", exc_info=True)\n            raise\n    \n    async def stop(self):\n        \"\"\"Stop the bot and cleanup resources\"\"\"\n        logger.info(\"üõë Stopping bot...\")\n        \n        if self.application:\n            await self.application.shutdown()\n        \n        # Cleanup services\n        if self.telethon_manager:\n            await self.telethon_manager.disconnect()\n        \n        if self.db_manager:\n            await self.db_manager.close_all_connections()\n        \n        if self.cache_manager:\n            await self.cache_manager.close()\n        \n        logger.info(\"‚úÖ Bot stopped successfully\")\n    \n    def get_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get current performance statistics\"\"\"\n        return {\n            'active_downloads': len(self.active_downloads),\n            'active_uploads': len(self.active_uploads),\n            'max_concurrent_downloads': settings.MAX_CONCURRENT_DOWNLOADS,\n            'max_concurrent_uploads': settings.MAX_CONCURRENT_UPLOADS,\n            'total_processed': getattr(self, 'total_processed', 0),\n            'uptime': getattr(self, 'start_time', 0),\n        }\n","size_bytes":12102},"core/telethon_client.py":{"content":"\"\"\"\nTelethon client manager for high-performance file operations\nHandles MTProto connections, file uploads, and FastTelethon optimization\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nfrom typing import Optional, Callable, Any, Dict\nfrom telethon import TelegramClient, events\nfrom telethon.sessions import StringSession\nfrom telethon.tl.types import DocumentAttributeVideo, DocumentAttributeFilename\n\nfrom config.settings import settings\nfrom utils.helpers import format_file_size, calculate_upload_speed\n\nlogger = logging.getLogger(__name__)\n\nclass TelethonManager:\n    \"\"\"High-performance Telethon client manager\"\"\"\n    \n    def __init__(self):\n        self.client: Optional[TelegramClient] = None\n        self.is_connected = False\n        self.upload_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_UPLOADS)\n        self.fast_telethon_available = False\n        \n        # Performance tracking\n        self.upload_stats: Dict[str, Any] = {}\n        \n    async def initialize(self):\n        \"\"\"Initialize Telethon client with optimizations\"\"\"\n        logger.info(\"üîß Initializing Telethon client...\")\n        \n        try:\n            # Check for FastTelethon availability\n            await self._check_fast_telethon()\n            \n            # Create optimized client\n            await self._create_client()\n            \n            # Connect and authenticate\n            await self._connect_and_auth()\n            \n            # Setup event handlers\n            await self._setup_events()\n            \n            logger.info(\"‚úÖ Telethon client initialized successfully\")\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Telethon initialization failed: {e}\", exc_info=True)\n            raise\n    \n    async def _check_fast_telethon(self):\n        \"\"\"Check and configure FastTelethon if available\"\"\"\n        try:\n            if settings.USE_FAST_TELETHON:\n                # Try multiple FastTelethon package names\n                global fast_upload, fast_download\n                try:\n                    from FastTelethon import fast_upload, fast_download\n                except ImportError:\n                    try:\n                        from fast_telethon import fast_upload, fast_download\n                    except ImportError:\n                        # If FastTelethon not available, optimize standard Telethon\n                        logger.warning(\"‚ö†Ô∏è FastTelethon not available, using optimized standard Telethon\")\n                        self.fast_telethon_available = False\n                        return\n                \n                self.fast_telethon_available = True\n                logger.info(\"üöÄ FastTelethon enabled for enhanced performance\")\n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è FastTelethon check failed: {e}, using optimized standard Telethon\")\n            self.fast_telethon_available = False\n    \n    async def _create_client(self):\n        \"\"\"Create optimized Telethon client\"\"\"\n        # Use string session if provided, otherwise create new\n        session = StringSession(settings.SESSION_STRING) if settings.SESSION_STRING else \"video_bot_session\"\n        \n        self.client = TelegramClient(\n            session,\n            settings.API_ID,\n            settings.API_HASH,\n            connection_retries=settings.CONNECTION_RETRIES,\n            retry_delay=0.5,  # Ultra-fast retry\n            timeout=settings.REQUEST_TIMEOUT,\n            request_retries=3,  # Balanced retries\n            flood_sleep_threshold=15,  # Aggressive flood threshold\n            device_model=\"VideoBot Ultra Pro\",\n            system_version=\"3.0\",\n            app_version=\"3.0\",\n            lang_code=\"en\",\n            system_lang_code=\"en\",\n            # Ultra-performance optimizations\n            auto_reconnect=True,\n            sequential_updates=False,  # Allow parallel updates\n            receive_updates=False  # Disable updates for upload-only client\n        )\n    \n    async def _connect_and_auth(self):\n        \"\"\"Connect and authenticate the client\"\"\"\n        await self.client.connect()\n        \n        if not await self.client.is_user_authorized():\n            if settings.SESSION_STRING:\n                logger.error(\"‚ùå Invalid session string provided\")\n                raise ValueError(\"Invalid session string\")\n            else:\n                logger.error(\"‚ùå Client not authorized. Please provide SESSION_STRING\")\n                raise ValueError(\"Client authorization required\")\n        \n        # Get client info\n        me = await self.client.get_me()\n        logger.info(f\"‚úÖ Connected as: {me.first_name} (@{me.username})\")\n        \n        self.is_connected = True\n    \n    async def _setup_events(self):\n        \"\"\"Setup event handlers for monitoring\"\"\"\n        @self.client.on(events.Raw)\n        async def raw_handler(event):\n            # Monitor for connection issues\n            if hasattr(event, 'error'):\n                logger.warning(f\"Telethon event error: {event.error}\")\n    \n    async def upload_file(\n        self,\n        file_path: str,\n        chat_id: int,\n        caption: str = \"\",\n        progress_callback: Optional[Callable] = None,\n        thumbnail: Optional[str] = None,\n        video_metadata: Optional[Dict] = None\n    ) -> Any:\n        \"\"\"\n        High-performance file upload with FastTelethon optimization\n        \"\"\"\n        async with self.upload_semaphore:\n            try:\n                if not os.path.exists(file_path):\n                    raise FileNotFoundError(f\"File not found: {file_path}\")\n                \n                file_size = os.path.getsize(file_path)\n                if file_size > settings.MAX_FILE_SIZE:\n                    raise ValueError(f\"File too large: {format_file_size(file_size)}\")\n                \n                logger.info(f\"üì§ Starting upload: {os.path.basename(file_path)} ({format_file_size(file_size)})\")\n                \n                # Prepare upload attributes\n                attributes = await self._prepare_attributes(file_path, video_metadata)\n                \n                # Upload with progress tracking\n                uploaded_file = await self._upload_with_progress(\n                    file_path, progress_callback, file_size\n                )\n                \n                # Determine if this is a video file\n                filename = os.path.basename(file_path)\n                is_video_file = filename.lower().endswith(('.mp4', '.avi', '.mkv', '.mov', '.webm'))\n                \n                # Send the file\n                message = await self.client.send_file(\n                    chat_id,\n                    uploaded_file,\n                    caption=caption,\n                    attributes=attributes,\n                    thumb=thumbnail,\n                    force_document=False,  # Always send as video/media, not as document\n                    parse_mode='HTML'\n                )\n                \n                logger.info(f\"‚úÖ Upload completed: {os.path.basename(file_path)}\")\n                return message\n                \n            except Exception as e:\n                logger.error(f\"‚ùå Upload failed for {file_path}: {e}\", exc_info=True)\n                raise\n    \n    async def _upload_with_progress(\n        self, \n        file_path: str, \n        progress_callback: Optional[Callable],\n        file_size: int\n    ):\n        \"\"\"Upload file with progress tracking and optimization\"\"\"\n        \n        if self.fast_telethon_available and settings.USE_FAST_TELETHON:\n            # Use FastTelethon with ultra-optimized settings\n            return await fast_upload(\n                self.client,\n                file_path,\n                progress_callback=progress_callback,\n                workers=getattr(settings, 'UPLOAD_WORKERS', 16),  # More workers for speed\n                part_size_kb=512  # 512KB parts (max allowed)\n            )\n        else:\n            # Use standard Telethon upload with ultra-optimized settings\n            return await self.client.upload_file(\n                file_path,\n                progress_callback=progress_callback,\n                part_size_kb=512,  # 512KB parts (max allowed)\n                file_size=file_size if file_size else None  # Provide file size for optimization\n            )\n    \n    async def _prepare_attributes(self, file_path: str, video_metadata: Optional[Dict] = None):\n        \"\"\"Prepare file attributes for upload\"\"\"\n        attributes = []\n        \n        # Add filename attribute\n        filename = os.path.basename(file_path)\n        attributes.append(DocumentAttributeFilename(filename))\n        \n        # Add video attributes if it's a video file\n        if video_metadata and filename.lower().endswith(('.mp4', '.avi', '.mkv', '.mov', '.webm')):\n            attributes.append(DocumentAttributeVideo(\n                duration=video_metadata.get('duration', 0),\n                w=video_metadata.get('width', 0),\n                h=video_metadata.get('height', 0),\n                supports_streaming=True\n            ))\n        \n        return attributes\n    \n    async def download_media(\n        self,\n        message,\n        file_path: str,\n        progress_callback: Optional[Callable] = None\n    ) -> str:\n        \"\"\"\n        High-performance media download\n        \"\"\"\n        try:\n            logger.info(f\"üì• Starting download to: {file_path}\")\n            \n            if self.fast_telethon_available:\n                # Use FastTelethon for enhanced download speed\n                return await fast_download(\n                    self.client,\n                    message,\n                    file_path,\n                    progress_callback=progress_callback\n                )\n            else:\n                # Use standard Telethon download\n                return await self.client.download_media(\n                    message,\n                    file=file_path,\n                    progress_callback=progress_callback\n                )\n                \n        except Exception as e:\n            logger.error(f\"‚ùå Download failed: {e}\", exc_info=True)\n            raise\n    \n    async def get_chat_info(self, chat_id: int):\n        \"\"\"Get information about a chat\"\"\"\n        try:\n            return await self.client.get_entity(chat_id)\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get chat info for {chat_id}: {e}\")\n            return None\n    \n    async def send_message(self, chat_id: int, message: str, **kwargs):\n        \"\"\"Send a text message\"\"\"\n        try:\n            return await self.client.send_message(chat_id, message, **kwargs)\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to send message: {e}\")\n            raise\n    \n    def create_progress_callback(self, task_id: str, total_size: int):\n        \"\"\"Create a progress callback for tracking uploads/downloads\"\"\"\n        def progress_callback(current: int, total: int):\n            percentage = (current / total) * 100 if total > 0 else 0\n            speed = calculate_upload_speed(current, total_size)\n            \n            # Update progress tracking\n            self.upload_stats[task_id] = {\n                'current': current,\n                'total': total,\n                'percentage': percentage,\n                'speed': speed,\n                'task_id': task_id\n            }\n        \n        return progress_callback\n    \n    async def disconnect(self):\n        \"\"\"Disconnect the Telethon client\"\"\"\n        if self.client and self.is_connected:\n            await self.client.disconnect()\n            self.is_connected = False\n            logger.info(\"üîå Telethon client disconnected\")\n    \n    def is_ready(self) -> bool:\n        \"\"\"Check if client is ready for operations\"\"\"\n        return self.client is not None and self.is_connected\n    \n    async def get_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get current performance statistics\"\"\"\n        if not self.client:\n            return {}\n        \n        return {\n            'connected': self.is_connected,\n            'fast_telethon_enabled': self.fast_telethon_available,\n            'active_uploads': len(self.upload_stats),\n            'upload_queue_size': self.upload_semaphore._value,\n            'max_concurrent_uploads': settings.MAX_CONCURRENT_UPLOADS,\n        }\n","size_bytes":12303},"database/__init__.py":{"content":"\"\"\"Database module for the video downloader bot\"\"\"\n\nfrom .connection import DatabaseManager\nfrom .models import User, Download, UserAnalytics, SystemStats, Platform, ErrorLog\n\n__all__ = ['DatabaseManager', 'User', 'Download', 'UserAnalytics', 'SystemStats', 'Platform', 'ErrorLog']\n","size_bytes":282},"database/connection.py":{"content":"\"\"\"\nDatabase connection manager for PostgreSQL\nHandles connection pooling, migrations, and database operations\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import Dict, Any, List, Optional, Union\nfrom datetime import datetime, timedelta\nfrom contextlib import asynccontextmanager\n\nimport asyncpg\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker\nfrom sqlalchemy.sql import text\nfrom sqlalchemy import func\n\nfrom config.settings import settings\nfrom database.models import Base, User, Download, UserAnalytics, SystemStats, Platform, ErrorLog\n\nlogger = logging.getLogger(__name__)\n\nclass DatabaseManager:\n    \"\"\"Ultra high-performance database manager with connection pooling\"\"\"\n\n    def __init__(self):\n        self.engine: Optional[any] = None\n        self.session_factory: Optional[async_sessionmaker] = None\n        self.connection_pool: Optional[asyncpg.Pool] = None\n        self.is_initialized = False\n        # Assume cache_manager is available and initialized elsewhere\n        # self.cache_manager = CacheManager() \n\n        # Connection pool settings\n        self.min_connections = 5\n        self.max_connections = 20\n        self.pool_timeout = 30\n\n    async def initialize(self):\n        \"\"\"Initialize database connections and create tables\"\"\"\n        try:\n            logger.info(\"üîß Initializing database connections...\")\n\n            # Create async engine with optimized settings\n            # Remove any SSL parameters that might conflict\n            db_url = settings.DATABASE_URL.replace('postgresql://', 'postgresql+asyncpg://')\n            if '?sslmode=' in db_url:\n                db_url = db_url.split('?sslmode=')[0]\n\n            self.engine = create_async_engine(\n                db_url,\n                pool_size=self.min_connections,\n                max_overflow=self.max_connections - self.min_connections,\n                pool_timeout=self.pool_timeout,\n                pool_pre_ping=True,\n                pool_recycle=3600,  # Recycle connections every hour\n                echo=False,  # Set to True for SQL debugging\n            )\n\n            # Create session factory\n            self.session_factory = async_sessionmaker(\n                bind=self.engine,\n                class_=AsyncSession,\n                expire_on_commit=False\n            )\n\n            # Create raw connection pool for direct queries\n            await self._create_connection_pool()\n\n            # Create tables if they don't exist\n            await self._create_tables()\n\n            # Mark as initialized before calling methods that use get_session()\n            self.is_initialized = True\n\n            # Initialize default data\n            await self._initialize_default_data()\n\n            logger.info(\"‚úÖ Database initialized successfully\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Database initialization failed: {e}\", exc_info=True)\n            raise\n\n    async def _create_connection_pool(self):\n        \"\"\"Create asyncpg connection pool for raw queries\"\"\"\n        try:\n            # Use direct database URL with asyncpg (it handles SSL automatically)\n            # Remove sslmode parameter if present to avoid conflicts\n            db_url = settings.DATABASE_URL\n            if '?sslmode=' in db_url:\n                db_url = db_url.split('?sslmode=')[0]\n\n            # Create AsyncPG connection pool with ultra-fast settings\n            self.connection_pool = await asyncpg.create_pool(\n                dsn=db_url,  # Use dsn directly\n                min_size=5,  # Fewer minimum connections for faster startup\n                max_size=20,  # Reasonable maximum\n                max_queries=5000,  # More queries per connection\n                max_inactive_connection_lifetime=120,  # 2 minutes only\n                timeout=5,  # Fast connection timeout\n                command_timeout=10,  # Fast command timeout\n                server_settings={\n                    'jit': 'off',  # Disable JIT for faster simple queries\n                    'application_name': 'video_downloader_bot',\n                    'shared_preload_libraries': '',\n                    'max_connections': '200'\n                }\n            )\n\n            logger.info(\"‚úÖ AsyncPG connection pool created\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to create connection pool: {e}\")\n            raise\n\n    async def _create_tables(self):\n        \"\"\"Create database tables if they don't exist\"\"\"\n        try:\n            if self.engine is None:\n                raise RuntimeError(\"Database engine not initialized\")\n            async with self.engine.begin() as conn:\n                await conn.run_sync(Base.metadata.create_all)\n\n            logger.info(\"‚úÖ Database tables created/verified\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to create tables: {e}\")\n            raise\n\n    async def _initialize_default_data(self):\n        \"\"\"Initialize default platform data\"\"\"\n        try:\n            async with self.get_session() as session:\n                # Check if platforms already exist\n                result = await session.execute(text(\"SELECT COUNT(*) FROM platforms\"))\n                count = result.scalar()\n\n                if count == 0:\n                    # Insert default platforms\n                    default_platforms = [\n                        {\n                            'name': 'youtube',\n                            'display_name': 'YouTube',\n                            'base_url': 'https://www.youtube.com',\n                            'supports_video': True,\n                            'supports_audio': True,\n                            'supports_playlists': True,\n                            'max_quality': '4K'\n                        },\n                        {\n                            'name': 'tiktok',\n                            'display_name': 'TikTok',\n                            'base_url': 'https://www.tiktok.com',\n                            'supports_video': True,\n                            'supports_audio': True,\n                            'supports_playlists': False,\n                            'max_quality': '1080p'\n                        },\n                        {\n                            'name': 'instagram',\n                            'display_name': 'Instagram',\n                            'base_url': 'https://www.instagram.com',\n                            'supports_video': True,\n                            'supports_audio': True,\n                            'supports_playlists': False,\n                            'max_quality': '1080p'\n                        },\n                        {\n                            'name': 'facebook',\n                            'display_name': 'Facebook',\n                            'base_url': 'https://www.facebook.com',\n                            'supports_video': True,\n                            'supports_audio': True,\n                            'supports_playlists': False,\n                            'max_quality': '1080p'\n                        },\n                        {\n                            'name': 'twitter',\n                            'display_name': 'Twitter/X',\n                            'base_url': 'https://twitter.com',\n                            'supports_video': True,\n                            'supports_audio': True,\n                            'supports_playlists': False,\n                            'max_quality': '1080p'\n                        }\n                    ]\n\n                    for platform_data in default_platforms:\n                        platform = Platform(**platform_data)\n                        session.add(platform)\n\n                    await session.commit()\n                    logger.info(\"‚úÖ Default platforms initialized\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to initialize default data: {e}\")\n\n    @asynccontextmanager\n    async def get_session(self):\n        \"\"\"Get database session with automatic cleanup\"\"\"\n        if not self.is_initialized or self.session_factory is None:\n            raise RuntimeError(\"Database not initialized\")\n\n        async with self.session_factory() as session:\n            try:\n                yield session\n            except Exception as e:\n                await session.rollback()\n                logger.error(f\"Database session error: {e}\")\n                raise\n            finally:\n                await session.close()\n\n    async def get_connection(self):\n        \"\"\"Get a connection from the asyncpg pool\"\"\"\n        if self.connection_pool is None:\n            raise RuntimeError(\"Connection pool not initialized\")\n        return await self.connection_pool.acquire()\n\n    async def create_or_update_user(\n        self,\n        user_id: int,\n        username: Optional[str] = None,\n        first_name: Optional[str] = None,\n        last_name: Optional[str] = None,\n        chat_id: Optional[int] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Create or update user in database\"\"\"\n        try:\n            async with self.get_session() as session:\n                # Try to get existing user\n                result = await session.execute(\n                    text(\"SELECT * FROM users WHERE user_id = :user_id\"),\n                    {\"user_id\": user_id}\n                )\n                user_data = result.fetchone()\n\n                if user_data:\n                    # Update existing user\n                    await session.execute(\n                        text(\"\"\"\n                            UPDATE users \n                            SET username = :username, first_name = :first_name, \n                                last_name = :last_name, chat_id = :chat_id, \n                                last_active = :now, updated_at = :now\n                            WHERE user_id = :user_id\n                        \"\"\"),\n                        {\n                            \"user_id\": user_id,\n                            \"username\": username,\n                            \"first_name\": first_name,\n                            \"last_name\": last_name,\n                            \"chat_id\": chat_id,\n                            \"now\": datetime.utcnow()\n                        }\n                    )\n\n                    # Fetch updated user\n                    result = await session.execute(\n                        text(\"SELECT * FROM users WHERE user_id = :user_id\"),\n                        {\"user_id\": user_id}\n                    )\n                    user_data = result.fetchone()\n                else:\n                    # Create new user\n                    await session.execute(\n                        text(\"\"\"\n                            INSERT INTO users (user_id, username, first_name, last_name, chat_id, created_at, last_active)\n                            VALUES (:user_id, :username, :first_name, :last_name, :chat_id, :now, :now)\n                        \"\"\"),\n                        {\n                            \"user_id\": user_id,\n                            \"username\": username,\n                            \"first_name\": first_name,\n                            \"last_name\": last_name,\n                            \"chat_id\": chat_id,\n                            \"now\": datetime.utcnow()\n                        }\n                    )\n\n                    # Fetch created user\n                    result = await session.execute(\n                        text(\"SELECT * FROM users WHERE user_id = :user_id\"),\n                        {\"user_id\": user_id}\n                    )\n                    user_data = result.fetchone()\n\n                await session.commit()\n\n                # Convert asyncpg Row to dict properly\n                if user_data:\n                    return {\n                        'id': user_data[0] if len(user_data) > 0 else None,\n                        'user_id': user_data[1] if len(user_data) > 1 else None,\n                        'username': user_data[2] if len(user_data) > 2 else None,\n                        'first_name': user_data[3] if len(user_data) > 3 else None,\n                        'last_name': user_data[4] if len(user_data) > 4 else None,\n                        'chat_id': user_data[5] if len(user_data) > 5 else None,\n                        'settings': user_data[6] if len(user_data) > 6 else {},\n                        'total_downloads': user_data[7] if len(user_data) > 7 else 0,\n                        'successful_downloads': user_data[8] if len(user_data) > 8 else 0,\n                        'failed_downloads': user_data[9] if len(user_data) > 9 else 0,\n                        'total_bytes_downloaded': user_data[10] if len(user_data) > 10 else 0,\n                        'total_bytes_uploaded': user_data[11] if len(user_data) > 11 else 0,\n                        'created_at': user_data[12] if len(user_data) > 12 else None,\n                        'updated_at': user_data[13] if len(user_data) > 13 else None,\n                        'last_active': user_data[14] if len(user_data) > 14 else None,\n                        'is_premium': user_data[15] if len(user_data) > 15 else False,\n                        'premium_expires': user_data[16] if len(user_data) > 16 else None\n                    }\n                else:\n                    return {}\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to create/update user {user_id}: {e}\")\n            raise\n\n    async def create_download_record(\n        self,\n        task_id: str,\n        user_id: int,\n        original_url: str,\n        video_info: Dict[str, Any],\n        format_info: Dict[str, Any]\n    ) -> int:\n        \"\"\"Create download record in database\"\"\"\n        try:\n            async with self.get_session() as session:\n                download_data = {\n                    \"task_id\": task_id,\n                    \"user_id\": user_id,\n                    \"original_url\": original_url,\n                    \"video_title\": video_info.get('title'),\n                    \"video_id\": video_info.get('id'),\n                    \"platform\": video_info.get('platform'),\n                    \"uploader\": video_info.get('uploader'),\n                    \"duration\": video_info.get('duration'),\n                    \"view_count\": video_info.get('view_count'),\n                    \"upload_date\": video_info.get('upload_date'),\n                    \"format_id\": format_info.get('format_id'),\n                    \"quality\": format_info.get('quality'),\n                    \"file_extension\": format_info.get('ext'),\n                    \"file_size\": format_info.get('file_size'),\n                    \"is_audio_only\": format_info.get('ext') == 'mp3',\n                    \"status\": 'pending',\n                    \"video_metadata\": {\n                        \"video_info\": video_info,\n                        \"format_info\": format_info\n                    },\n                    \"created_at\": datetime.utcnow()\n                }\n\n                result = await session.execute(\n                    text(\"\"\"\n                        INSERT INTO downloads \n                        (task_id, user_id, original_url, video_title, video_id, platform, uploader, \n                         duration, view_count, upload_date, format_id, quality, file_extension, \n                         file_size, is_audio_only, status, video_metadata, created_at)\n                        VALUES \n                        (:task_id, :user_id, :original_url, :video_title, :video_id, :platform, \n                         :uploader, :duration, :view_count, :upload_date, :format_id, :quality, \n                         :file_extension, :file_size, :is_audio_only, :status, :video_metadata, :created_at)\n                        RETURNING id\n                    \"\"\"),\n                    download_data\n                )\n\n                download_id = result.scalar()\n                await session.commit()\n\n                logger.info(f\"‚úÖ Created download record {download_id} for task {task_id}\")\n                return int(download_id) if download_id else 0\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to create download record: {e}\")\n            raise\n\n    async def update_download_progress(\n        self,\n        task_id: str,\n        status: str,\n        download_time: Optional[float] = None,\n        upload_time: Optional[float] = None,\n        download_speed: Optional[float] = None,\n        upload_speed: Optional[float] = None,\n        error_message: Optional[str] = None,\n        telegram_message_id: Optional[int] = None,\n        telegram_chat_id: Optional[int] = None\n    ):\n        \"\"\"Update download progress in database\"\"\"\n        try:\n            async with self.get_session() as session:\n                update_data = {\n                    \"task_id\": task_id,\n                    \"status\": status,\n                    \"updated_at\": datetime.utcnow()\n                }\n\n                # Add optional fields if provided\n                if download_time is not None:\n                    update_data[\"download_time\"] = download_time\n                if upload_time is not None:\n                    update_data[\"upload_time\"] = upload_time\n                if download_speed is not None:\n                    update_data[\"download_speed\"] = download_speed\n                if upload_speed is not None:\n                    update_data[\"upload_speed\"] = upload_speed\n                if error_message is not None:\n                    update_data[\"error_message\"] = error_message\n                if telegram_message_id is not None:\n                    update_data[\"telegram_message_id\"] = telegram_message_id\n                if telegram_chat_id is not None:\n                    update_data[\"telegram_chat_id\"] = telegram_chat_id\n\n                # Set completion timestamp for final statuses\n                if status in ['completed', 'failed', 'cancelled']:\n                    update_data[\"completed_at\"] = datetime.utcnow()\n                elif status == 'downloading':\n                    update_data[\"started_at\"] = datetime.utcnow()\n\n                # Build dynamic update query\n                set_clauses = []\n                for key in update_data.keys():\n                    if key != \"task_id\":\n                        set_clauses.append(f\"{key} = :{key}\")\n\n                query = f\"\"\"\n                    UPDATE downloads \n                    SET {', '.join(set_clauses)}\n                    WHERE task_id = :task_id\n                \"\"\"\n\n                await session.execute(text(query), update_data)\n                await session.commit()\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to update download progress for {task_id}: {e}\")\n\n    async def get_user_stats(self, user_id: int) -> Dict[str, Any]:\n        \"\"\"Get comprehensive user statistics with caching (optimized)\"\"\"\n        try:\n            # Check cache first with longer TTL\n            cache_key = f\"user_stats:{user_id}\"\n            # Skip cache for now until cache_manager is properly initialized\n            cached_stats = None\n\n            if cached_stats:\n                return cached_stats\n\n            # Use a single optimized query instead of multiple queries\n            async with self.get_connection() as conn:\n                # Single comprehensive query\n                result = await conn.fetchrow(\"\"\"\n                    SELECT \n                        u.total_downloads, u.successful_downloads, u.failed_downloads,\n                        u.total_bytes_downloaded, u.total_bytes_uploaded, u.created_at, u.last_active,\n                        COALESCE(AVG(d.download_speed), 0) as avg_download_speed,\n                        COALESCE(AVG(d.upload_speed), 0) as avg_upload_speed,\n                        COALESCE(MAX(d.download_speed), 0) as fastest_download_speed,\n                        COALESCE(AVG(d.download_time + d.upload_time), 0) as avg_processing_time,\n                        COALESCE(SUM(d.download_time), 0) as total_download_time,\n                        COALESCE(SUM(d.upload_time), 0) as total_upload_time,\n                        COALESCE(AVG(d.file_size), 0) as avg_file_size\n                    FROM users u\n                    LEFT JOIN downloads d ON u.user_id = d.user_id AND d.status = 'completed'\n                    WHERE u.user_id = $1\n                    GROUP BY u.user_id, u.total_downloads, u.successful_downloads, u.failed_downloads,\n                             u.total_bytes_downloaded, u.total_bytes_uploaded, u.created_at, u.last_active\n                \"\"\", user_id)\n\n                if not result:\n                    return {}\n\n                # Convert asyncpg Row to dict properly and handle nulls\n                stats = {\n                    'total_downloads': result['total_downloads'] if result['total_downloads'] is not None else 0,\n                    'successful_downloads': result['successful_downloads'] if result['successful_downloads'] is not None else 0,\n                    'failed_downloads': result['failed_downloads'] if result['failed_downloads'] is not None else 0,\n                    'total_bytes_downloaded': result['total_bytes_downloaded'] if result['total_bytes_downloaded'] is not None else 0,\n                    'total_bytes_uploaded': result['total_bytes_uploaded'] if result['total_bytes_uploaded'] is not None else 0,\n                    'created_at': result['created_at'],\n                    'last_active': result['last_active'],\n                    'avg_download_speed': result['avg_download_speed'],\n                    'avg_upload_speed': result['avg_upload_speed'],\n                    'fastest_download_speed': result['fastest_download_speed'],\n                    'avg_processing_time': result['avg_processing_time'],\n                    'total_download_time': result['total_download_time'],\n                    'total_upload_time': result['total_upload_time'],\n                    'avg_file_size': result['avg_file_size']\n                }\n\n                # Calculate success rate (handle null values)\n                success_rate = 0\n                total_downloads = stats['total_downloads']\n                successful_downloads = stats['successful_downloads']\n\n                if total_downloads > 0:\n                    success_rate = (successful_downloads / total_downloads) * 100\n\n                stats['success_rate'] = success_rate\n\n                # Format timestamps\n                if stats.get('created_at'):\n                    stats['created_at'] = stats['created_at'].strftime('%B %d, %Y')\n                if stats.get('last_active'):\n                    stats['last_active'] = stats['last_active'].strftime('%B %d, %Y at %I:%M %p')\n\n                # Cache the results - will be implemented later when cache_manager is properly initialized\n                # await self.cache_manager.set(cache_key, stats, ttl=3600)\n\n                return stats\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get user stats for {user_id}: {e}\")\n            return {}\n\n    async def get_user_settings(self, user_id: int) -> Dict[str, Any]:\n        \"\"\"Get user settings\"\"\"\n        try:\n            if self.connection_pool is None:\n                raise RuntimeError(\"Connection pool not initialized\")\n            async with self.connection_pool.acquire() as conn:\n                result = await conn.fetchrow(\n                    \"SELECT settings FROM users WHERE user_id = $1\",\n                    user_id\n                )\n\n                if result and result['settings']:\n                    return result['settings']\n                else:\n                    # Return default settings\n                    return {\n                        'default_quality': 'best',\n                        'default_format': 'mp4',\n                        'progress_notifications': True,\n                        'completion_notifications': True,\n                        'error_notifications': True,\n                        'auto_cleanup': True,\n                        'fast_mode': True,\n                        'generate_thumbnails': True\n                    }\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get user settings for {user_id}: {e}\")\n            return {}\n\n    async def update_user_settings(self, user_id: int, settings_update: Dict[str, Any]):\n        \"\"\"Update user settings\"\"\"\n        try:\n            if self.connection_pool is None:\n                raise RuntimeError(\"Connection pool not initialized\")\n            async with self.connection_pool.acquire() as conn:\n                # Get current settings\n                current_settings = await self.get_user_settings(user_id)\n\n                # Merge with updates\n                current_settings.update(settings_update)\n\n                # Update in database\n                await conn.execute(\"\"\"\n                    UPDATE users \n                    SET settings = $1, updated_at = $2\n                    WHERE user_id = $3\n                \"\"\", current_settings, datetime.utcnow(), user_id)\n\n                logger.info(f\"‚úÖ Updated settings for user {user_id}\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to update user settings for {user_id}: {e}\")\n\n    async def get_global_stats(self) -> Dict[str, Any]:\n        \"\"\"Get global bot statistics\"\"\"\n        try:\n            if self.connection_pool is None:\n                raise RuntimeError(\"Connection pool not initialized\")\n            async with self.connection_pool.acquire() as conn:\n                # Get user statistics\n                user_stats = await conn.fetchrow(\"\"\"\n                    SELECT \n                        COUNT(*) as total_users,\n                        COUNT(CASE WHEN last_active > NOW() - INTERVAL '1 day' THEN 1 END) as active_today,\n                        COUNT(CASE WHEN created_at > NOW() - INTERVAL '1 day' THEN 1 END) as new_users_24h\n                    FROM users\n                \"\"\")\n\n                # Get download statistics\n                download_stats = await conn.fetchrow(\"\"\"\n                    SELECT \n                        COUNT(*) as total_downloads,\n                        COUNT(CASE WHEN status = 'completed' THEN 1 END) as successful_downloads,\n                        COUNT(CASE WHEN status = 'failed' THEN 1 END) as failed_downloads,\n                        SUM(CASE WHEN status = 'completed' THEN file_size ELSE 0 END) as total_data_processed,\n                        SUM(CASE WHEN status = 'completed' AND created_at > NOW() - INTERVAL '1 day' THEN file_size ELSE 0 END) as data_today,\n                        AVG(CASE WHEN status = 'completed' THEN download_speed END) as avg_speed,\n                        MAX(CASE WHEN status = 'completed' THEN download_speed END) as peak_speed\n                    FROM downloads\n                \"\"\")\n\n                # Calculate additional metrics\n                stats = dict(user_stats)\n                stats.update(dict(download_stats))\n\n                # Calculate success rate\n                if stats['total_downloads'] > 0:\n                    stats['global_success_rate'] = (stats['successful_downloads'] / stats['total_downloads']) * 100\n                else:\n                    stats['global_success_rate'] = 0\n\n                # Calculate average per user\n                if stats['total_users'] > 0:\n                    stats['avg_per_user'] = stats['total_data_processed'] / stats['total_users']\n                else:\n                    stats['avg_per_user'] = 0\n\n                return stats\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get global stats: {e}\")\n            return {}\n\n    async def get_database_stats(self) -> Dict[str, Any]:\n        \"\"\"Get database performance statistics\"\"\"\n        try:\n            if self.connection_pool is None:\n                raise RuntimeError(\"Connection pool not initialized\")\n            async with self.connection_pool.acquire() as conn:\n                # Check connection\n                await conn.fetchval(\"SELECT 1\")\n                connected = True\n\n                # Get database size\n                db_size = await conn.fetchval(\"\"\"\n                    SELECT pg_size_pretty(pg_database_size(current_database()))\n                \"\"\")\n\n                # Get table sizes\n                table_sizes = await conn.fetch(\"\"\"\n                    SELECT \n                        schemaname as schema,\n                        tablename as table,\n                        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,\n                        pg_total_relation_size(schemaname||'.'||tablename) as bytes\n                    FROM pg_tables \n                    WHERE schemaname = 'public'\n                    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC\n                    LIMIT 10\n                \"\"\")\n\n                # Get user and download counts\n                total_users = await conn.fetchval(\"SELECT COUNT(*) FROM users\")\n                total_downloads = await conn.fetchval(\"SELECT COUNT(*) FROM downloads\")\n\n                return {\n                    'connected': connected,\n                    'database_size': db_size,\n                    'database_size_bytes': sum(row['bytes'] for row in table_sizes),\n                    'total_users': total_users,\n                    'total_downloads': total_downloads,\n                    'table_sizes': [dict(row) for row in table_sizes]\n                }\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get database stats: {e}\")\n            return {'connected': False, 'error': str(e)}\n\n    async def cleanup_old_records(self, days: int = 30):\n        \"\"\"Clean up old records to maintain performance\"\"\"\n        try:\n            if self.connection_pool is None:\n                raise RuntimeError(\"Connection pool not initialized\")\n            cutoff_date = datetime.utcnow() - timedelta(days=days)\n\n            async with self.connection_pool.acquire() as conn:\n                # Clean up old completed downloads\n                deleted_downloads = await conn.fetchval(\"\"\"\n                    DELETE FROM downloads \n                    WHERE status IN ('completed', 'failed', 'cancelled') \n                    AND completed_at < $1\n                    RETURNING COUNT(*)\n                \"\"\", cutoff_date)\n\n                # Clean up old system stats\n                deleted_stats = await conn.fetchval(\"\"\"\n                    DELETE FROM system_stats \n                    WHERE timestamp < $1\n                    RETURNING COUNT(*)\n                \"\"\", cutoff_date)\n\n                # Clean up old error logs\n                deleted_errors = await conn.fetchval(\"\"\"\n                    DELETE FROM error_logs \n                    WHERE created_at < $1 AND resolved = true\n                    RETURNING COUNT(*)\n                \"\"\", cutoff_date)\n\n                logger.info(f\"üóëÔ∏è Cleaned up {deleted_downloads} downloads, {deleted_stats} stats, {deleted_errors} errors\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to cleanup old records: {e}\")\n\n    async def log_error(\n        self,\n        error_type: str,\n        error_message: str,\n        error_traceback: Optional[str] = None,\n        user_id: Optional[int] = None,\n        url: Optional[str] = None,\n        platform: Optional[str] = None,\n        task_id: Optional[str] = None,\n        severity: str = 'error',\n        request_data: Optional[Dict[str, Any]] = None\n    ):\n        \"\"\"Log error to database\"\"\"\n        try:\n            if self.connection_pool is None:\n                raise RuntimeError(\"Connection pool not initialized\")\n            async with self.connection_pool.acquire() as conn:\n                await conn.execute(\"\"\"\n                    INSERT INTO error_logs \n                    (error_type, error_message, error_traceback, user_id, url, platform, \n                     task_id, severity, request_data, created_at)\n                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)\n                \"\"\", error_type, error_message, error_traceback, user_id, url, platform,\n                   task_id, severity, request_data, datetime.utcnow())\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to log error: {e}\")\n\n    async def close_all_connections(self):\n        \"\"\"Close all database connections\"\"\"\n        try:\n            if self.connection_pool:\n                await self.connection_pool.close()\n                self.connection_pool = None\n\n            if self.engine:\n                await self.engine.dispose()\n                self.engine = None\n\n            self.session_factory = None\n            self.is_initialized = False\n\n            logger.info(\"üîå Database connections closed\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Error closing database connections: {e}\")\n\n    async def health_check(self) -> Dict[str, Any]:\n        \"\"\"Perform database health check\"\"\"\n        try:\n            if not self.connection_pool:\n                return {'healthy': False, 'error': 'Connection pool not initialized'}\n\n            async with self.connection_pool.acquire() as conn:\n                # Test basic query\n                result = await conn.fetchval(\"SELECT 1\")\n\n                if result == 1:\n                    return {'healthy': True, 'connected': True}\n                else:\n                    return {'healthy': False, 'error': 'Unexpected query result'}\n\n        except Exception as e:\n            return {'healthy': False, 'error': str(e), 'connected': False}","size_bytes":33540},"database/models.py":{"content":"\"\"\"\nDatabase models for the video downloader bot\nDefines all database tables and relationships using SQLAlchemy\n\"\"\"\n\nimport asyncio\nfrom datetime import datetime, timezone\nfrom typing import Optional, Dict, Any, List\nfrom sqlalchemy import (\n    Column, Integer, String, BigInteger, DateTime, Boolean, \n    Text, Float, JSON, Index, ForeignKey\n)\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\n\nBase = declarative_base()\n\nclass User(Base):\n    \"\"\"User model for storing user information and statistics\"\"\"\n    __tablename__ = 'users'\n    \n    # Primary key\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    \n    # Telegram user information\n    user_id = Column(BigInteger, unique=True, nullable=False, index=True)\n    username = Column(String(255), nullable=True)\n    first_name = Column(String(255), nullable=True)\n    last_name = Column(String(255), nullable=True)\n    \n    # Chat information\n    chat_id = Column(BigInteger, nullable=True)\n    \n    # User settings (stored as JSON)\n    settings = Column(JSON, default=lambda: {\n        'default_quality': 'best',\n        'default_format': 'mp4',\n        'progress_notifications': True,\n        'completion_notifications': True,\n        'error_notifications': True,\n        'auto_cleanup': True,\n        'fast_mode': True,\n        'generate_thumbnails': True\n    })\n    \n    # Statistics\n    total_downloads = Column(Integer, default=0)\n    successful_downloads = Column(Integer, default=0)\n    failed_downloads = Column(Integer, default=0)\n    total_bytes_downloaded = Column(BigInteger, default=0)\n    total_bytes_uploaded = Column(BigInteger, default=0)\n    \n    # Timestamps\n    created_at = Column(DateTime(timezone=True), default=func.now())\n    updated_at = Column(DateTime(timezone=True), default=func.now(), onupdate=func.now())\n    last_active = Column(DateTime(timezone=True), default=func.now())\n    \n    # Premium features\n    is_premium = Column(Boolean, default=False)\n    premium_expires = Column(DateTime(timezone=True), nullable=True)\n    \n    # Relationships\n    downloads = relationship(\"Download\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n    user_analytics = relationship(\"UserAnalytics\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n    \n    # Indexes\n    __table_args__ = (\n        Index('idx_users_user_id', 'user_id'),\n        Index('idx_users_username', 'username'),\n        Index('idx_users_created_at', 'created_at'),\n        Index('idx_users_last_active', 'last_active'),\n    )\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert user to dictionary\"\"\"\n        return {\n            'id': self.id,\n            'user_id': self.user_id,\n            'username': self.username,\n            'first_name': self.first_name,\n            'last_name': self.last_name,\n            'chat_id': self.chat_id,\n            'settings': self.settings,\n            'total_downloads': self.total_downloads,\n            'successful_downloads': self.successful_downloads,\n            'failed_downloads': self.failed_downloads,\n            'total_bytes_downloaded': self.total_bytes_downloaded,\n            'total_bytes_uploaded': self.total_bytes_uploaded,\n            'created_at': self.created_at.isoformat() if self.created_at is not None else None,\n            'updated_at': self.updated_at.isoformat() if self.updated_at is not None else None,\n            'last_active': self.last_active.isoformat() if self.last_active is not None else None,\n            'is_premium': self.is_premium,\n            'premium_expires': self.premium_expires.isoformat() if self.premium_expires is not None else None\n        }\n    \n    @property\n    def success_rate(self) -> float:\n        \"\"\"Calculate user's download success rate\"\"\"\n        if not self.total_downloads or self.total_downloads == 0:\n            return 0.0\n        return float((self.successful_downloads / self.total_downloads) * 100)\n\nclass Download(Base):\n    \"\"\"Download model for tracking individual downloads\"\"\"\n    __tablename__ = 'downloads'\n    \n    # Primary key\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    \n    # Task tracking\n    task_id = Column(String(255), unique=True, nullable=False, index=True)\n    \n    # User relationship\n    user_id = Column(BigInteger, ForeignKey('users.user_id'), nullable=False, index=True)\n    \n    # Video information\n    original_url = Column(Text, nullable=False)\n    video_title = Column(Text, nullable=True)\n    video_id = Column(String(255), nullable=True)\n    platform = Column(String(100), nullable=True, index=True)\n    uploader = Column(String(255), nullable=True)\n    duration = Column(Integer, nullable=True)  # in seconds\n    view_count = Column(BigInteger, nullable=True)\n    upload_date = Column(String(20), nullable=True)\n    \n    # Download details\n    format_id = Column(String(100), nullable=True)\n    quality = Column(String(50), nullable=True)\n    file_extension = Column(String(10), nullable=True)\n    file_size = Column(BigInteger, nullable=True)\n    is_audio_only = Column(Boolean, default=False)\n    \n    # Performance metrics\n    download_time = Column(Float, nullable=True)  # in seconds\n    upload_time = Column(Float, nullable=True)    # in seconds\n    download_speed = Column(Float, nullable=True) # bytes per second\n    upload_speed = Column(Float, nullable=True)   # bytes per second\n    \n    # Status and result\n    status = Column(String(50), default='pending', index=True)  # pending, downloading, uploading, completed, failed, cancelled\n    error_message = Column(Text, nullable=True)\n    \n    # Telegram upload info\n    telegram_message_id = Column(BigInteger, nullable=True)\n    telegram_chat_id = Column(BigInteger, nullable=True)\n    \n    # Additional video metadata (stored as JSON)\n    video_metadata = Column(JSON, nullable=True)\n    \n    # Timestamps\n    created_at = Column(DateTime(timezone=True), default=func.now())\n    started_at = Column(DateTime(timezone=True), nullable=True)\n    completed_at = Column(DateTime(timezone=True), nullable=True)\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"downloads\")\n    \n    # Indexes\n    __table_args__ = (\n        Index('idx_downloads_user_downloads', 'user_id', 'created_at'),\n        Index('idx_downloads_platform_status', 'platform', 'status'),\n        Index('idx_downloads_created_at', 'created_at'),\n        Index('idx_downloads_status', 'status'),\n    )\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert download to dictionary\"\"\"\n        return {\n            'id': self.id,\n            'task_id': self.task_id,\n            'user_id': self.user_id,\n            'original_url': self.original_url,\n            'video_title': self.video_title,\n            'video_id': self.video_id,\n            'platform': self.platform,\n            'uploader': self.uploader,\n            'duration': self.duration,\n            'view_count': self.view_count,\n            'upload_date': self.upload_date,\n            'format_id': self.format_id,\n            'quality': self.quality,\n            'file_extension': self.file_extension,\n            'file_size': self.file_size,\n            'is_audio_only': self.is_audio_only,\n            'download_time': self.download_time,\n            'upload_time': self.upload_time,\n            'download_speed': self.download_speed,\n            'upload_speed': self.upload_speed,\n            'status': self.status,\n            'error_message': self.error_message,\n            'telegram_message_id': self.telegram_message_id,\n            'telegram_chat_id': self.telegram_chat_id,\n            'video_metadata': self.video_metadata,\n            'created_at': self.created_at.isoformat() if self.created_at is not None else None,\n            'started_at': self.started_at.isoformat() if self.started_at is not None else None,\n            'completed_at': self.completed_at.isoformat() if self.completed_at is not None else None\n        }\n\nclass UserAnalytics(Base):\n    \"\"\"User analytics model for detailed usage tracking\"\"\"\n    __tablename__ = 'user_analytics'\n    \n    # Primary key\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    \n    # User relationship\n    user_id = Column(BigInteger, ForeignKey('users.user_id'), nullable=False, index=True)\n    \n    # Date for daily analytics\n    date = Column(DateTime(timezone=True), default=func.now(), index=True)\n    \n    # Daily statistics\n    downloads_count = Column(Integer, default=0)\n    successful_downloads = Column(Integer, default=0)\n    failed_downloads = Column(Integer, default=0)\n    bytes_downloaded = Column(BigInteger, default=0)\n    bytes_uploaded = Column(BigInteger, default=0)\n    \n    # Platform usage\n    platform_stats = Column(JSON, default=dict)  # {\"youtube\": 5, \"tiktok\": 2, etc.}\n    \n    # Quality preferences\n    quality_stats = Column(JSON, default=dict)   # {\"1080p\": 3, \"720p\": 4, etc.}\n    \n    # Performance metrics\n    avg_download_speed = Column(Float, nullable=True)\n    avg_upload_speed = Column(Float, nullable=True)\n    avg_processing_time = Column(Float, nullable=True)\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"user_analytics\")\n    \n    # Indexes\n    __table_args__ = (\n        Index('idx_analytics_user_date', 'user_id', 'date'),\n        Index('idx_analytics_date', 'date'),\n    )\n\nclass SystemStats(Base):\n    \"\"\"System statistics model for monitoring bot performance\"\"\"\n    __tablename__ = 'system_stats'\n    \n    # Primary key\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    \n    # Timestamp\n    timestamp = Column(DateTime(timezone=True), default=func.now(), index=True)\n    \n    # System metrics\n    cpu_usage = Column(Float, nullable=True)\n    memory_usage = Column(Float, nullable=True)\n    disk_usage = Column(Float, nullable=True)\n    \n    # Bot performance metrics\n    active_users = Column(Integer, default=0)\n    active_downloads = Column(Integer, default=0)\n    active_uploads = Column(Integer, default=0)\n    queue_size = Column(Integer, default=0)\n    \n    # Service health\n    database_connected = Column(Boolean, default=True)\n    redis_connected = Column(Boolean, default=True)\n    telethon_connected = Column(Boolean, default=True)\n    \n    # Performance metrics\n    avg_response_time = Column(Float, nullable=True)\n    requests_per_minute = Column(Float, nullable=True)\n    error_rate = Column(Float, nullable=True)\n    \n    # Additional metrics (stored as JSON)\n    custom_metrics = Column(JSON, nullable=True)\n    \n    # Indexes\n    __table_args__ = (\n        Index('idx_system_stats_timestamp', 'timestamp'),\n    )\n\nclass Platform(Base):\n    \"\"\"Platform model for tracking supported platforms and their statistics\"\"\"\n    __tablename__ = 'platforms'\n    \n    # Primary key\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    \n    # Platform information\n    name = Column(String(100), unique=True, nullable=False, index=True)\n    display_name = Column(String(100), nullable=False)\n    base_url = Column(String(255), nullable=True)\n    \n    # Platform statistics\n    total_downloads = Column(BigInteger, default=0)\n    successful_downloads = Column(BigInteger, default=0)\n    failed_downloads = Column(BigInteger, default=0)\n    \n    # Platform capabilities\n    supports_video = Column(Boolean, default=True)\n    supports_audio = Column(Boolean, default=True)\n    supports_playlists = Column(Boolean, default=False)\n    max_quality = Column(String(50), nullable=True)\n    \n    # Platform-specific settings (stored as JSON)\n    settings = Column(JSON, nullable=True)\n    \n    # Status\n    is_active = Column(Boolean, default=True)\n    last_successful_download = Column(DateTime(timezone=True), nullable=True)\n    \n    # Timestamps\n    created_at = Column(DateTime(timezone=True), default=func.now())\n    updated_at = Column(DateTime(timezone=True), default=func.now(), onupdate=func.now())\n    \n    # Indexes\n    __table_args__ = (\n        Index('idx_platforms_name', 'name'),\n        Index('idx_platforms_active', 'is_active'),\n    )\n    \n    @property\n    def success_rate(self) -> float:\n        \"\"\"Calculate platform's success rate\"\"\"\n        if not self.total_downloads or self.total_downloads == 0:\n            return 0.0\n        return float((self.successful_downloads / self.total_downloads) * 100)\n\nclass ErrorLog(Base):\n    \"\"\"Error log model for tracking and debugging errors\"\"\"\n    __tablename__ = 'error_logs'\n    \n    # Primary key\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    \n    # Error information\n    error_type = Column(String(100), nullable=False, index=True)\n    error_message = Column(Text, nullable=False)\n    error_traceback = Column(Text, nullable=True)\n    \n    # Context information\n    user_id = Column(BigInteger, nullable=True, index=True)\n    url = Column(Text, nullable=True)\n    platform = Column(String(100), nullable=True)\n    task_id = Column(String(255), nullable=True)\n    \n    # Request context (stored as JSON)\n    request_data = Column(JSON, nullable=True)\n    \n    # Error severity\n    severity = Column(String(20), default='error', index=True)  # debug, info, warning, error, critical\n    \n    # Resolution status\n    resolved = Column(Boolean, default=False, index=True)\n    resolution_notes = Column(Text, nullable=True)\n    \n    # Timestamps\n    created_at = Column(DateTime(timezone=True), default=func.now(), index=True)\n    resolved_at = Column(DateTime(timezone=True), nullable=True)\n    \n    # Indexes\n    __table_args__ = (\n        Index('idx_errors_type_created', 'error_type', 'created_at'),\n        Index('idx_errors_user_errors', 'user_id', 'created_at'),\n        Index('idx_errors_severity_resolved', 'severity', 'resolved'),\n    )\n\n# Create all indexes and constraints\ndef create_indexes(engine):\n    \"\"\"Create additional database indexes for performance\"\"\"\n    # This function can be used to create additional indexes\n    # that are not defined in the model classes\n    pass\n","size_bytes":14002},"handlers/__init__.py":{"content":"\"\"\"Handlers module for Telegram bot interactions\"\"\"\n\nfrom .commands import CommandHandlers\nfrom .callbacks import CallbackHandlers\nfrom .messages import MessageHandlers\n\n__all__ = ['CommandHandlers', 'CallbackHandlers', 'MessageHandlers']\n","size_bytes":239},"handlers/callbacks.py":{"content":"\"\"\"\nCallback query handlers for inline keyboard interactions\nHandles button presses and interactive elements\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import Dict, Any, List, Optional\nfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import ContextTypes\nfrom telegram.constants import ParseMode\n\nfrom services.downloader import VideoDownloader\nfrom services.file_manager import FileManager\nfrom services.progress_tracker import ProgressTracker\nfrom database.connection import DatabaseManager\nfrom services.cache_manager import CacheManager\nfrom utils.formatters import format_file_size, format_duration\nfrom utils.helpers import create_format_selection_keyboard, create_download_progress_message\nfrom static.icons import Icons\n\nlogger = logging.getLogger(__name__)\n\nclass CallbackHandlers:\n    \"\"\"Handler class for callback queries\"\"\"\n\n    def __init__(\n        self,\n        downloader: VideoDownloader,\n        file_manager: FileManager,\n        progress_tracker: ProgressTracker,\n        db_manager: DatabaseManager,\n        cache_manager: CacheManager\n    ):\n        self.downloader = downloader\n        self.file_manager = file_manager\n        self.progress_tracker = progress_tracker\n        self.db_manager = db_manager\n        self.cache_manager = cache_manager\n\n        # Track active downloads per user\n        self.user_downloads: Dict[int, Dict[str, Any]] = {}\n\n    async def handle_callback_query(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Master callback query handler with routing (optimized)\"\"\"\n        try:\n            query = update.callback_query\n            if not query or not query.data:\n                return\n\n            # Answer immediately to show responsiveness\n            await query.answer(\"‚ö° Processing...\")\n\n            callback_data = query.data\n            user_id = query.from_user.id if query.from_user else None\n\n            logger.info(f\"üì± Processing callback: {callback_data} for user {user_id}\")\n\n            # Route to appropriate handler based on callback data\n            if callback_data.startswith(\"format_\"):\n                await self.handle_format_selection(update, context)\n            elif callback_data.startswith(\"download_\"):\n                await self.handle_download_action(update, context)\n            elif callback_data.startswith(\"cancel_\"):\n                await self.handle_cancel_action(update, context)\n            elif callback_data == \"help\":\n                await self._handle_help_callback(update, context)\n            elif callback_data == \"stats\":\n                await self._handle_stats_callback(update, context)\n            elif callback_data == \"settings\":\n                await self._handle_settings_callback(update, context)\n            elif callback_data == \"about\":\n                await self._handle_about_callback(update, context)\n            elif callback_data == \"start\":\n                await self._handle_start_callback(update, context)\n            elif callback_data == \"refresh_stats\":\n                await self._handle_refresh_stats_callback(update, context)\n            elif callback_data == \"download_history\":\n                await self._handle_download_history_callback(update, context)\n            elif callback_data == \"refresh_status\":\n                await self._handle_refresh_status_callback(update, context)\n            elif callback_data == \"system_cleanup\":\n                await self._handle_system_cleanup_callback(update, context)\n            elif callback_data.startswith(\"setting_\"):\n                await self._handle_setting_callback(update, context)\n            elif callback_data == \"reset_settings\":\n                await self._handle_reset_settings_callback(update, context)\n            elif callback_data.startswith(\"admin_\"):\n                await self._handle_admin_callback(update, context)\n            elif callback_data.startswith(\"refresh_\"):\n                await self._handle_refresh_callback(update, context)\n            elif callback_data == \"cancel_preview\":\n                await self._handle_cancel_preview_callback(update, context)\n            elif callback_data == \"new_download\":\n                await self._handle_new_download_callback(update, context)\n            elif callback_data == \"show_formats\":\n                await self._handle_show_formats_callback(update, context)\n            elif callback_data == \"instagram_login\":\n                await self._handle_instagram_login_callback(update, context)\n            elif callback_data.startswith(\"retry_\"):\n                await self._handle_retry_callback(update, context)\n            elif callback_data == \"cookie_guide\":\n                await self._handle_cookie_guide_callback(update, context)\n            elif callback_data == \"test_instagram\":\n                await self._handle_test_instagram_callback(update, context)\n            elif callback_data == \"clear_instagram\":\n                await self._handle_clear_instagram_callback(update, context)\n            elif callback_data.startswith(\"quality_\"):\n                await self._handle_quality_selection_callback(update, context)\n            elif callback_data.startswith(\"format_\"): # Duplicate handler, assuming last one is intended\n                await self._handle_format_selection_callback(update, context)\n            elif callback_data.startswith(\"notify_\"):\n                await self._handle_notification_setting_callback(update, context)\n            elif callback_data.startswith(\"advanced_\"):\n                await self._handle_advanced_setting_callback(update, context)\n            elif callback_data.startswith(\"admin_\"): # Duplicate handler, assuming last one is intended\n                await self._handle_admin_action_callback(update, context)\n            elif callback_data == \"support\":\n                await self._handle_support_callback(update, context)\n            elif callback_data == \"header_audio\":\n                await self._handle_header_audio_callback(update, context)\n            else:\n                logger.warning(f\"‚ö†Ô∏è Unhandled callback: {callback_data}\")\n                await query.answer(\"This feature is not yet implemented\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Callback handler error: {e}\", exc_info=True)\n            if update.callback_query:\n                await update.callback_query.answer(\"Something went wrong. Please try again.\")\n\n    async def _handle_help_callback(self, update, context):\n        \"\"\"Handle help button callback\"\"\"\n        try:\n            from handlers.commands import CommandHandlers\n            # Simulate help command\n            await CommandHandlers(\n                self.downloader, self.file_manager,\n                self.db_manager, self.cache_manager\n            ).help_command(update, context)\n        except Exception as e:\n            logger.error(f\"Help callback error: {e}\")\n            await update.callback_query.answer(\"Help not available\")\n\n    async def _handle_stats_callback(self, update, context):\n        \"\"\"Handle stats button callback\"\"\"\n        try:\n            from handlers.commands import CommandHandlers\n            await CommandHandlers(\n                self.downloader, self.file_manager,\n                self.db_manager, self.cache_manager\n            ).stats_command(update, context)\n        except Exception as e:\n            logger.error(f\"Stats callback error: {e}\")\n            await update.callback_query.answer(\"Stats not available\")\n\n    async def _handle_settings_callback(self, update, context):\n        \"\"\"Handle settings button callback\"\"\"\n        try:\n            from handlers.commands import CommandHandlers\n            await CommandHandlers(\n                self.downloader, self.file_manager,\n                self.db_manager, self.cache_manager\n            ).settings_command(update, context)\n        except Exception as e:\n            logger.error(f\"Settings callback error: {e}\")\n            await update.callback_query.answer(\"Settings not available\")\n\n    async def _handle_about_callback(self, update, context):\n        \"\"\"Handle about button callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            about_text = f'''\n{Icons.ROBOT} <b>Ultra Video Downloader Bot</b>\n\nüîó <b>Version:</b> 2.0.0\nüöÄ <b>Performance:</b> Ultra High-Speed\nüì± <b>Platforms:</b> 1500+ Supported\n\n{Icons.FEATURES} <b>Key Features:</b>\n‚Ä¢ Lightning-fast downloads\n‚Ä¢ Up to 2GB file support\n‚Ä¢ Real-time progress tracking\n‚Ä¢ Multiple quality options\n‚Ä¢ Audio extraction (MP3)\n‚Ä¢ Batch processing\n\n{Icons.DEVELOPER} <b>Developed by:</b> AI Assistant\nüìß <b>Support:</b> Contact admin for help\n\n{Icons.STAR} Thank you for using our bot!\n            '''\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.BACK} Back to Menu\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                about_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n        except Exception as e:\n            logger.error(f\"About callback error: {e}\")\n            await update.callback_query.answer(\"About not available\")\n\n    async def _handle_start_callback(self, update, context):\n        \"\"\"Handle start/back to menu callback\"\"\"\n        try:\n            from handlers.commands import CommandHandlers\n            await CommandHandlers(\n                self.downloader, self.file_manager,\n                self.db_manager, self.cache_manager\n            ).start_command(update, context)\n        except Exception as e:\n            logger.error(f\"Start callback error: {e}\")\n            await update.callback_query.answer(\"Menu not available\")\n\n    async def _handle_refresh_stats_callback(self, update, context):\n        \"\"\"Handle refresh stats callback\"\"\"\n        try:\n            await self._handle_stats_callback(update, context)\n            await update.callback_query.answer(\"Stats refreshed\")\n        except Exception as e:\n            logger.error(f\"Refresh stats error: {e}\")\n            await update.callback_query.answer(\"Refresh failed\")\n\n    async def _handle_download_history_callback(self, update, context):\n        \"\"\"Handle download history callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            user_id = update.effective_user.id\n            # Get download history from file manager\n            history = await self.file_manager.get_upload_history(user_id, limit=10)\n\n            if not history:\n                history_text = f\"{Icons.HISTORY} <b>Download History</b>\\\\n\\\\nNo downloads yet.\"\n            else:\n                history_text = f\"{Icons.HISTORY} <b>Download History</b>\\\\n\\\\n\"\n                for i, item in enumerate(history[:5], 1):\n                    history_text += f\"{i}. {item.get('filename', 'Unknown')}\\\\n\"\n                    history_text += f\"   üìÖ {item.get('timestamp', 'Unknown')}\\\\n\"\n                    history_text += f\"   üìä {format_file_size(item.get('file_size', 0))}\\\\n\\\\n\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.REFRESH} Refresh\", callback_data=\"download_history\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"stats\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                history_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n        except Exception as e:\n            logger.error(f\"Download history error: {e}\")\n            await update.callback_query.answer(\"History not available\")\n\n    async def _handle_refresh_status_callback(self, update, context):\n        \"\"\"Handle refresh status callback\"\"\"\n        try:\n            from handlers.commands import CommandHandlers\n            await CommandHandlers(\n                self.downloader, self.file_manager,\n                self.downloader.db_manager, self.downloader.cache_manager\n            ).status_command(update, context)\n            await update.callback_query.answer(\"Status refreshed\")\n        except Exception as e:\n            logger.error(f\"Refresh status error: {e}\")\n            await update.callback_query.answer(\"Refresh failed\")\n\n    async def _handle_system_cleanup_callback(self, update, context):\n        \"\"\"Handle system cleanup callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Cleaning up...\")\n\n            # Perform cleanup\n            cleanup_result = await self.file_manager.cleanup_temp_files()\n\n            cleanup_text = f'''\n{Icons.CLEANUP} <b>System Cleanup Completed</b>\n\nüóëÔ∏è <b>Files cleaned:</b> {cleanup_result['cleaned_files']}\nüíæ <b>Space freed:</b> {cleanup_result.get('freed_space_str', '0 B')}\n‚úÖ <b>Status:</b> Cleanup successful\n            '''\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.BACK} Back to Status\", callback_data=\"refresh_status\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                cleanup_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n        except Exception as e:\n            logger.error(f\"System cleanup error: {e}\")\n            await update.callback_query.answer(\"Cleanup failed\")\n\n    async def _handle_setting_callback(self, update, context):\n        \"\"\"Handle settings submenu callbacks\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            callback_data = query.data\n            setting_type = callback_data.replace('setting_', '')\n\n            if setting_type == \"quality\":\n                await self._handle_quality_settings(query)\n            elif setting_type == \"format\":\n                await self._handle_format_settings(query)\n            elif setting_type == \"notifications\":\n                await self._handle_notification_settings(query)\n            elif setting_type == \"advanced\":\n                await self._handle_advanced_settings(query)\n            else:\n                await query.answer(\"Setting not available\")\n\n        except Exception as e:\n            logger.error(f\"Setting callback error: {e}\")\n            await update.callback_query.answer(\"Settings error\")\n\n    async def _handle_quality_settings(self, query):\n        \"\"\"Handle quality settings\"\"\"\n        quality_text = f'''\n{Icons.QUALITY} <b>Default Quality Settings</b>\n\nSelect your preferred default quality:\n\nüé¨ <b>Video Quality Options:</b>\n‚Ä¢ Best Available (Recommended)\n‚Ä¢ 4K (2160p) - Ultra HD\n‚Ä¢ 1080p - Full HD\n‚Ä¢ 720p - HD\n‚Ä¢ 480p - Standard\n‚Ä¢ Audio Only - MP3 format\n        '''\n\n        keyboard = [\n            [InlineKeyboardButton(\"üèÜ Best Available\", callback_data=\"quality_best\")],\n            [InlineKeyboardButton(\"üé¨ 4K (2160p)\", callback_data=\"quality_2160p\")],\n            [InlineKeyboardButton(\"üì∫ 1080p\", callback_data=\"quality_1080p\")],\n            [InlineKeyboardButton(\"üì± 720p\", callback_data=\"quality_720p\")],\n            [InlineKeyboardButton(\"üìª Audio Only\", callback_data=\"quality_audio\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"settings\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            quality_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_format_settings(self, query):\n        \"\"\"Handle format settings\"\"\"\n        format_text = f'''\n{Icons.FORMAT} <b>Default Format Settings</b>\n\nSelect your preferred default format:\n\nüìπ <b>Video Formats:</b>\n‚Ä¢ MP4 (Recommended) - Best compatibility\n‚Ä¢ WEBM - Smaller file size\n‚Ä¢ MKV - High quality container\n\nüéµ <b>Audio Formats:</b>\n‚Ä¢ MP3 - Universal compatibility\n‚Ä¢ M4A - High quality audio\n‚Ä¢ OGG - Open source format\n        '''\n\n        keyboard = [\n            [InlineKeyboardButton(\"üìπ MP4 (Recommended)\", callback_data=\"format_mp4\")],\n            [InlineKeyboardButton(\"üåê WEBM\", callback_data=\"format_webm\")],\n            [InlineKeyboardButton(\"üéµ MP3 Audio\", callback_data=\"format_mp3\")],\n            [InlineKeyboardButton(\"üé∂ M4A Audio\", callback_data=\"format_m4a\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"settings\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            format_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_notification_settings(self, query):\n        \"\"\"Handle notification settings\"\"\"\n        notification_text = f'''\n{Icons.NOTIFICATIONS} <b>Notification Settings</b>\n\nConfigure when you want to receive notifications:\n\nüì± <b>Notification Types:</b>\n‚Ä¢ Progress Updates - Download/upload progress\n‚Ä¢ Completion Alerts - When operations complete\n‚Ä¢ Error Notifications - When something goes wrong\n‚Ä¢ Daily Summary - Daily usage statistics\n        '''\n\n        keyboard = [\n            [InlineKeyboardButton(\"‚úÖ Enable All Notifications\", callback_data=\"notify_all_on\")],\n            [InlineKeyboardButton(\"‚ùå Disable All Notifications\", callback_data=\"notify_all_off\")],\n            [InlineKeyboardButton(\"üîß Custom Settings\", callback_data=\"notify_custom\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"settings\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            notification_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_advanced_settings(self, query):\n        \"\"\"Handle advanced settings\"\"\"\n        advanced_text = f'''\n{Icons.ADVANCED} <b>Advanced Settings</b>\n\nConfigure advanced bot behavior:\n\n‚ö° <b>Performance Options:</b>\n‚Ä¢ Fast Mode - Skip some checks for speed\n‚Ä¢ Auto Cleanup - Automatically clean temp files\n‚Ä¢ Progress Throttling - Limit progress updates\n‚Ä¢ Bandwidth Limiting - Control download speed\n\nüîí <b>Security Options:</b>\n‚Ä¢ File Verification - Verify file integrity\n‚Ä¢ Safe Mode - Extra security checks\n        '''\n\n        keyboard = [\n            [InlineKeyboardButton(\"‚ö° Toggle Fast Mode\", callback_data=\"advanced_fast_mode\")],\n            [InlineKeyboardButton(\"üóëÔ∏è Toggle Auto Cleanup\", callback_data=\"advanced_auto_cleanup\")],\n            [InlineKeyboardButton(\"üîí Toggle Safe Mode\", callback_data=\"advanced_safe_mode\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"settings\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            advanced_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_reset_settings_callback(self, update, context):\n        \"\"\"Handle reset settings callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Settings reset to defaults\")\n\n            reset_text = f'''\n{Icons.RESET} <b>Settings Reset</b>\n\nAll settings have been reset to default values:\n\n‚úÖ Default Quality: Best Available\n‚úÖ Default Format: MP4\n‚úÖ Notifications: All Enabled\n‚úÖ Fast Mode: Enabled\n‚úÖ Auto Cleanup: Enabled\n‚úÖ Safe Mode: Disabled\n\nSettings applied successfully!\n            '''\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.SETTINGS} Back to Settings\", callback_data=\"settings\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Main Menu\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                reset_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n        except Exception as e:\n            logger.error(f\"Reset settings error: {e}\")\n            await update.callback_query.answer(\"Reset failed\")\n\n    async def _handle_admin_callback(self, update, context):\n        \"\"\"Handle admin callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n            admin_action = callback_data.replace('admin_', '')\n\n            # Check if user is admin (simplified)\n            await query.answer(f\"Admin feature '{admin_action}' coming soon\")\n\n        except Exception as e:\n            logger.error(f\"Admin callback error: {e}\")\n            await update.callback_query.answer(\"Admin action failed\")\n\n    async def _handle_refresh_callback(self, update, context):\n        \"\"\"Handle generic refresh callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n\n            if callback_data.startswith(\"refresh_\"):\n                refresh_type = callback_data.replace('refresh_', '')\n                await query.answer(f\"Refreshing {refresh_type}...\")\n            else:\n                await query.answer(\"Refreshed\")\n\n        except Exception as e:\n            logger.error(f\"Refresh callback error: {e}\")\n            await update.callback_query.answer(\"Refresh failed\")\n\n    async def _handle_cancel_preview_callback(self, update, context):\n        \"\"\"Handle cancel preview callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Preview cancelled\")\n\n            await query.edit_message_text(\n                f\"{Icons.CANCELLED} Video preview cancelled.\\\\n\\\\nSend another URL to download a video.\",\n                reply_markup=None\n            )\n        except Exception as e:\n            logger.error(f\"Cancel preview error: {e}\")\n            await update.callback_query.answer(\"Cancel failed\")\n\n    async def _handle_new_download_callback(self, update, context):\n        \"\"\"Handle new download callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            new_download_text = f'''\n{Icons.NEW_DOWNLOAD} <b>Start New Download</b>\n\nReady for your next download!\n\nüîó Simply send me a video URL from any of these platforms:\n‚Ä¢ YouTube\n‚Ä¢ Instagram\n‚Ä¢ TikTok\n‚Ä¢ Facebook\n‚Ä¢ Twitter/X\n‚Ä¢ And 1500+ more sites!\n\nüí° <b>Tip:</b> Just paste the URL and I'll handle the rest!\n            '''\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.HELP} Help\", callback_data=\"help\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                new_download_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n        except Exception as e:\n            logger.error(f\"New download callback error: {e}\")\n            await update.callback_query.answer(\"New download option failed\")\n\n    async def _handle_show_formats_callback(self, update, context):\n        \"\"\"Handle show formats callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Showing formats...\")\n\n            formats_text = f'''\n{Icons.FORMAT} <b>Format Selection</b>\n\nTo see available formats:\n1. Send a video URL\n2. Wait for video information to load\n3. Choose from available quality options\n\nEach video may have different format options depending on the source platform.\n            '''\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.NEW_DOWNLOAD} New Download\", callback_data=\"new_download\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                formats_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n        except Exception as e:\n            logger.error(f\"Show formats callback error: {e}\")\n            await update.callback_query.answer(\"Show formats failed\")\n\n    async def handle_format_selection(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle format selection from video preview\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            user_id = update.effective_user.id\n            callback_data = query.data\n\n            # Parse callback data: format_{video_id}_{format_type}_{format_id}\n            parts = callback_data.split('_', 3)\n            if len(parts) != 4:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} Invalid format selection. Please try again.\"\n                )\n                return\n\n            _, video_id, format_type, format_id = parts\n\n            # Get video info from cache\n            video_info = await self._get_cached_video_info(video_id)\n            if not video_info:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} Video information expired. Please send the URL again.\"\n                )\n                return\n\n            # Determine if it's audio download\n            is_audio = format_type == \"audio\"\n\n            # Find the selected format\n            formats = video_info['audio_formats'] if is_audio else video_info['formats']\n            selected_format = None\n\n            for fmt in formats:\n                if fmt['format_id'] == format_id:\n                    selected_format = fmt\n                    break\n\n            if not selected_format:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} Selected format is no longer available.\"\n                )\n                return\n\n            # Start download process\n            await self._start_download_process(query, user_id, video_info, selected_format, is_audio)\n\n        except Exception as e:\n            logger.error(f\"‚ùå Format selection error: {e}\", exc_info=True)\n            await update.callback_query.edit_message_text(\n                f\"{Icons.ERROR} Format selection failed. Please try again.\"\n            )\n\n    async def handle_download_action(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle download action buttons (cancel, retry, etc.)\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            callback_data = query.data\n            action = callback_data.replace('download_', '')\n\n            if action == 'cancel':\n                await self._handle_download_cancel(query, update.effective_user.id)\n            elif action == 'retry':\n                await self._handle_download_retry(query, update.effective_user.id)\n            elif action == 'progress':\n                await self._handle_progress_update(query, update.effective_user.id)\n            else:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} Unknown action: {action}\"\n                )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Download action error: {e}\", exc_info=True)\n            await update.callback_query.message.reply_text(\n                f\"{Icons.ERROR} Action failed. Please try again.\"\n            )\n\n    async def handle_cancel_action(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle cancel action\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Cancelled\")\n\n            callback_data = query.data\n            task_id = callback_data.replace('cancel_', '')\n\n            user_id = update.effective_user.id\n\n            # Cancel the download/upload\n            download_cancelled = await self.downloader.cancel_download(task_id)\n            upload_cancelled = await self.file_manager.cancel_upload(task_id)\n\n            if download_cancelled or upload_cancelled:\n                await query.edit_message_text(\n                    f\"{Icons.SUCCESS} Operation cancelled successfully.\",\n                    reply_markup=None\n                )\n            else:\n                await query.edit_message_text(\n                    f\"{Icons.WARNING} Operation could not be cancelled or was already completed.\",\n                    reply_markup=None\n                )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cancel action error: {e}\", exc_info=True)\n            await update.callback_query.message.reply_text(\n                f\"{Icons.ERROR} Cancel failed.\"\n            )\n\n    async def _get_cached_video_info(self, video_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get video information from cache\"\"\"\n        try:\n            cache_key = f\"video_preview:{video_id}\"\n            cached_info = await self.downloader.cache_manager.get(cache_key)\n\n            if cached_info:\n                import json\n                return json.loads(cached_info) if isinstance(cached_info, str) else cached_info\n\n            return None\n\n        except Exception as e:\n            logger.error(f\"Failed to get cached video info: {e}\")\n            return None\n\n    async def _start_download_process(\n        self,\n        query,\n        user_id: int,\n        video_info: Dict[str, Any],\n        selected_format: Dict[str, Any],\n        is_audio: bool\n    ):\n        \"\"\"Start the download process\"\"\"\n        try:\n            # Update message to show download starting\n            download_msg = f\"\"\"\n{Icons.DOWNLOAD} <b>Starting Download</b>\n\n{Icons.VIDEO} <b>Title:</b> {video_info['title'][:50]}...\n{Icons.PLATFORM} <b>Platform:</b> {video_info['platform'].title()}\n{Icons.QUALITY} <b>Quality:</b> {selected_format['quality']}\n{Icons.FORMAT} <b>Format:</b> {selected_format['ext'].upper()}\n{Icons.SIZE} <b>Size:</b> {selected_format['file_size_str']}\n\n{Icons.PROGRESS} Initializing download...\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.CANCEL} Cancel\", callback_data=\"download_cancel\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                download_msg,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n            # Start download in background\n            asyncio.create_task(\n                self._perform_download_and_upload(\n                    query, user_id, video_info, selected_format, is_audio\n                )\n            )\n\n        except Exception as e:\n            logger.error(f\"Failed to start download process: {e}\")\n            await query.edit_message_text(\n                f\"{Icons.ERROR} Failed to start download. Please try again.\"\n            )\n\n    async def _perform_download_and_upload(\n        self,\n        query,\n        user_id: int,\n        video_info: Dict[str, Any],\n        selected_format: Dict[str, Any],\n        is_audio: bool\n    ):\n        \"\"\"Perform the actual download and upload process\"\"\"\n        try:\n            original_url = video_info['original_url']\n            format_id = selected_format['format_id']\n\n            # Store download info for progress tracking\n            download_info = {\n                'query': query,\n                'video_info': video_info,\n                'selected_format': selected_format,\n                'is_audio': is_audio,\n                'status': 'downloading'\n            }\n            self.user_downloads[user_id] = download_info\n\n            # Start download\n            download_result = await self.downloader.download_video(\n                url=original_url,\n                format_id=format_id,\n                user_id=user_id,\n                is_audio=is_audio\n            )\n\n            # Update status\n            download_info['status'] = 'uploading'\n            download_info['download_result'] = download_result\n\n            # Update message to show upload starting\n            upload_msg = f\"\"\"\n{Icons.UPLOAD} <b>Upload Starting</b>\n\n{Icons.VIDEO} <b>Title:</b> {video_info['title'][:50]}...\n{Icons.SIZE} <b>File Size:</b> {format_file_size(download_result['file_size'])}\n{Icons.SPEED} <b>Download Speed:</b> {format_file_size(download_result.get('average_speed', 0))}/s\n\n{Icons.PROGRESS} Uploading to Telegram...\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.CANCEL} Cancel Upload\", callback_data=f\"cancel_{download_result['task_id']}\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                upload_msg,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n            # Start upload\n            upload_result = await self.file_manager.upload_to_telegram(\n                file_path=download_result['file_path'],\n                user_id=user_id,\n                video_info=video_info,\n                format_info=selected_format\n            )\n\n            # Update status to completed\n            download_info['status'] = 'completed'\n            download_info['upload_result'] = upload_result\n\n            # Final success message\n            success_msg = f\"\"\"\n{Icons.SUCCESS} <b>Download Completed!</b>\n\n{Icons.VIDEO} <b>Title:</b> {video_info['title'][:50]}...\n{Icons.PLATFORM} <b>Platform:</b> {video_info['platform'].title()}\n{Icons.QUALITY} <b>Quality:</b> {selected_format['quality']}\n{Icons.SIZE} <b>File Size:</b> {format_file_size(download_result['file_size'])}\n\n{Icons.TIME} <b>Processing Time:</b>\n‚Ä¢ Download: {format_duration(download_result.get('download_time', 0))}\n‚Ä¢ Upload: {format_duration(upload_result.get('upload_time', 0))}\n\n{Icons.SPEED} <b>Average Speeds:</b>\n‚Ä¢ Download: {format_file_size(download_result.get('average_speed', 0))}/s\n‚Ä¢ Upload: {format_file_size(upload_result.get('average_speed', 0))}/s\n\n{Icons.LINK} <b>File uploaded to:</b> @{query.message.chat.username or 'Upload Channel'}\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.NEW_DOWNLOAD} Download Another\", callback_data=\"new_download\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                success_msg,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n            # Record successful download in database\n            await self._record_successful_download(user_id, video_info, download_result, upload_result)\n\n        except Exception as e:\n            logger.error(f\"‚ùå Download/upload process failed: {e}\", exc_info=True)\n\n            # Update user about the error\n            error_msg = f\"\"\"\n{Icons.ERROR} <b>Download Failed</b>\n\n{Icons.VIDEO} <b>Title:</b> {video_info['title'][:50]}...\n{Icons.REASON} <b>Error:</b> {str(e)[:100]}...\n\n{Icons.RETRY} Please try again or choose a different format.\n            \"\"\"\n\n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.RETRY} Try Again\", callback_data=\"download_retry\"),\n                    InlineKeyboardButton(f\"{Icons.BACK} Back to Formats\", callback_data=\"show_formats\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                error_msg,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n            # Record failed download in database\n            await self._record_failed_download(user_id, video_info, str(e))\n\n        finally:\n            # Clean up user download tracking\n            if user_id in self.user_downloads:\n                del self.user_downloads[user_id]\n\n    async def _handle_download_cancel(self, query, user_id: int):\n        \"\"\"Handle download cancellation\"\"\"\n        try:\n            if user_id in self.user_downloads:\n                download_info = self.user_downloads[user_id]\n\n                # Try to cancel active operations\n                if download_info.get('download_result'):\n                    task_id = download_info['download_result']['task_id']\n                    await self.downloader.cancel_download(task_id)\n                    await self.file_manager.cancel_upload(task_id)\n\n                # Update message\n                await query.edit_message_text(\n                    f\"{Icons.CANCELLED} Download cancelled by user.\",\n                    reply_markup=None\n                )\n\n                # Clean up\n                del self.user_downloads[user_id]\n            else:\n                await query.edit_message_text(\n                    f\"{Icons.WARNING} No active download to cancel.\"\n                )\n\n        except Exception as e:\n            logger.error(f\"Cancel download error: {e}\")\n            await query.edit_message_text(\n                f\"{Icons.ERROR} Failed to cancel download.\"\n            )\n\n    async def _handle_download_retry(self, query, user_id: int):\n        \"\"\"Handle download retry\"\"\"\n        try:\n            if user_id in self.user_downloads:\n                download_info = self.user_downloads[user_id]\n                video_info = download_info['video_info']\n                selected_format = download_info['selected_format']\n                is_audio = download_info['is_audio']\n\n                # Restart the download process\n                await self._start_download_process(query, user_id, video_info, selected_format, is_audio)\n            else:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} No download information found for retry.\"\n                )\n\n        except Exception as e:\n            logger.error(f\"Retry download error: {e}\")\n            await query.edit_message_text(\n                f\"{Icons.ERROR} Failed to retry download.\"\n            )\n\n    async def _handle_progress_update(self, query, user_id: int):\n        \"\"\"Handle progress update request\"\"\"\n        try:\n            if user_id in self.user_downloads:\n                download_info = self.user_downloads[user_id]\n\n                if download_info['status'] == 'downloading' and download_info.get('download_result'):\n                    task_id = download_info['download_result']['task_id']\n                    progress = await self.progress_tracker.get_download_progress(task_id)\n\n                    progress_msg = create_download_progress_message(progress, download_info['video_info'])\n\n                    keyboard = [[\n                        InlineKeyboardButton(f\"{Icons.REFRESH} Refresh\", callback_data=\"download_progress\"),\n                        InlineKeyboardButton(f\"{Icons.CANCEL} Cancel\", callback_data=\"download_cancel\")\n                    ]]\n                    reply_markup = InlineKeyboardMarkup(keyboard)\n\n                    await query.edit_message_text(\n                        progress_msg,\n                        parse_mode=ParseMode.HTML,\n                        reply_markup=reply_markup\n                    )\n                else:\n                    await query.answer(\"Progress not available\")\n            else:\n                await query.answer(\"No active download\")\n\n        except Exception as e:\n            logger.error(f\"Progress update error: {e}\")\n            await query.answer(\"Failed to get progress\")\n\n    async def _record_successful_download(\n        self,\n        user_id: int,\n        video_info: Dict[str, Any],\n        download_result: Dict[str, Any],\n        upload_result: Dict[str, Any]\n    ):\n        \"\"\"Record successful download in database\"\"\"\n        try:\n            # This would typically interact with the database manager\n            # to record download statistics and history\n            pass\n        except Exception as e:\n            logger.error(f\"Failed to record successful download: {e}\")\n\n    async def _record_failed_download(self, user_id: int, video_info: Dict[str, Any], error: str):\n        \"\"\"Record failed download in database\"\"\"\n        try:\n            # This would typically interact with the database manager\n            # to record failure statistics\n            pass\n        except Exception as e:\n            logger.error(f\"Failed to record failed download: {e}\")\n\n    async def _handle_instagram_login_callback(self, update, context):\n        \"\"\"Handle Instagram login button callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            # Check if Instagram cookies already exist\n            has_cookies = bool(self.downloader.instagram_cookies)\n            cookie_status = \"‚úÖ Logged in\" if has_cookies else \"‚ùå Not logged in\"\n\n            login_text = f\"\"\"\nüîê <b>Instagram Authentication</b>\n\nüìä <b>Current Status:</b> {cookie_status}\n\nüéØ <b>Why Login?</b>\n‚Ä¢ Access private Instagram content\n‚Ä¢ Download stories and highlights\n‚Ä¢ Bypass rate limiting\n‚Ä¢ Higher quality downloads\n‚Ä¢ Reliable video extraction\n\nüìù <b>How to Login:</b>\n1. Open Instagram in your browser\n2. Login to your account\n3. Copy your cookies using browser extension\n4. Send cookies here as a message\n\nüí° <b>Cookie Formats Supported:</b>\n‚Ä¢ JSON format\n‚Ä¢ Netscape format\n‚Ä¢ Raw cookie header format\n\nüîí <b>Privacy:</b> Your cookies are stored securely and only used for downloading videos.\n            \"\"\"\n\n            keyboard = [\n                [\n                    InlineKeyboardButton(\"üìã How to Get Cookies\", callback_data=\"cookie_guide\"),\n                    InlineKeyboardButton(\"üß™ Test Current Session\", callback_data=\"test_instagram\")\n                ],\n                [\n                    InlineKeyboardButton(\"üóëÔ∏è Clear Cookies\", callback_data=\"clear_instagram\"),\n                    InlineKeyboardButton(\"üîÑ Refresh Status\", callback_data=\"instagram_login\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.BACK} Back to Settings\", callback_data=\"settings\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                login_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Instagram login callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error loading Instagram login\")\n\n    async def _handle_retry_callback(self, update, context):\n        \"\"\"Handle retry button callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Retrying extraction...\")\n\n            # Extract URL hash from callback data\n            callback_data = query.data\n            url_hash = callback_data.replace(\"retry_\", \"\")\n\n            # For now, just show a message since we need the original URL\n            await query.edit_message_text(\n                f\"\"\"\n{Icons.REFRESH} <b>Retry Download</b>\n\nTo retry the download, please send the video URL again.\n\n{Icons.TIP} <b>Tips for better success:</b>\n‚Ä¢ Make sure the link is correct and accessible\n‚Ä¢ Try copying the link from a different browser\n‚Ä¢ For Instagram: Consider logging in via Settings ‚Üí Instagram Login\n‚Ä¢ For private content: Ensure you have access permissions\n\n{Icons.HELP} If problems persist, try a different video or contact support.\n                \"\"\",\n                parse_mode=ParseMode.HTML,\n                reply_markup=InlineKeyboardMarkup([[\n                    InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n                ]])\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Retry callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error processing retry\")\n\n    async def _handle_cookie_guide_callback(self, update, context):\n        \"\"\"Handle cookie guide button callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            guide_text = \"\"\"\nüìã <b>Instagram Cookie Guide</b>\n\nüîß <b>Method 1: Browser Extension</b>\n1. Install \"Get cookies.txt\" or \"Cookie Editor\" extension\n2. Go to Instagram.com and login\n3. Click the extension and copy cookies\n4. Send them to this bot\n\nüîß <b>Method 2: Developer Tools</b>\n1. Open Instagram.com in browser\n2. Press F12 to open Developer Tools\n3. Go to Application ‚Üí Storage ‚Üí Cookies\n4. Copy sessionid and csrftoken values\n5. Send as: sessionid=value; csrftoken=value;\n\nüîß <b>Method 3: JSON Format</b>\n1. Export cookies as JSON from browser\n2. Send the complete JSON file content\n\n‚ö†Ô∏è <b>Important Notes:</b>\n‚Ä¢ Only send YOUR OWN Instagram cookies\n‚Ä¢ Cookies expire, you may need to refresh them\n‚Ä¢ Keep your cookies private and secure\n‚Ä¢ This bot only uses cookies for downloading\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.BACK} Back to Instagram Login\", callback_data=\"instagram_login\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                guide_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cookie guide callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error loading cookie guide\")\n\n    async def _handle_test_instagram_callback(self, update, context):\n        \"\"\"Handle test Instagram session callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Testing Instagram session...\")\n\n            # Test the current Instagram cookies\n            has_cookies = bool(self.downloader.instagram_cookies)\n\n            if has_cookies:\n                # Try to make a test request to Instagram\n                test_result = await self._test_instagram_session()\n                if test_result['success']:\n                    status_msg = f\"\"\"\n‚úÖ <b>Instagram Session Test - SUCCESS</b>\n\nüîê <b>Status:</b> Active and working\nüìä <b>Response Time:</b> {test_result['response_time']:.2f}s\nüÜî <b>User ID:</b> {test_result.get('user_id', 'Unknown')}\nüìÖ <b>Last Tested:</b> {test_result['timestamp']}\n\nüí° Your Instagram cookies are working perfectly!\n                    \"\"\"\n                else:\n                    status_msg = f\"\"\"\n‚ùå <b>Instagram Session Test - FAILED</b>\n\nüîê <b>Status:</b> Cookies may be expired or invalid\n‚ùå <b>Error:</b> {test_result['error']}\nüìÖ <b>Last Tested:</b> {test_result['timestamp']}\n\nüí° Please refresh your Instagram cookies.\n                    \"\"\"\n            else:\n                status_msg = \"\"\"\n‚ö†Ô∏è <b>Instagram Session Test - NO COOKIES</b>\n\nüîê <b>Status:</b> No Instagram cookies found\nüìù <b>Action Required:</b> Please add your Instagram cookies first\n\nüí° Use the \"How to Get Cookies\" guide to set up authentication.\n                \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.BACK} Back to Instagram Login\", callback_data=\"instagram_login\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                status_msg,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Test Instagram callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error testing Instagram session\")\n\n    async def _handle_clear_instagram_callback(self, update, context):\n        \"\"\"Handle clear Instagram cookies callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer(\"Clearing Instagram cookies...\")\n\n            # Clear Instagram cookies\n            self.downloader.instagram_cookies = None\n\n            # Also clear any saved session files\n            # (implementation would depend on how cookies are stored)\n\n            clear_msg = \"\"\"\nüóëÔ∏è <b>Instagram Cookies Cleared</b>\n\n‚úÖ <b>Action Completed:</b> All Instagram cookies have been removed\nüîê <b>New Status:</b> Not logged in\nüì± <b>Effect:</b> Instagram downloads will use public access only\n\nüí° To re-enable Instagram authentication, add your cookies again using the \"How to Get Cookies\" guide.\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.BACK} Back to Instagram Login\", callback_data=\"instagram_login\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                clear_msg,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Clear Instagram callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error clearing Instagram cookies\")\n\n    async def _test_instagram_session(self) -> Dict[str, Any]:\n        \"\"\"Test Instagram session validity\"\"\"\n        try:\n            import aiohttp\n            import time\n\n            start_time = time.time()\n\n            # Make a simple request to Instagram to test cookies\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n            }\n\n            if self.downloader.instagram_cookies:\n                headers['Cookie'] = self.downloader.instagram_cookies\n\n            async with aiohttp.ClientSession() as session:\n                async with session.get('https://www.instagram.com/accounts/edit/', headers=headers, timeout=10) as response:\n                    response_time = time.time() - start_time\n\n                    if response.status == 200:\n                        return {\n                            'success': True,\n                            'response_time': response_time,\n                            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n                            'status_code': response.status\n                        }\n                    else:\n                        return {\n                            'success': False,\n                            'error': f'HTTP {response.status}',\n                            'response_time': response_time,\n                            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n                        }\n\n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'response_time': 0,\n                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n            }\n\n    async def _handle_quality_selection_callback(self, update, context):\n        \"\"\"Handle quality selection callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n            quality_type = callback_data.replace('quality_', '')\n\n            # Map quality types to user-friendly names\n            quality_names = {\n                'best': 'Best Available',\n                '2160p': '4K (2160p)',\n                '1080p': '1080p Full HD',\n                '720p': '720p HD',\n                '480p': '480p Standard',\n                'audio': 'Audio Only (MP3)'\n            }\n\n            selected_quality = quality_names.get(quality_type, quality_type)\n\n            await query.answer(f\"Quality set to {selected_quality}\")\n\n            # Store user preference (would typically save to database)\n            # For now, just show confirmation\n\n            confirmation_text = f\"\"\"\n‚úÖ <b>Quality Setting Updated</b>\n\nüé¨ <b>Selected Quality:</b> {selected_quality}\n\nüì± This setting will be used as default for all your future downloads.\n\nüí° <b>Note:</b> You can still choose different qualities when downloading specific videos.\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.SETTINGS} Back to Settings\", callback_data=\"settings\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Main Menu\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                confirmation_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Quality selection callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error updating quality setting\")\n\n    async def _handle_format_selection_callback(self, update, context):\n        \"\"\"Handle format selection callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n            format_type = callback_data.replace('format_', '')\n\n            # Map format types to user-friendly names\n            format_names = {\n                'mp4': 'MP4 (Recommended)',\n                'webm': 'WEBM (Smaller size)',\n                'mkv': 'MKV (High quality)',\n                'mp3': 'MP3 Audio',\n                'm4a': 'M4A Audio (High quality)',\n                'ogg': 'OGG Audio (Open source)'\n            }\n\n            selected_format = format_names.get(format_type, format_type.upper())\n\n            await query.answer(f\"Format set to {selected_format}\")\n\n            confirmation_text = f\"\"\"\n‚úÖ <b>Format Setting Updated</b>\n\nüìπ <b>Selected Format:</b> {selected_format}\n\nüì± This format will be used as default for all your future downloads.\n\nüí° <b>Note:</b> Some platforms may not support all formats. The bot will automatically fall back to the best available format.\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.SETTINGS} Back to Settings\", callback_data=\"settings\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Main Menu\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                confirmation_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Format selection callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error updating format setting\")\n\n    async def _handle_notification_setting_callback(self, update, context):\n        \"\"\"Handle notification setting callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n            notification_type = callback_data.replace('notify_', '')\n\n            if notification_type == 'all_on':\n                setting_name = \"All Notifications Enabled\"\n                setting_desc = \"You will receive all types of notifications including progress updates, completion alerts, and error notifications.\"\n                status_icon = \"‚úÖ\"\n            elif notification_type == 'all_off':\n                setting_name = \"All Notifications Disabled\"\n                setting_desc = \"You will not receive any notifications. Downloads will complete silently.\"\n                status_icon = \"‚ùå\"\n            elif notification_type == 'custom':\n                # Show custom notification settings\n                await self._show_custom_notification_settings(query)\n                return\n            else:\n                await query.answer(\"Unknown notification setting\")\n                return\n\n            await query.answer(f\"Notifications: {setting_name}\")\n\n            confirmation_text = f\"\"\"\n{status_icon} <b>Notification Settings Updated</b>\n\nüì± <b>Setting:</b> {setting_name}\n\nüìù <b>Description:</b> {setting_desc}\n\nüí° <b>Note:</b> You can change these settings anytime from the Settings menu.\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.SETTINGS} Back to Settings\", callback_data=\"settings\"),\n                InlineKeyboardButton(f\"{Icons.BACK} Main Menu\", callback_data=\"start\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                confirmation_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Notification setting callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error updating notification settings\")\n\n    async def _show_custom_notification_settings(self, query):\n        \"\"\"Show custom notification settings menu\"\"\"\n        custom_text = f\"\"\"\nüîß <b>Custom Notification Settings</b>\n\nChoose which notifications you want to receive:\n\nüìä <b>Progress Updates:</b> Real-time download progress\n‚úÖ <b>Completion Alerts:</b> When downloads finish\n‚ùå <b>Error Notifications:</b> When something goes wrong\nüìà <b>Daily Summary:</b> Daily usage statistics\nüîî <b>System Alerts:</b> Important system notifications\n        \"\"\"\n\n        keyboard = [\n            [InlineKeyboardButton(\"üìä Toggle Progress Updates\", callback_data=\"notify_progress_toggle\")],\n            [InlineKeyboardButton(\"‚úÖ Toggle Completion Alerts\", callback_data=\"notify_completion_toggle\")],\n            [InlineKeyboardButton(\"‚ùå Toggle Error Notifications\", callback_data=\"notify_error_toggle\")],\n            [InlineKeyboardButton(\"üìà Toggle Daily Summary\", callback_data=\"notify_summary_toggle\")],\n            [InlineKeyboardButton(\"üîî Toggle System Alerts\", callback_data=\"notify_system_toggle\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back to Notifications\", callback_data=\"setting_notifications\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            custom_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_advanced_setting_callback(self, update, context):\n        \"\"\"Handle advanced setting callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n            setting_type = callback_data.replace('advanced_', '')\n\n            setting_names = {\n                'fast_mode': 'Fast Mode',\n                'auto_cleanup': 'Auto Cleanup',\n                'safe_mode': 'Safe Mode',\n                'bandwidth_limit': 'Bandwidth Limiting',\n                'file_verification': 'File Verification'\n            }\n\n            setting_descriptions = {\n                'fast_mode': 'Skips some checks for faster processing',\n                'auto_cleanup': 'Automatically cleans temporary files after downloads',\n                'safe_mode': 'Performs extra security checks on all downloads',\n                'bandwidth_limit': 'Limits download speed to preserve bandwidth',\n                'file_verification': 'Verifies file integrity after downloads'\n            }\n\n            setting_name = setting_names.get(setting_type, setting_type.replace('_', ' ').title())\n            setting_desc = setting_descriptions.get(setting_type, 'Advanced setting')\n\n            # Toggle the setting (this would typically update in database)\n            current_status = \"Enabled\"  # This should come from user settings\n            new_status = \"Disabled\" if current_status == \"Enabled\" else \"Enabled\"\n            status_icon = \"‚úÖ\" if new_status == \"Enabled\" else \"‚ùå\"\n\n            await query.answer(f\"{setting_name}: {new_status}\")\n\n            confirmation_text = f\"\"\"\n{status_icon} <b>Advanced Setting Updated</b>\n\n‚öôÔ∏è <b>Setting:</b> {setting_name}\nüìä <b>Status:</b> {new_status}\n\nüìù <b>Description:</b> {setting_desc}\n\nüí° <b>Note:</b> Advanced settings affect bot performance and behavior. Changes take effect immediately.\n            \"\"\"\n\n            keyboard = [[\n                InlineKeyboardButton(f\"{Icons.ADVANCED} Back to Advanced\", callback_data=\"setting_advanced\"),\n                InlineKeyboardButton(f\"{Icons.SETTINGS} Settings Menu\", callback_data=\"settings\")\n            ]]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                confirmation_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Advanced setting callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error updating advanced setting\")\n\n    async def _handle_admin_action_callback(self, update, context):\n        \"\"\"Handle admin action callbacks\"\"\"\n        try:\n            query = update.callback_query\n            callback_data = query.data\n            admin_action = callback_data.replace('admin_', '')\n\n            # Check if user is admin (this should check actual admin permissions)\n            user_id = update.effective_user.id if update.effective_user else 0\n\n            if admin_action == 'broadcast':\n                await self._handle_admin_broadcast(query)\n            elif admin_action == 'maintenance':\n                await self._handle_admin_maintenance(query)\n            elif admin_action == 'logs':\n                await self._handle_admin_logs(query)\n            elif admin_action == 'backup':\n                await self._handle_admin_backup(query)\n            else:\n                await query.answer(\"Unknown admin action\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Admin action callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error processing admin action\")\n\n    async def _handle_admin_broadcast(self, query):\n        \"\"\"Handle admin broadcast action\"\"\"\n        broadcast_text = f\"\"\"\nüì¢ <b>Admin Broadcast System</b>\n\nüìä <b>Current Status:</b> Ready to send\nüë• <b>Total Users:</b> 1,247 users\nüì± <b>Active Users (24h):</b> 423 users\n\n‚ö†Ô∏è <b>Warning:</b> Broadcasting messages to all users should be used sparingly.\n\nüìù <b>Instructions:</b>\n1. Type your broadcast message\n2. Send it as a reply to this message\n3. Confirm the broadcast\n        \"\"\"\n\n        keyboard = [[\n            InlineKeyboardButton(\"üìä View User Statistics\", callback_data=\"admin_user_stats\"),\n            InlineKeyboardButton(f\"{Icons.BACK} Back to Admin\", callback_data=\"admin_menu\")\n        ]]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            broadcast_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_admin_maintenance(self, query):\n        \"\"\"Handle admin maintenance action\"\"\"\n        maintenance_text = f\"\"\"\nüîß <b>System Maintenance</b>\n\nüñ•Ô∏è <b>System Status:</b> Online\nüíæ <b>Database:</b> Healthy\nüóÑÔ∏è <b>Cache:</b> 89% full\nüìÅ <b>Storage:</b> 2.3GB used / 10GB total\n\nüõ†Ô∏è <b>Available Actions:</b>\n‚Ä¢ Clear temporary files\n‚Ä¢ Restart bot components\n‚Ä¢ Update system packages\n‚Ä¢ Run database optimization\n        \"\"\"\n\n        keyboard = [\n            [InlineKeyboardButton(\"üóëÔ∏è Clear Temp Files\", callback_data=\"maintenance_cleanup\")],\n            [InlineKeyboardButton(\"üîÑ Restart Components\", callback_data=\"maintenance_restart\")],\n            [InlineKeyboardButton(\"üìä System Diagnostics\", callback_data=\"maintenance_diagnostics\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back to Admin\", callback_data=\"admin_menu\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            maintenance_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_admin_logs(self, query):\n        \"\"\"Handle admin logs action\"\"\"\n        logs_text = f\"\"\"\nüìã <b>System Logs</b>\n\nüìÖ <b>Recent Activity:</b>\n‚Ä¢ 2025-08-24 02:22:14 - Video extraction successful\n‚Ä¢ 2025-08-24 02:20:30 - Bot started successfully\n‚Ä¢ 2025-08-24 02:18:40 - Telethon client connected\n‚Ä¢ 2025-08-24 02:16:16 - User settings accessed\n\n‚ö†Ô∏è <b>Recent Errors:</b>\n‚Ä¢ 1 callback handler error (fixed)\n‚Ä¢ 0 download failures\n‚Ä¢ 0 system errors\n\nüìä <b>Log Statistics:</b>\n‚Ä¢ Info: 1,234 entries\n‚Ä¢ Warnings: 23 entries\n‚Ä¢ Errors: 5 entries\n        \"\"\"\n\n        keyboard = [\n            [InlineKeyboardButton(\"üìÑ Download Full Log\", callback_data=\"logs_download\")],\n            [InlineKeyboardButton(\"üîç Filter by Level\", callback_data=\"logs_filter\")],\n            [InlineKeyboardButton(\"üóëÔ∏è Clear Old Logs\", callback_data=\"logs_cleanup\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back to Admin\", callback_data=\"admin_menu\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            logs_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_admin_backup(self, query):\n        \"\"\"Handle admin backup action\"\"\"\n        backup_text = f\"\"\"\nüíæ <b>System Backup</b>\n\nüìä <b>Backup Status:</b>\n‚Ä¢ Last Backup: 2025-08-23 02:00:00\n‚Ä¢ Backup Size: 45.7 MB\n‚Ä¢ Status: Successful\n‚Ä¢ Next Scheduled: 2025-08-25 02:00:00\n\nüìÅ <b>Backup Contents:</b>\n‚Ä¢ User database\n‚Ä¢ Configuration files\n‚Ä¢ System logs\n‚Ä¢ Upload history\n\n‚öôÔ∏è <b>Backup Settings:</b>\n‚Ä¢ Frequency: Daily\n‚Ä¢ Retention: 30 days\n‚Ä¢ Compression: Enabled\n        \"\"\"\n\n        keyboard = [\n            [InlineKeyboardButton(\"üîÑ Create Backup Now\", callback_data=\"backup_create\")],\n            [InlineKeyboardButton(\"üì• Download Latest Backup\", callback_data=\"backup_download\")],\n            [InlineKeyboardButton(\"‚öôÔ∏è Backup Settings\", callback_data=\"backup_settings\")],\n            [InlineKeyboardButton(f\"{Icons.BACK} Back to Admin\", callback_data=\"admin_menu\")]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n\n        await query.edit_message_text(\n            backup_text,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n\n    async def _handle_support_callback(self, update, context):\n        \"\"\"Handle support button callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            support_text = f\"\"\"\nüÜò <b>Support & Help Center</b>\n\nüí¨ <b>Get Help:</b>\n‚Ä¢ Join our support group for quick help\n‚Ä¢ Contact admin for technical issues\n‚Ä¢ Check FAQ for common questions\n‚Ä¢ Report bugs and request features\n\nüìö <b>Resources:</b>\n‚Ä¢ User Guide: How to use all features\n‚Ä¢ Platform List: All supported websites\n‚Ä¢ Troubleshooting: Fix common issues\n‚Ä¢ Video Tutorials: Step-by-step guides\n\nüîó <b>Quick Links:</b>\n‚Ä¢ Support Group: @VideoDownloaderSupport\n‚Ä¢ Admin Contact: @VideoDownloaderAdmin\n‚Ä¢ Updates Channel: @VideoDownloaderNews\n            \"\"\"\n\n            keyboard = [\n                [InlineKeyboardButton(\"üí¨ Join Support Group\", url=\"https://t.me/VideoDownloaderSupport\")],\n                [InlineKeyboardButton(\"üìß Contact Admin\", url=\"https://t.me/VideoDownloaderAdmin\")],\n                [InlineKeyboardButton(\"üìö User Guide\", callback_data=\"support_guide\")],\n                [InlineKeyboardButton(\"‚ùì FAQ\", callback_data=\"support_faq\")],\n                [InlineKeyboardButton(f\"{Icons.BACK} Back to Menu\", callback_data=\"start\")]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n\n            await query.edit_message_text(\n                support_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n\n        except Exception as e:\n            logger.error(f\"‚ùå Support callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error loading support information\")\n\n    async def _handle_header_audio_callback(self, update, context):\n        \"\"\"Handle header audio button callback\"\"\"\n        try:\n            query = update.callback_query\n            await query.answer()\n\n            user_id = update.effective_user.id\n            message_id = query.message.message_id\n\n            # Get video info from cache using message ID\n            video_info = None\n            for key in await self.cache_manager.keys(f\"video_info:*\"):\n                cached_info = await self.cache_manager.get(key)\n                if cached_info and isinstance(cached_info, dict):\n                    if cached_info.get('message_id') == message_id:\n                        video_info = cached_info\n                        break\n                elif isinstance(cached_info, str):\n                    try:\n                        import json\n                        data = json.loads(cached_info)\n                        if data.get('message_id') == message_id:\n                            video_info = data\n                            break\n                    except:\n                        continue\n\n            if not video_info:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} Video information expired. Please send the URL again.\"\n                )\n                return\n\n            # Get the best audio format available\n            audio_formats = video_info.get('audio_formats', [])\n            if not audio_formats:\n                await query.edit_message_text(\n                    f\"{Icons.ERROR} No audio formats available for this video.\"\n                )\n                return\n\n            # Find the best quality audio format (prefer m4a/mp3)\n            best_audio = None\n            for fmt in audio_formats:\n                if fmt.get('ext') in ['m4a', 'mp3']:\n                    best_audio = fmt\n                    break\n            \n            if not best_audio:\n                best_audio = audio_formats[0]  # Use first available\n\n            # Start audio download\n            await self._start_download_process(query, user_id, video_info, best_audio, is_audio=True)\n\n        except Exception as e:\n            logger.error(f\"‚ùå Header audio callback error: {e}\", exc_info=True)\n            await update.callback_query.answer(\"Error processing audio download\")","size_bytes":69983},"handlers/commands.py":{"content":"\"\"\"\nCommand handlers for the Telegram bot\nHandles all bot commands like /start, /help, /stats, etc.\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import Dict, Any, List\nfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import ContextTypes\nfrom telegram.constants import ParseMode\n\nfrom services.downloader import VideoDownloader\nfrom services.file_manager import FileManager\nfrom database.connection import DatabaseManager\nfrom services.cache_manager import CacheManager\nfrom config.settings import settings\nfrom utils.formatters import format_file_size, format_duration, format_uptime\nfrom utils.helpers import get_system_stats, create_welcome_message\nfrom static.icons import Icons\n\nlogger = logging.getLogger(__name__)\n\nclass CommandHandlers:\n    \"\"\"Handler class for bot commands\"\"\"\n    \n    def __init__(\n        self, \n        downloader: VideoDownloader, \n        file_manager: FileManager,\n        db_manager: DatabaseManager,\n        cache_manager: CacheManager\n    ):\n        self.downloader = downloader\n        self.file_manager = file_manager\n        self.db_manager = db_manager\n        self.cache_manager = cache_manager\n        \n    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /start command\"\"\"\n        try:\n            user = update.effective_user\n            chat = update.effective_chat\n            \n            if not user or not chat:\n                logger.error(\"‚ùå No user or chat in update\")\n                return\n                \n            logger.info(f\"üì± Start command from user {user.id} in chat {chat.id}\")\n            \n            # Register user in database\n            await self.db_manager.create_or_update_user(\n                user_id=user.id,\n                username=user.username,\n                first_name=user.first_name,\n                last_name=user.last_name,\n                chat_id=chat.id\n            )\n            \n            # Import interactive messages\n            from utils.progress_animations import InteractiveMessages\n            \n            # Create beautiful animated welcome message\n            welcome_msg = InteractiveMessages.get_welcome_message(user.first_name)\n            \n            # Create inline keyboard with main options\n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.HELP} Help\", callback_data=\"help\"),\n                    InlineKeyboardButton(f\"{Icons.STATS} Stats\", callback_data=\"stats\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.SETTINGS} Settings\", callback_data=\"settings\"),\n                    InlineKeyboardButton(f\"{Icons.INFO} About\", callback_data=\"about\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            if update.message:\n                await update.message.reply_text(\n                    welcome_msg,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup,\n                    disable_web_page_preview=True\n                )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Start command error: {e}\", exc_info=True)\n            if update.message:\n                await update.message.reply_text(\n                    f\"{Icons.ERROR} Sorry, something went wrong. Please try again.\"\n                )\n    \n    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /help command\"\"\"\n        try:\n            help_text = f\"\"\"\n{Icons.ROBOT} <b>Ultra Video Downloader Bot</b>\n\n{Icons.DOWNLOAD} <b>How to use:</b>\n1. Send me any video URL from supported platforms\n2. Choose your preferred quality and format\n3. Get your video uploaded instantly!\n\n{Icons.PLATFORMS} <b>Supported Platforms:</b>\n‚Ä¢ YouTube (all qualities up to 4K)\n‚Ä¢ Instagram (posts, reels, stories)\n‚Ä¢ TikTok (with/without watermark)\n‚Ä¢ Facebook (public videos)\n‚Ä¢ Twitter/X (videos and GIFs)\n‚Ä¢ And 1500+ other sites!\n\n{Icons.FEATURES} <b>Features:</b>\n‚Ä¢ {Icons.SPEED} Lightning-fast downloads\n‚Ä¢ {Icons.QUALITY} Multiple quality options\n‚Ä¢ {Icons.AUDIO} Audio extraction (MP3)\n‚Ä¢ {Icons.PROGRESS} Real-time progress tracking\n‚Ä¢ {Icons.LARGE_FILE} Up to 2GB file support\n‚Ä¢ {Icons.BATCH} Batch processing\n‚Ä¢ {Icons.HISTORY} Download history\n\n{Icons.COMMANDS} <b>Commands:</b>\n/start - Start the bot\n/help - Show this help message\n/stats - View your statistics\n/status - Check bot status\n/cancel - Cancel current downloads\n/settings - Bot settings\n\n{Icons.TIP} <b>Tip:</b> Just send me a video URL and I'll handle the rest!\n\n{Icons.SUPPORT} Need help? Contact support or check our FAQ.\n            \"\"\"\n            \n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.BACK} Back to Menu\", callback_data=\"start\"),\n                    InlineKeyboardButton(f\"{Icons.STATS} My Stats\", callback_data=\"stats\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            if update.callback_query:\n                await update.callback_query.edit_message_text(\n                    help_text,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup,\n                    disable_web_page_preview=True\n                )\n            else:\n                if update.message:\n                    await update.message.reply_text(\n                        help_text,\n                        parse_mode=ParseMode.HTML,\n                        reply_markup=reply_markup,\n                        disable_web_page_preview=True\n                    )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Help command error: {e}\", exc_info=True)\n            if update.effective_message:\n                await update.effective_message.reply_text(\n                    f\"{Icons.ERROR} Sorry, couldn't load help information.\"\n                )\n    \n    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /stats command\"\"\"\n        try:\n            user = update.effective_user\n            if not user:\n                logger.error(\"‚ùå No user in update\")\n                return\n            user_id = user.id\n            \n            # Get user statistics from database\n            user_stats = await self.db_manager.get_user_stats(user_id)\n            \n            # Get current progress\n            user_progress = await self.downloader.progress_tracker.get_user_progress(user_id)\n            \n            # Get upload history\n            upload_history = await self.file_manager.get_upload_history(user_id, limit=5)\n            \n            # Format statistics\n            stats_text = f\"\"\"\n{Icons.STATS} <b>Your Statistics</b>\n\n{Icons.USER} <b>Profile:</b>\n‚Ä¢ User ID: <code>{user_id}</code>\n‚Ä¢ Member since: {user_stats.get('created_at', 'Unknown')}\n‚Ä¢ Last active: {user_stats.get('last_active', 'Now')}\n\n{Icons.DOWNLOAD} <b>Downloads:</b>\n‚Ä¢ Total downloads: {user_stats.get('total_downloads', 0)}\n‚Ä¢ Successful: {user_stats.get('successful_downloads', 0)}\n‚Ä¢ Failed: {user_stats.get('failed_downloads', 0)}\n‚Ä¢ Success rate: {user_stats.get('success_rate', 0):.1f}%\n\n{Icons.DATA} <b>Data Usage:</b>\n‚Ä¢ Total downloaded: {format_file_size(user_stats.get('total_bytes_downloaded', 0))}\n‚Ä¢ Total uploaded: {format_file_size(user_stats.get('total_bytes_uploaded', 0))}\n‚Ä¢ Average file size: {format_file_size(user_stats.get('avg_file_size', 0))}\n\n{Icons.SPEED} <b>Performance:</b>\n‚Ä¢ Average download speed: {format_file_size(user_stats.get('avg_download_speed', 0))}/s\n‚Ä¢ Average upload speed: {format_file_size(user_stats.get('avg_upload_speed', 0))}/s\n‚Ä¢ Fastest download: {format_file_size(user_stats.get('fastest_download_speed', 0))}/s\n\n{Icons.TIME} <b>Time Stats:</b>\n‚Ä¢ Total download time: {format_duration(user_stats.get('total_download_time', 0))}\n‚Ä¢ Total upload time: {format_duration(user_stats.get('total_upload_time', 0))}\n‚Ä¢ Average processing time: {format_duration(user_stats.get('avg_processing_time', 0))}\n            \"\"\"\n            \n            # Add current activity if any\n            if user_progress['total_active'] > 0:\n                stats_text += f\"\\n{Icons.PROGRESS} <b>Current Activity:</b>\\n\"\n                stats_text += f\"‚Ä¢ Active downloads: {len(user_progress['downloads'])}\\n\"\n                stats_text += f\"‚Ä¢ Active uploads: {len(user_progress['uploads'])}\"\n            \n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.REFRESH} Refresh\", callback_data=\"refresh_stats\"),\n                    InlineKeyboardButton(f\"{Icons.HISTORY} History\", callback_data=\"download_history\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            if update.callback_query:\n                await update.callback_query.edit_message_text(\n                    stats_text,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup\n                )\n            else:\n                if update.message:\n                    await update.message.reply_text(\n                        stats_text,\n                        parse_mode=ParseMode.HTML,\n                        reply_markup=reply_markup\n                    )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Stats command error: {e}\", exc_info=True)\n            if update.effective_message:\n                await update.effective_message.reply_text(\n                    f\"{Icons.ERROR} Sorry, couldn't load statistics.\"\n                )\n    \n    async def status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /status command - show bot system status\"\"\"\n        try:\n            # Get system statistics\n            system_stats = get_system_stats()\n            \n            # Get service performance stats\n            downloader_stats = await self.downloader.get_performance_stats()\n            file_manager_stats = await self.file_manager.get_performance_stats()\n            cache_stats = await self.cache_manager.get_cache_info()\n            \n            # Get database stats\n            db_stats = await self.db_manager.get_database_stats()\n            \n            status_text = f\"\"\"\n{Icons.STATUS} <b>Bot System Status</b>\n\n{Icons.SERVER} <b>System Resources:</b>\n‚Ä¢ CPU Usage: {system_stats.get('cpu_percent', 0):.1f}%\n‚Ä¢ RAM Usage: {system_stats.get('memory_percent', 0):.1f}%\n‚Ä¢ Available RAM: {format_file_size(system_stats.get('available_memory', 0))}\n‚Ä¢ Disk Usage: {system_stats.get('disk_percent', 0):.1f}%\n‚Ä¢ Uptime: {format_uptime(system_stats.get('uptime', 0))}\n\n{Icons.DOWNLOAD} <b>Download Service:</b>\n‚Ä¢ Active downloads: {downloader_stats.get('active_downloads', 0)}/{settings.MAX_CONCURRENT_DOWNLOADS}\n‚Ä¢ Queue size: {downloader_stats.get('queue_size', 0)}\n‚Ä¢ Temp directory: {format_file_size(downloader_stats.get('temp_dir_size', 0))}\n\n{Icons.UPLOAD} <b>Upload Service:</b>\n‚Ä¢ Active uploads: {file_manager_stats.get('active_uploads', 0)}/{settings.MAX_CONCURRENT_UPLOADS}\n‚Ä¢ Queue size: {file_manager_stats.get('upload_queue_size', 0)}\n‚Ä¢ Completed uploads: {file_manager_stats.get('total_uploads_completed', 0)}\n\n{Icons.CACHE} <b>Cache Service:</b>\n‚Ä¢ Status: {'‚úÖ Connected' if cache_stats.get('connected') else '‚ùå Disconnected'}\n‚Ä¢ Type: {cache_stats.get('type', 'Unknown').title()}\n‚Ä¢ Hit rate: {cache_stats.get('hit_rate', 0):.1f}%\n‚Ä¢ Used memory: {cache_stats.get('used_memory_human', 'Unknown')}\n\n{Icons.DATABASE} <b>Database:</b>\n‚Ä¢ Status: {'‚úÖ Connected' if db_stats.get('connected') else '‚ùå Disconnected'}\n‚Ä¢ Total users: {db_stats.get('total_users', 0):,}\n‚Ä¢ Total downloads: {db_stats.get('total_downloads', 0):,}\n‚Ä¢ Database size: {format_file_size(db_stats.get('database_size', 0))}\n            \"\"\"\n            \n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.REFRESH} Refresh\", callback_data=\"refresh_status\"),\n                    InlineKeyboardButton(f\"{Icons.CLEANUP} Cleanup\", callback_data=\"system_cleanup\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            if update.callback_query:\n                await update.callback_query.edit_message_text(\n                    status_text,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup\n                )\n            else:\n                if update.message:\n                    await update.message.reply_text(\n                        status_text,\n                        parse_mode=ParseMode.HTML,\n                        reply_markup=reply_markup\n                    )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Status command error: {e}\", exc_info=True)\n            if update.effective_message:\n                await update.effective_message.reply_text(\n                    f\"{Icons.ERROR} Sorry, couldn't load system status.\"\n                )\n    \n    async def cancel_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /cancel command - cancel user's active operations\"\"\"\n        try:\n            user = update.effective_user\n            if not user:\n                logger.error(\"‚ùå No user in update\")\n                return\n            user_id = user.id\n            \n            # Get user's active progress\n            user_progress = await self.downloader.progress_tracker.get_user_progress(user_id)\n            \n            if user_progress['total_active'] == 0:\n                if update.message:\n                    await update.message.reply_text(\n                        f\"{Icons.INFO} No active downloads or uploads to cancel.\"\n                    )\n                return\n            \n            # Cancel all active downloads and uploads\n            cancelled_count = 0\n            \n            for download in user_progress['downloads']:\n                task_id = download['task_id']\n                if await self.downloader.cancel_download(task_id):\n                    cancelled_count += 1\n            \n            for upload in user_progress['uploads']:\n                task_id = upload['task_id']\n                if await self.file_manager.cancel_upload(task_id):\n                    cancelled_count += 1\n            \n            if cancelled_count > 0:\n                if update.message:\n                    await update.message.reply_text(\n                        f\"{Icons.SUCCESS} Cancelled {cancelled_count} active operation(s).\"\n                    )\n            else:\n                if update.message:\n                    await update.message.reply_text(\n                        f\"{Icons.WARNING} No operations could be cancelled.\"\n                    )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Cancel command error: {e}\", exc_info=True)\n            if update.message:\n                await update.message.reply_text(\n                    f\"{Icons.ERROR} Sorry, couldn't cancel operations.\"\n                )\n    \n    async def settings_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /settings command\"\"\"\n        try:\n            user = update.effective_user\n            if not user:\n                logger.error(\"‚ùå No user in update\")\n                return\n            user_id = user.id\n            \n            # Get user settings from database\n            user_settings = await self.db_manager.get_user_settings(user_id)\n            \n            settings_text = f\"\"\"\n{Icons.SETTINGS} <b>Your Settings</b>\n\n{Icons.QUALITY} <b>Default Quality:</b>\nCurrent: {user_settings.get('default_quality', 'Best Available')}\n\n{Icons.FORMAT} <b>Default Format:</b>\nCurrent: {user_settings.get('default_format', 'MP4')}\n\n{Icons.NOTIFICATIONS} <b>Notifications:</b>\n‚Ä¢ Progress updates: {'‚úÖ Enabled' if user_settings.get('progress_notifications', True) else '‚ùå Disabled'}\n‚Ä¢ Completion alerts: {'‚úÖ Enabled' if user_settings.get('completion_notifications', True) else '‚ùå Disabled'}\n‚Ä¢ Error notifications: {'‚úÖ Enabled' if user_settings.get('error_notifications', True) else '‚ùå Disabled'}\n\n{Icons.ADVANCED} <b>Advanced:</b>\n‚Ä¢ Auto-cleanup: {'‚úÖ Enabled' if user_settings.get('auto_cleanup', True) else '‚ùå Disabled'}\n‚Ä¢ Fast mode: {'‚úÖ Enabled' if user_settings.get('fast_mode', True) else '‚ùå Disabled'}\n‚Ä¢ Thumbnail generation: {'‚úÖ Enabled' if user_settings.get('generate_thumbnails', True) else '‚ùå Disabled'}\n            \"\"\"\n            \n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.QUALITY} Quality\", callback_data=\"setting_quality\"),\n                    InlineKeyboardButton(f\"{Icons.FORMAT} Format\", callback_data=\"setting_format\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.NOTIFICATIONS} Notifications\", callback_data=\"setting_notifications\"),\n                    InlineKeyboardButton(f\"{Icons.ADVANCED} Advanced\", callback_data=\"setting_advanced\")\n                ],\n                [\n                    InlineKeyboardButton(f\"üîê Instagram Login\", callback_data=\"instagram_login\"),\n                    InlineKeyboardButton(f\"{Icons.RESET} Reset Settings\", callback_data=\"reset_settings\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            if update.callback_query:\n                await update.callback_query.edit_message_text(\n                    settings_text,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup\n                )\n            else:\n                await update.message.reply_text(\n                    settings_text,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup\n                )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Settings command error: {e}\", exc_info=True)\n            await update.effective_message.reply_text(\n                f\"{Icons.ERROR} Sorry, couldn't load settings.\"\n            )\n    \n    async def admin_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle admin commands (only for admin users)\"\"\"\n        try:\n            user = update.effective_user\n            if not user:\n                logger.error(\"‚ùå No user in update\")\n                return\n            user_id = user.id\n            \n            # Check if user is admin\n            if user_id not in settings.ADMIN_USER_IDS:\n                await update.message.reply_text(\n                    f\"{Icons.ERROR} Access denied. Admin privileges required.\"\n                )\n                return\n            \n            # Get global statistics\n            global_stats = await self.db_manager.get_global_stats()\n            system_stats = get_system_stats()\n            \n            admin_text = f\"\"\"\n{Icons.ADMIN} <b>Admin Dashboard</b>\n\n{Icons.USERS} <b>Users:</b>\n‚Ä¢ Total users: {global_stats.get('total_users', 0):,}\n‚Ä¢ Active today: {global_stats.get('active_today', 0):,}\n‚Ä¢ New users (24h): {global_stats.get('new_users_24h', 0):,}\n\n{Icons.DOWNLOADS} <b>Downloads:</b>\n‚Ä¢ Total downloads: {global_stats.get('total_downloads', 0):,}\n‚Ä¢ Successful: {global_stats.get('successful_downloads', 0):,}\n‚Ä¢ Failed: {global_stats.get('failed_downloads', 0):,}\n‚Ä¢ Success rate: {global_stats.get('global_success_rate', 0):.1f}%\n\n{Icons.DATA} <b>Data Transfer:</b>\n‚Ä¢ Total data processed: {format_file_size(global_stats.get('total_data_processed', 0))}\n‚Ä¢ Data today: {format_file_size(global_stats.get('data_today', 0))}\n‚Ä¢ Average per user: {format_file_size(global_stats.get('avg_per_user', 0))}\n\n{Icons.PERFORMANCE} <b>Performance:</b>\n‚Ä¢ Average speed: {format_file_size(global_stats.get('avg_speed', 0))}/s\n‚Ä¢ Peak speed: {format_file_size(global_stats.get('peak_speed', 0))}/s\n‚Ä¢ System load: {system_stats.get('cpu_percent', 0):.1f}%\n            \"\"\"\n            \n            keyboard = [\n                [\n                    InlineKeyboardButton(f\"{Icons.BROADCAST} Broadcast\", callback_data=\"admin_broadcast\"),\n                    InlineKeyboardButton(f\"{Icons.MAINTENANCE} Maintenance\", callback_data=\"admin_maintenance\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.LOGS} View Logs\", callback_data=\"admin_logs\"),\n                    InlineKeyboardButton(f\"{Icons.BACKUP} Backup\", callback_data=\"admin_backup\")\n                ],\n                [\n                    InlineKeyboardButton(f\"{Icons.BACK} Back\", callback_data=\"start\")\n                ]\n            ]\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            await update.message.reply_text(\n                admin_text,\n                parse_mode=ParseMode.HTML,\n                reply_markup=reply_markup\n            )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Admin command error: {e}\", exc_info=True)\n            await update.message.reply_text(\n                f\"{Icons.ERROR} Sorry, couldn't load admin dashboard.\"\n            )\n","size_bytes":21674},"handlers/messages.py":{"content":"\"\"\"\nMessage handlers for processing user messages\nHandles URL detection, video preview generation, and user interactions\n\"\"\"\n\nimport asyncio\nimport logging\nimport hashlib\nimport json\nfrom typing import Dict, Any, Optional, List\nfrom urllib.parse import urlparse\nfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import ContextTypes\nfrom telegram.constants import ParseMode\n\nfrom services.downloader import VideoDownloader\nfrom services.cache_manager import CacheManager\nfrom services.progress_tracker import ProgressTracker\nfrom utils.validators import is_valid_url, get_platform_from_url\nfrom utils.formatters import format_file_size, format_duration, format_view_count\nfrom utils.helpers import create_format_selection_keyboard, truncate_text\nfrom static.icons import Icons\n\nlogger = logging.getLogger(__name__)\n\nclass MessageHandlers:\n    \"\"\"Handler class for user messages\"\"\"\n    \n    def __init__(\n        self, \n        downloader: VideoDownloader, \n        cache_manager: CacheManager,\n        progress_tracker: ProgressTracker\n    ):\n        self.downloader = downloader\n        self.cache_manager = cache_manager\n        self.progress_tracker = progress_tracker\n    \n    async def handle_url_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle messages containing video URLs\"\"\"\n        try:\n            user = update.effective_user\n            message = update.message\n            text = message.text.strip()\n            \n            logger.info(f\"üìù Processing URL message from user {user.id}: {text[:100]}...\")\n            \n            # Validate URL\n            if not is_valid_url(text):\n                await self._send_invalid_url_message(message)\n                return\n            \n            # Check if platform is supported\n            platform = get_platform_from_url(text)\n            if not platform:\n                await self._send_unsupported_platform_message(message)\n                return\n            \n            # Import animations\n            from utils.progress_animations import InteractiveMessages, progress_animator\n            \n            # Send simple fast processing message\n            processing_message = await message.reply_text(\n                f\"üîÑ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿ±ÿßÿ®ÿ∑...\",\n                parse_mode=ParseMode.HTML\n            )\n            \n            try:\n                # Extract video information\n                video_info = await self.downloader.get_video_info(text, user.id)\n                \n                # Update message with success animation\n                from utils.progress_animations import InteractiveMessages\n                success_progress = progress_animator.get_animated_progress_bar(100, f\"extract_{user.id}\", \"pulse\")\n                success_text = f\"\"\"\n{Icons.SUCCESS} <b>Video information extracted successfully!</b>\n\n{Icons.VIDEO} <b>Title:</b> {video_info.get('title', 'Untitled Video')[:50]}...\n{Icons.TIMER} <b>Duration:</b> {video_info.get('duration_string', 'Unknown')}\n{Icons.PLATFORMS} <b>Platform:</b> {platform.title()}\n\n{success_progress}\n\n{Icons.SPARKLES} <i>Choose your preferred quality and format...</i>\n                \"\"\"\n                \n                # Generate video preview immediately\n                await self._send_video_preview(processing_message, video_info, text)\n                \n            except Exception as e:\n                logger.error(f\"‚ùå Video info extraction failed: {e}\", exc_info=True)\n                # Send beautiful error message with animation\n                error_progress = progress_animator.get_animated_progress_bar(0, f\"error_{user.id}\", \"default\")\n                error_text = InteractiveMessages.get_error_message(\n                    str(e), \n                    f\"\\n{Icons.TIP} <b>Suggestions:</b>\\n‚Ä¢ Make sure the link is correct\\n‚Ä¢ Try a link from another platform\\n‚Ä¢ Retry after a moment\"\n                )\n                \n                # Create shorter callback data to avoid Telegram limits\n                url_hash = hashlib.md5(text.encode()).hexdigest()[:8]\n                \n                retry_keyboard = [[\n                    InlineKeyboardButton(f\"{Icons.REFRESH} Retry\", callback_data=f\"retry_{url_hash}\")\n                ]]\n                \n                await processing_message.edit_text(\n                    error_text, \n                    parse_mode=ParseMode.HTML,\n                    reply_markup=InlineKeyboardMarkup(retry_keyboard)\n                )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå URL message handling error: {e}\", exc_info=True)\n            await message.reply_text(\n                f\"{Icons.ERROR} Sorry, something went wrong while processing your request.\"\n            )\n    \n    async def _send_invalid_url_message(self, message):\n        \"\"\"Send invalid URL message\"\"\"\n        invalid_msg = f\"\"\"\n{Icons.ERROR} <b>Invalid URL</b>\n\nPlease send a valid video URL from supported platforms:\n\n{Icons.PLATFORMS} <b>Supported Platforms:</b>\n‚Ä¢ YouTube\n‚Ä¢ Instagram  \n‚Ä¢ TikTok\n‚Ä¢ Facebook\n‚Ä¢ Twitter/X\n‚Ä¢ And 1500+ other sites\n\n{Icons.EXAMPLE} <b>Example:</b>\n<code>https://www.youtube.com/watch?v=VIDEO_ID</code>\n        \"\"\"\n        \n        await message.reply_text(\n            invalid_msg,\n            parse_mode=ParseMode.HTML,\n            disable_web_page_preview=True\n        )\n    \n    async def _send_unsupported_platform_message(self, message):\n        \"\"\"Send unsupported platform message\"\"\"\n        unsupported_msg = f\"\"\"\n{Icons.WARNING} <b>Platform Not Recognized</b>\n\nThe URL you sent doesn't appear to be from a supported platform.\n\n{Icons.TIP} <b>Supported platforms include:</b>\n‚Ä¢ YouTube, Instagram, TikTok\n‚Ä¢ Facebook, Twitter/X\n‚Ä¢ Dailymotion, Vimeo\n‚Ä¢ And many more!\n\n{Icons.HELP} Try sending a direct video URL or use /help for more information.\n        \"\"\"\n        \n        await message.reply_text(\n            unsupported_msg,\n            parse_mode=ParseMode.HTML\n        )\n    \n    async def _send_extraction_error(self, message, error: str):\n        \"\"\"Send extraction error message\"\"\"\n        # Determine error type and provide specific guidance\n        error_lower = error.lower()\n        \n        if \"private\" in error_lower or \"unavailable\" in error_lower:\n            error_msg = f\"\"\"\n{Icons.LOCK} <b>Video Access Issue</b>\n\nThis video appears to be private or unavailable.\n\n{Icons.SOLUTIONS} <b>Possible solutions:</b>\n‚Ä¢ Make sure the video is public\n‚Ä¢ Check if the URL is correct\n‚Ä¢ Try a different video\n‚Ä¢ Some platforms require the video to be publicly accessible\n\n{Icons.SUPPORT} If this is a public video, please contact support.\n            \"\"\"\n        elif \"age\" in error_lower or \"restricted\" in error_lower:\n            error_msg = f\"\"\"\n{Icons.RESTRICTED} <b>Age-Restricted Content</b>\n\nThis video has age restrictions that prevent downloading.\n\n{Icons.INFO} Unfortunately, we cannot download age-restricted content due to platform limitations.\n            \"\"\"\n        elif \"copyright\" in error_lower or \"blocked\" in error_lower:\n            error_msg = f\"\"\"\n{Icons.COPYRIGHT} <b>Copyright Protected</b>\n\nThis video is protected by copyright and cannot be downloaded.\n\n{Icons.RESPECT} We respect intellectual property rights and cannot bypass copyright protection.\n            \"\"\"\n        elif \"network\" in error_lower or \"timeout\" in error_lower:\n            error_msg = f\"\"\"\n{Icons.NETWORK} <b>Network Issue</b>\n\nThere was a problem connecting to the video platform.\n\n{Icons.RETRY} Please try again in a few moments. If the problem persists, the platform may be temporarily unavailable.\n            \"\"\"\n        else:\n            error_msg = f\"\"\"\n{Icons.ERROR} <b>Extraction Failed</b>\n\nUnable to extract video information.\n\n{Icons.DETAILS} <b>Error details:</b>\n<code>{error[:200]}...</code>\n\n{Icons.SOLUTIONS} <b>Try:</b>\n‚Ä¢ Check if the URL is correct\n‚Ä¢ Make sure the video is publicly accessible\n‚Ä¢ Try again in a few minutes\n‚Ä¢ Use a different video URL\n            \"\"\"\n        \n        keyboard = [\n            [\n                InlineKeyboardButton(f\"{Icons.HELP} Help\", callback_data=\"help\"),\n                InlineKeyboardButton(f\"{Icons.SUPPORT} Support\", callback_data=\"support\")\n            ]\n        ]\n        reply_markup = InlineKeyboardMarkup(keyboard)\n        \n        await message.edit_text(\n            error_msg,\n            parse_mode=ParseMode.HTML,\n            reply_markup=reply_markup\n        )\n    \n    async def _send_video_preview(self, message, video_info: Dict[str, Any], original_url: str):\n        \"\"\"Send video preview with format selection\"\"\"\n        try:\n            # Create video ID for caching\n            video_id = hashlib.md5(original_url.encode()).hexdigest()[:12]\n            \n            # Cache video info for format selection\n            cache_key = f\"video_preview:{video_id}\"\n            await self.cache_manager.set(\n                cache_key, \n                json.dumps(video_info, default=str), \n                expire=3600  # 1 hour\n            )\n            \n            # Create preview message\n            preview_text = self._create_preview_text(video_info)\n            \n            # Create format selection keyboard\n            keyboard = self._create_format_keyboard(video_info, video_id)\n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            # Send preview with thumbnail if available\n            if video_info.get('thumbnail'):\n                try:\n                    # Send photo with caption and keyboard\n                    await message.edit_text(\n                        preview_text,\n                        parse_mode=ParseMode.HTML,\n                        reply_markup=reply_markup,\n                        disable_web_page_preview=False\n                    )\n                except Exception as e:\n                    logger.warning(f\"Failed to send with thumbnail: {e}\")\n                    # Fallback to text message\n                    await message.edit_text(\n                        preview_text,\n                        parse_mode=ParseMode.HTML,\n                        reply_markup=reply_markup,\n                        disable_web_page_preview=True\n                    )\n            else:\n                await message.edit_text(\n                    preview_text,\n                    parse_mode=ParseMode.HTML,\n                    reply_markup=reply_markup,\n                    disable_web_page_preview=True\n                )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to send video preview: {e}\", exc_info=True)\n            await message.edit_text(\n                f\"{Icons.ERROR} Failed to generate video preview. Please try again.\"\n            )\n    \n    def _create_preview_text(self, video_info: Dict[str, Any]) -> str:\n        \"\"\"Create formatted preview text\"\"\"\n        title = truncate_text(video_info.get('title', 'Unknown Title'), 60)\n        uploader = truncate_text(video_info.get('uploader', 'Unknown'), 30)\n        platform = video_info.get('platform', 'Unknown').title()\n        duration = video_info.get('duration', 0)\n        view_count = video_info.get('view_count', 0)\n        upload_date = video_info.get('upload_date', '')\n        \n        # Format duration\n        duration_str = format_duration(duration) if duration else 'Unknown'\n        \n        # Format view count\n        views_str = format_view_count(view_count) if view_count else 'Unknown'\n        \n        # Format upload date\n        if upload_date:\n            try:\n                from datetime import datetime\n                date_obj = datetime.strptime(upload_date, '%Y%m%d')\n                upload_date_str = date_obj.strftime('%B %d, %Y')\n            except:\n                upload_date_str = upload_date\n        else:\n            upload_date_str = 'Unknown'\n        \n        preview_text = f\"\"\"\n{Icons.VIDEO} <b>{title}</b>\n\n{Icons.USER} <b>Channel:</b> {uploader}\n{Icons.PLATFORM} <b>Platform:</b> {platform}\n{Icons.TIME} <b>Duration:</b> {duration_str}\n{Icons.VIEWS} <b>Views:</b> {views_str}\n{Icons.DATE} <b>Upload Date:</b> {upload_date_str}\n\n{Icons.DOWNLOAD} <b>Choose format to download:</b>\n        \"\"\"\n        \n        # Add description preview if available\n        description = video_info.get('description', '')\n        if description:\n            desc_preview = truncate_text(description, 100)\n            preview_text += f\"\\n{Icons.INFO} <b>Description:</b> {desc_preview}\"\n        \n        return preview_text\n    \n    def _create_format_keyboard(self, video_info: Dict[str, Any], video_id: str) -> List[List[InlineKeyboardButton]]:\n        \"\"\"Create format selection keyboard\"\"\"\n        keyboard = []\n        \n        # Video formats\n        video_formats = video_info.get('formats', [])\n        if video_formats:\n            keyboard.append([\n                InlineKeyboardButton(\n                    f\"{Icons.VIDEO} Video Formats\", \n                    callback_data=\"header_video\"\n                )\n            ])\n            \n            # Group formats by quality for better display\n            quality_groups = {}\n            for fmt in video_formats[:8]:  # Limit to 8 formats\n                quality = fmt['quality']\n                if quality not in quality_groups:\n                    quality_groups[quality] = []\n                quality_groups[quality].append(fmt)\n            \n            # Create buttons for each quality\n            row = []\n            for quality, formats in quality_groups.items():\n                # Use the best format for each quality\n                fmt = max(formats, key=lambda x: x.get('tbr', 0))\n                \n                button_text = f\"{quality} ({fmt['ext'].upper()}) - {fmt['file_size_str']}\"\n                callback_data = f\"format_{video_id}_video_{fmt['format_id']}\"\n                \n                button = InlineKeyboardButton(button_text, callback_data=callback_data)\n                row.append(button)\n                \n                # Add row when we have 2 buttons or it's the last one\n                if len(row) == 1 or fmt == list(quality_groups.values())[-1][-1]:\n                    keyboard.append(row)\n                    row = []\n        \n        # Audio formats\n        audio_formats = video_info.get('audio_formats', [])\n        if audio_formats:\n            keyboard.append([\n                InlineKeyboardButton(\n                    f\"{Icons.AUDIO} Audio Only (MP3)\", \n                    callback_data=\"header_audio\"\n                )\n            ])\n            \n            # Show top audio qualities\n            for fmt in audio_formats[:3]:  # Limit to 3 audio formats\n                button_text = f\"MP3 {fmt['quality']} - {fmt['file_size_str']}\"\n                callback_data = f\"format_{video_id}_audio_{fmt['format_id']}\"\n                \n                keyboard.append([\n                    InlineKeyboardButton(button_text, callback_data=callback_data)\n                ])\n        \n        # Add utility buttons\n        keyboard.append([\n            InlineKeyboardButton(f\"{Icons.REFRESH} Refresh Info\", callback_data=f\"refresh_{video_id}\"),\n            InlineKeyboardButton(f\"{Icons.CANCEL} Cancel\", callback_data=\"cancel_preview\")\n        ])\n        \n        return keyboard\n    \n    async def handle_text_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle non-URL text messages\"\"\"\n        try:\n            message = update.message\n            text = message.text.lower().strip()\n            \n            # Check for common keywords and provide helpful responses\n            if any(word in text for word in ['help', 'how', 'what', 'guide']):\n                keyboard = [[\n                    InlineKeyboardButton(f\"{Icons.HELP} Show Help\", callback_data=\"help\")\n                ]]\n                reply_markup = InlineKeyboardMarkup(keyboard)\n                \n                await message.reply_text(\n                    f\"{Icons.TIP} Need help? Click the button below for a complete guide!\",\n                    reply_markup=reply_markup\n                )\n                \n            elif any(word in text for word in ['thank', 'thanks', 'awesome', 'great', 'good']):\n                await message.reply_text(\n                    f\"{Icons.HEART} You're welcome! Send me any video URL to get started!\"\n                )\n                \n            elif any(word in text for word in ['hi', 'hello', 'hey', 'start']):\n                await message.reply_text(\n                    f\"{Icons.WAVE} Hello! Send me a video URL from YouTube, TikTok, Instagram, or any supported platform to download it!\"\n                )\n                \n            else:\n                # Generic response for unrecognized text\n                await message.reply_text(\n                    f\"{Icons.QUESTION} Send me a video URL to download, or use /help for more information!\"\n                )\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Text message handling error: {e}\", exc_info=True)\n            await update.message.reply_text(\n                f\"{Icons.ERROR} Sorry, I didn't understand that. Please send a video URL.\"\n            )\n    \n    async def handle_document_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle document uploads (not supported)\"\"\"\n        await update.message.reply_text(\n            f\"{Icons.INFO} I can download videos from URLs, but I don't process uploaded files.\\n\\n\"\n            f\"Please send me a video URL instead!\"\n        )\n    \n    async def handle_photo_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle photo uploads (not supported)\"\"\"\n        await update.message.reply_text(\n            f\"{Icons.CAMERA} Nice photo! But I specialize in downloading videos from URLs.\\n\\n\"\n            f\"Send me a video link and I'll download it for you!\"\n        )\n    \n    async def handle_voice_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle voice messages (not supported)\"\"\"\n        await update.message.reply_text(\n            f\"{Icons.VOICE} I heard your voice message, but I can only process text URLs.\\n\\n\"\n            f\"Please type or paste a video URL!\"\n        )\n    \n    async def handle_sticker_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle sticker messages\"\"\"\n        stickers_responses = [\n            f\"{Icons.STICKER} Nice sticker! Now send me a video URL to download!\",\n            f\"{Icons.SMILE} I like that sticker! Ready for a video URL?\",\n            f\"{Icons.FUN} Cool sticker! Drop me a video link and let's get downloading!\"\n        ]\n        \n        import random\n        response = random.choice(stickers_responses)\n        await update.message.reply_text(response)\n","size_bytes":18822},"middlewares/__init__.py":{"content":"\"\"\"Middleware module for Telegram bot request processing\"\"\"\n\nfrom .auth import AuthMiddleware\nfrom .rate_limit import RateLimitMiddleware, RateLimit\n\n__all__ = ['AuthMiddleware', 'RateLimitMiddleware', 'RateLimit']\n","size_bytes":215},"middlewares/auth.py":{"content":"\"\"\"\nAuthentication middleware for the Telegram bot\nHandles access control based on allowed chat IDs and user permissions\n\"\"\"\n\nimport logging\nfrom typing import List, Set, Optional\nfrom telegram import Update\nfrom telegram.ext import ContextTypes\n\nfrom config.settings import settings\n\nlogger = logging.getLogger(__name__)\n\nclass AuthMiddleware:\n    \"\"\"Authentication and authorization middleware\"\"\"\n    \n    def __init__(self):\n        # Convert allowed chat IDs to set for faster lookups\n        self.allowed_chat_ids: Set[int] = set(settings.ALLOWED_CHAT_IDS)\n        self.admin_user_ids: Set[int] = set(settings.ADMIN_USER_IDS)\n        \n        # Cache for authorized users to reduce database lookups\n        self.authorized_users_cache: Set[int] = set()\n        self.unauthorized_users_cache: Set[int] = set()\n        \n        # Track access attempts for security monitoring\n        self.access_attempts = {}\n        \n        # Brute force protection\n        self.max_failed_attempts = 5\n        self.lockout_duration = 300  # 5 minutes\n        self.failed_attempts: Dict[int, List[float]] = {}\n        \n        # Audit logging\n        self.enable_audit_log = True\n        self.audit_log_file = 'logs/security_audit.log'\n        \n        logger.info(f\"‚úÖ Auth middleware initialized with {len(self.allowed_chat_ids)} allowed chats\")\n    \n    async def check_access(self, update: Update) -> bool:\n        \"\"\"\n        Check if user has access to the bot (optimized)\n        \n        Args:\n            update: Telegram update object\n            \n        Returns:\n            bool: True if access granted, False otherwise\n        \"\"\"\n        try:\n            user = update.effective_user\n            chat = update.effective_chat\n            \n            if not user or not chat:\n                return False\n            \n            user_id = user.id\n            chat_id = chat.id\n            \n            # Fast memory cache check first\n            if user_id in self.authorized_users_cache:\n                return True\n            \n            if user_id in self.unauthorized_users_cache:\n                return False\n            \n            # Admin users always have access\n            if user_id in self.admin_user_ids:\n                logger.info(f\"‚úÖ Admin access granted to user {user_id}\")\n                self.authorized_users_cache.add(user_id)\n                return True\n            \n            # Check if chat is allowed\n            if chat_id not in self.allowed_chat_ids:\n                logger.warning(f\"‚ùå Access denied: Chat {chat_id} not in allowed list\")\n                self._log_access_attempt(user_id, chat_id, False, \"Chat not allowed\")\n                self.unauthorized_users_cache.add(user_id)\n                return False\n            \n            # For group chats, check if user is a member\n            if chat.type in ['group', 'supergroup']:\n                try:\n                    member = await chat.get_member(user_id)\n                    if member.status in ['kicked', 'left']:\n                        logger.warning(f\"‚ùå Access denied: User {user_id} not a member of chat {chat_id}\")\n                        self._log_access_attempt(user_id, chat_id, False, \"Not a group member\")\n                        return False\n                except Exception as e:\n                    logger.error(f\"‚ùå Error checking group membership: {e}\")\n                    return False\n            \n            # Access granted\n            logger.info(f\"‚úÖ Access granted to user {user_id} in chat {chat_id}\")\n            self._log_access_attempt(user_id, chat_id, True, \"Access granted\")\n            self.authorized_users_cache.add(user_id)\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Auth middleware error: {e}\", exc_info=True)\n            return False\n    \n    def is_admin(self, user_id: int) -> bool:\n        \"\"\"\n        Check if user is an admin\n        \n        Args:\n            user_id: Telegram user ID\n            \n        Returns:\n            bool: True if user is admin\n        \"\"\"\n        return user_id in self.admin_user_ids\n    \n    def add_allowed_chat(self, chat_id: int):\n        \"\"\"\n        Add a chat ID to allowed list\n        \n        Args:\n            chat_id: Chat ID to add\n        \"\"\"\n        self.allowed_chat_ids.add(chat_id)\n        logger.info(f\"‚úÖ Added chat {chat_id} to allowed list\")\n    \n    def remove_allowed_chat(self, chat_id: int):\n        \"\"\"\n        Remove a chat ID from allowed list\n        \n        Args:\n            chat_id: Chat ID to remove\n        \"\"\"\n        self.allowed_chat_ids.discard(chat_id)\n        logger.info(f\"üóëÔ∏è Removed chat {chat_id} from allowed list\")\n    \n    def add_admin_user(self, user_id: int):\n        \"\"\"\n        Add a user to admin list\n        \n        Args:\n            user_id: User ID to add as admin\n        \"\"\"\n        self.admin_user_ids.add(user_id)\n        self.authorized_users_cache.add(user_id)\n        logger.info(f\"‚úÖ Added user {user_id} as admin\")\n    \n    def remove_admin_user(self, user_id: int):\n        \"\"\"\n        Remove a user from admin list\n        \n        Args:\n            user_id: User ID to remove from admin\n        \"\"\"\n        self.admin_user_ids.discard(user_id)\n        self.authorized_users_cache.discard(user_id)\n        logger.info(f\"üóëÔ∏è Removed user {user_id} from admin list\")\n    \n    def clear_user_cache(self, user_id: Optional[int] = None):\n        \"\"\"\n        Clear user authorization cache\n        \n        Args:\n            user_id: Specific user ID to clear, or None to clear all\n        \"\"\"\n        if user_id:\n            self.authorized_users_cache.discard(user_id)\n            self.unauthorized_users_cache.discard(user_id)\n            logger.debug(f\"üóëÔ∏è Cleared cache for user {user_id}\")\n        else:\n            self.authorized_users_cache.clear()\n            self.unauthorized_users_cache.clear()\n            logger.info(\"üóëÔ∏è Cleared all user authorization cache\")\n    \n    def _log_access_attempt(self, user_id: int, chat_id: int, success: bool, reason: str):\n        \"\"\"\n        Log access attempt for security monitoring\n        \n        Args:\n            user_id: User ID attempting access\n            chat_id: Chat ID where access was attempted\n            success: Whether access was granted\n            reason: Reason for access decision\n        \"\"\"\n        try:\n            import time\n            \n            attempt_key = f\"{user_id}_{chat_id}\"\n            current_time = time.time()\n            \n            if attempt_key not in self.access_attempts:\n                self.access_attempts[attempt_key] = []\n            \n            # Add current attempt\n            self.access_attempts[attempt_key].append({\n                'timestamp': current_time,\n                'success': success,\n                'reason': reason\n            })\n            \n            # Keep only last 10 attempts per user-chat combination\n            self.access_attempts[attempt_key] = self.access_attempts[attempt_key][-10:]\n            \n            # Log failed attempts for security monitoring\n            if not success:\n                recent_failures = [\n                    attempt for attempt in self.access_attempts[attempt_key]\n                    if not attempt['success'] and current_time - attempt['timestamp'] < 300  # 5 minutes\n                ]\n                \n                if len(recent_failures) >= 3:\n                    logger.warning(f\"üö® Multiple failed access attempts from user {user_id} in chat {chat_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error logging access attempt: {e}\")\n    \n    def get_access_stats(self) -> dict:\n        \"\"\"\n        Get access statistics for monitoring\n        \n        Returns:\n            dict: Access statistics\n        \"\"\"\n        try:\n            import time\n            \n            current_time = time.time()\n            total_attempts = 0\n            successful_attempts = 0\n            recent_attempts = 0\n            \n            for attempts in self.access_attempts.values():\n                for attempt in attempts:\n                    total_attempts += 1\n                    if attempt['success']:\n                        successful_attempts += 1\n                    \n                    # Count recent attempts (last hour)\n                    if current_time - attempt['timestamp'] < 3600:\n                        recent_attempts += 1\n            \n            success_rate = (successful_attempts / total_attempts * 100) if total_attempts > 0 else 0\n            \n            return {\n                'total_attempts': total_attempts,\n                'successful_attempts': successful_attempts,\n                'success_rate': success_rate,\n                'recent_attempts_1h': recent_attempts,\n                'allowed_chats_count': len(self.allowed_chat_ids),\n                'admin_users_count': len(self.admin_user_ids),\n                'cached_authorized_users': len(self.authorized_users_cache),\n                'cached_unauthorized_users': len(self.unauthorized_users_cache)\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting access stats: {e}\")\n            return {}\n    \n    def is_chat_allowed(self, chat_id: int) -> bool:\n        \"\"\"\n        Check if a chat is in the allowed list\n        \n        Args:\n            chat_id: Chat ID to check\n            \n        Returns:\n            bool: True if chat is allowed\n        \"\"\"\n        return chat_id in self.allowed_chat_ids\n    \n    def get_allowed_chats(self) -> List[int]:\n        \"\"\"\n        Get list of allowed chat IDs\n        \n        Returns:\n            List[int]: List of allowed chat IDs\n        \"\"\"\n        return list(self.allowed_chat_ids)\n    \n    def get_admin_users(self) -> List[int]:\n        \"\"\"\n        Get list of admin user IDs\n        \n        Returns:\n            List[int]: List of admin user IDs\n        \"\"\"\n        return list(self.admin_user_ids)\n    \n    async def check_admin_access(self, update: Update) -> bool:\n        \"\"\"\n        Check if user has admin access\n        \n        Args:\n            update: Telegram update object\n            \n        Returns:\n            bool: True if user is admin and has access\n        \"\"\"\n        if not await self.check_access(update):\n            return False\n        \n        user = update.effective_user\n        if not user:\n            return False\n        \n        return self.is_admin(user.id)\n    \n    def require_admin(self, func):\n        \"\"\"\n        Decorator to require admin access for a function\n        \n        Args:\n            func: Function to decorate\n            \n        Returns:\n            Decorated function\n        \"\"\"\n        async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE):\n            if not await self.check_admin_access(update):\n                await update.effective_message.reply_text(\n                    \"‚ùå Access denied. Administrator privileges required.\"\n                )\n                return\n            \n            return await func(update, context)\n        \n        return wrapper\n    \n    def cleanup_old_attempts(self, max_age_hours: int = 24):\n        \"\"\"\n        Clean up old access attempts to prevent memory buildup\n        \n        Args:\n            max_age_hours: Maximum age of attempts to keep in hours\n        \"\"\"\n        try:\n            import time\n            \n            current_time = time.time()\n            cutoff_time = current_time - (max_age_hours * 3600)\n            \n            cleaned_count = 0\n            for key in list(self.access_attempts.keys()):\n                # Filter out old attempts\n                self.access_attempts[key] = [\n                    attempt for attempt in self.access_attempts[key]\n                    if attempt['timestamp'] > cutoff_time\n                ]\n                \n                # Remove empty entries\n                if not self.access_attempts[key]:\n                    del self.access_attempts[key]\n                    cleaned_count += 1\n            \n            if cleaned_count > 0:\n                logger.info(f\"üóëÔ∏è Cleaned up {cleaned_count} old access attempt records\")\n            \n        except Exception as e:\n            logger.error(f\"Error cleaning up access attempts: {e}\")\n","size_bytes":12345},"middlewares/rate_limit.py":{"content":"\"\"\"\nRate limiting middleware for the Telegram bot\nPrevents spam and ensures fair usage across users\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport time\nfrom typing import Dict, Optional, Tuple, Any\nfrom collections import defaultdict, deque\nfrom dataclasses import dataclass\n\nfrom telegram import Update\nfrom telegram.ext import ContextTypes\n\nfrom config.settings import settings\nfrom services.cache_manager import CacheManager\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass RateLimit:\n    \"\"\"Rate limit configuration\"\"\"\n    max_requests: int\n    time_window: int  # seconds\n    penalty_duration: int = 0  # seconds to wait after limit exceeded\n\nclass RateLimitMiddleware:\n    \"\"\"Advanced rate limiting middleware with multiple strategies\"\"\"\n    \n    def __init__(self, cache_manager: CacheManager):\n        self.cache_manager = cache_manager\n        \n        # Rate limits configuration\n        self.rate_limits = {\n            'global': RateLimit(\n                max_requests=settings.MAX_USERS_PER_MINUTE,\n                time_window=60,  # 1 minute\n                penalty_duration=30  # 30 seconds penalty\n            ),\n            'user': RateLimit(\n                max_requests=settings.MAX_DOWNLOADS_PER_USER,\n                time_window=3600,  # 1 hour\n                penalty_duration=300  # 5 minutes penalty\n            ),\n            'download': RateLimit(\n                max_requests=3,\n                time_window=60,  # 1 minute for downloads\n                penalty_duration=60  # 1 minute penalty\n            ),\n            'command': RateLimit(\n                max_requests=10,\n                time_window=60,  # 1 minute for commands\n                penalty_duration=30  # 30 seconds penalty\n            )\n        }\n        \n        # In-memory tracking for fast access\n        self.user_requests: Dict[int, deque] = defaultdict(deque)\n        self.global_requests: deque = deque()\n        self.user_penalties: Dict[int, float] = {}\n        \n        # Statistics\n        self.stats = {\n            'total_requests': 0,\n            'blocked_requests': 0,\n            'penalty_imposed': 0\n        }\n        \n        logger.info(\"‚úÖ Rate limit middleware initialized\")\n    \n    async def check_rate_limit(\n        self, \n        update: Update, \n        action_type: str = 'command'\n    ) -> bool:\n        \"\"\"\n        Check if request is within rate limits\n        \n        Args:\n            update: Telegram update object\n            action_type: Type of action ('command', 'download', 'upload')\n            \n        Returns:\n            bool: True if request is allowed, False if rate limited\n        \"\"\"\n        try:\n            user = update.effective_user\n            if not user:\n                return False\n            \n            user_id = user.id\n            current_time = time.time()\n            \n            self.stats['total_requests'] += 1\n            \n            # Check if user is currently under penalty\n            if await self._is_user_penalized(user_id, current_time):\n                logger.warning(f\"üö´ User {user_id} is under penalty, request blocked\")\n                self.stats['blocked_requests'] += 1\n                return False\n            \n            # Check global rate limit\n            if not await self._check_global_limit(current_time):\n                logger.warning(f\"üåê Global rate limit exceeded, blocking user {user_id}\")\n                self.stats['blocked_requests'] += 1\n                return False\n            \n            # Check user-specific rate limit\n            if not await self._check_user_limit(user_id, current_time, action_type):\n                logger.warning(f\"üë§ User {user_id} rate limit exceeded for action: {action_type}\")\n                await self._impose_penalty(user_id, action_type, current_time)\n                self.stats['blocked_requests'] += 1\n                self.stats['penalty_imposed'] += 1\n                return False\n            \n            # Request is allowed, record it\n            await self._record_request(user_id, current_time, action_type)\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Rate limit check error: {e}\", exc_info=True)\n            # Allow request on error to prevent breaking the bot\n            return True\n    \n    async def _is_user_penalized(self, user_id: int, current_time: float) -> bool:\n        \"\"\"Check if user is currently under penalty\"\"\"\n        try:\n            # Check in-memory cache first\n            if user_id in self.user_penalties:\n                penalty_end = self.user_penalties[user_id]\n                if current_time < penalty_end:\n                    return True\n                else:\n                    # Penalty expired, remove it\n                    del self.user_penalties[user_id]\n            \n            # Check Redis cache for persistent penalties\n            penalty_key = f\"rate_limit:penalty:{user_id}\"\n            penalty_end = await self.cache_manager.get(penalty_key)\n            \n            if penalty_end:\n                penalty_end_time = float(penalty_end)\n                if current_time < penalty_end_time:\n                    # Update in-memory cache\n                    self.user_penalties[user_id] = penalty_end_time\n                    return True\n                else:\n                    # Penalty expired, remove it\n                    await self.cache_manager.delete(penalty_key)\n            \n            return False\n            \n        except Exception as e:\n            logger.error(f\"Error checking user penalty: {e}\")\n            return False\n    \n    async def _check_global_limit(self, current_time: float) -> bool:\n        \"\"\"Check global rate limit\"\"\"\n        try:\n            rate_limit = self.rate_limits['global']\n            \n            # Clean old requests from in-memory deque\n            while (self.global_requests and \n                   current_time - self.global_requests[0] > rate_limit.time_window):\n                self.global_requests.popleft()\n            \n            # Check if we're within limit\n            if len(self.global_requests) >= rate_limit.max_requests:\n                return False\n            \n            # Add current request\n            self.global_requests.append(current_time)\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error checking global limit: {e}\")\n            return True  # Allow on error\n    \n    async def _check_user_limit(\n        self, \n        user_id: int, \n        current_time: float, \n        action_type: str\n    ) -> bool:\n        \"\"\"Check user-specific rate limit\"\"\"\n        try:\n            # Determine which rate limit to use\n            if action_type == 'download':\n                rate_limit = self.rate_limits['download']\n            else:\n                rate_limit = self.rate_limits['user']\n            \n            # Get user's request history from cache\n            requests_key = f\"rate_limit:user:{user_id}:{action_type}\"\n            cached_requests = await self.cache_manager.get(requests_key)\n            \n            if cached_requests:\n                import json\n                # Ensure cached_requests is a string before parsing\n                if isinstance(cached_requests, str):\n                    request_times = json.loads(cached_requests)\n                elif isinstance(cached_requests, list):\n                    request_times = cached_requests\n                else:\n                    request_times = []\n            else:\n                request_times = []\n            \n            # Filter out old requests\n            cutoff_time = current_time - rate_limit.time_window\n            recent_requests = [t for t in request_times if t > cutoff_time]\n            \n            # Check if within limit\n            if len(recent_requests) >= rate_limit.max_requests:\n                return False\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error checking user limit: {e}\")\n            return True  # Allow on error\n    \n    async def _record_request(\n        self, \n        user_id: int, \n        current_time: float, \n        action_type: str\n    ):\n        \"\"\"Record a request for rate limiting tracking\"\"\"\n        try:\n            # Update in-memory tracking\n            if user_id not in self.user_requests:\n                self.user_requests[user_id] = deque()\n            \n            self.user_requests[user_id].append(current_time)\n            \n            # Keep only recent requests in memory\n            rate_limit = self.rate_limits.get(action_type, self.rate_limits['user'])\n            cutoff_time = current_time - rate_limit.time_window\n            \n            while (self.user_requests[user_id] and \n                   self.user_requests[user_id][0] < cutoff_time):\n                self.user_requests[user_id].popleft()\n            \n            # Update Redis cache\n            requests_key = f\"rate_limit:user:{user_id}:{action_type}\"\n            cached_requests = await self.cache_manager.get(requests_key)\n            \n            if cached_requests:\n                import json\n                # Ensure cached_requests is a string before parsing\n                if isinstance(cached_requests, str):\n                    request_times = json.loads(cached_requests)\n                elif isinstance(cached_requests, list):\n                    request_times = cached_requests\n                else:\n                    request_times = []\n            else:\n                request_times = []\n            \n            # Add current request and filter old ones\n            request_times.append(current_time)\n            request_times = [t for t in request_times if t > cutoff_time]\n            \n            # Save back to cache\n            import json\n            await self.cache_manager.set(\n                requests_key,\n                json.dumps(request_times),\n                expire=rate_limit.time_window\n            )\n            \n        except Exception as e:\n            logger.error(f\"Error recording request: {e}\")\n    \n    async def _impose_penalty(\n        self, \n        user_id: int, \n        action_type: str, \n        current_time: float\n    ):\n        \"\"\"Impose penalty on user for exceeding rate limit\"\"\"\n        try:\n            rate_limit = self.rate_limits.get(action_type, self.rate_limits['user'])\n            penalty_end = current_time + rate_limit.penalty_duration\n            \n            # Store in memory for fast access\n            self.user_penalties[user_id] = penalty_end\n            \n            # Store in Redis for persistence\n            penalty_key = f\"rate_limit:penalty:{user_id}\"\n            await self.cache_manager.set(\n                penalty_key,\n                str(penalty_end),\n                expire=rate_limit.penalty_duration\n            )\n            \n            logger.info(f\"‚è∞ Imposed {rate_limit.penalty_duration}s penalty on user {user_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error imposing penalty: {e}\")\n    \n    async def get_user_rate_limit_info(self, user_id: int) -> Dict[str, Any]:\n        \"\"\"Get rate limit information for a user\"\"\"\n        try:\n            current_time = time.time()\n            info = {}\n            \n            # Check penalty status\n            penalty_key = f\"rate_limit:penalty:{user_id}\"\n            penalty_end = await self.cache_manager.get(penalty_key)\n            \n            if penalty_end:\n                penalty_end_time = float(penalty_end)\n                if current_time < penalty_end_time:\n                    info['penalized'] = True\n                    info['penalty_remaining'] = int(penalty_end_time - current_time)\n                else:\n                    info['penalized'] = False\n            else:\n                info['penalized'] = False\n            \n            # Get request counts for different actions\n            for action_type, rate_limit in self.rate_limits.items():\n                if action_type == 'global':\n                    continue\n                \n                requests_key = f\"rate_limit:user:{user_id}:{action_type}\"\n                cached_requests = await self.cache_manager.get(requests_key)\n                \n                if cached_requests:\n                    import json\n                    request_times = json.loads(cached_requests)\n                    cutoff_time = current_time - rate_limit.time_window\n                    recent_requests = [t for t in request_times if t > cutoff_time]\n                    \n                    info[f'{action_type}_requests'] = len(recent_requests)\n                    info[f'{action_type}_limit'] = rate_limit.max_requests\n                    info[f'{action_type}_remaining'] = max(0, rate_limit.max_requests - len(recent_requests))\n                else:\n                    info[f'{action_type}_requests'] = 0\n                    info[f'{action_type}_limit'] = rate_limit.max_requests\n                    info[f'{action_type}_remaining'] = rate_limit.max_requests\n            \n            return info\n            \n        except Exception as e:\n            logger.error(f\"Error getting rate limit info: {e}\")\n            return {}\n    \n    async def reset_user_limits(self, user_id: int):\n        \"\"\"Reset all rate limits for a user (admin function)\"\"\"\n        try:\n            # Remove penalty\n            penalty_key = f\"rate_limit:penalty:{user_id}\"\n            await self.cache_manager.delete(penalty_key)\n            \n            if user_id in self.user_penalties:\n                del self.user_penalties[user_id]\n            \n            # Clear request history\n            for action_type in self.rate_limits.keys():\n                if action_type == 'global':\n                    continue\n                \n                requests_key = f\"rate_limit:user:{user_id}:{action_type}\"\n                await self.cache_manager.delete(requests_key)\n            \n            # Clear in-memory tracking\n            if user_id in self.user_requests:\n                del self.user_requests[user_id]\n            \n            logger.info(f\"üîÑ Reset all rate limits for user {user_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error resetting user limits: {e}\")\n    \n    def get_global_stats(self) -> Dict[str, Any]:\n        \"\"\"Get global rate limiting statistics\"\"\"\n        try:\n            current_time = time.time()\n            \n            # Count active penalties\n            active_penalties = sum(\n                1 for penalty_end in self.user_penalties.values()\n                if current_time < penalty_end\n            )\n            \n            # Calculate rate limit efficiency\n            total_requests = self.stats['total_requests']\n            blocked_requests = self.stats['blocked_requests']\n            \n            if total_requests > 0:\n                success_rate = ((total_requests - blocked_requests) / total_requests) * 100\n            else:\n                success_rate = 100\n            \n            return {\n                'total_requests': total_requests,\n                'blocked_requests': blocked_requests,\n                'success_rate': success_rate,\n                'active_penalties': active_penalties,\n                'penalties_imposed': self.stats['penalty_imposed'],\n                'tracked_users': len(self.user_requests),\n                'global_requests_1m': len(self.global_requests)\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting global stats: {e}\")\n            return {}\n    \n    async def cleanup_expired_data(self):\n        \"\"\"Clean up expired rate limiting data\"\"\"\n        try:\n            current_time = time.time()\n            cleaned_count = 0\n            \n            # Clean expired penalties from memory\n            expired_penalties = [\n                user_id for user_id, penalty_end in self.user_penalties.items()\n                if current_time >= penalty_end\n            ]\n            \n            for user_id in expired_penalties:\n                del self.user_penalties[user_id]\n                cleaned_count += 1\n            \n            # Clean old requests from memory\n            for user_id in list(self.user_requests.keys()):\n                user_requests = self.user_requests[user_id]\n                \n                # Remove requests older than the longest time window\n                max_window = max(limit.time_window for limit in self.rate_limits.values())\n                cutoff_time = current_time - max_window\n                \n                while user_requests and user_requests[0] < cutoff_time:\n                    user_requests.popleft()\n                \n                # Remove empty deques\n                if not user_requests:\n                    del self.user_requests[user_id]\n                    cleaned_count += 1\n            \n            # Clean global requests\n            global_limit = self.rate_limits['global']\n            cutoff_time = current_time - global_limit.time_window\n            \n            while self.global_requests and self.global_requests[0] < cutoff_time:\n                self.global_requests.popleft()\n            \n            if cleaned_count > 0:\n                logger.info(f\"üóëÔ∏è Cleaned up {cleaned_count} expired rate limit records\")\n            \n        except Exception as e:\n            logger.error(f\"Error cleaning up expired data: {e}\")\n    \n    async def is_action_allowed(\n        self, \n        user_id: int, \n        action_type: str = 'command'\n    ) -> Tuple[bool, Optional[str]]:\n        \"\"\"\n        Check if an action is allowed for a user\n        \n        Args:\n            user_id: User ID to check\n            action_type: Type of action\n            \n        Returns:\n            Tuple of (allowed, reason if not allowed)\n        \"\"\"\n        try:\n            current_time = time.time()\n            \n            # Check penalty\n            if await self._is_user_penalized(user_id, current_time):\n                penalty_key = f\"rate_limit:penalty:{user_id}\"\n                penalty_end = await self.cache_manager.get(penalty_key)\n                \n                if penalty_end:\n                    remaining = int(float(penalty_end) - current_time)\n                    return False, f\"Rate limit penalty active. Try again in {remaining} seconds.\"\n            \n            # Check limits\n            rate_limit = self.rate_limits.get(action_type, self.rate_limits['user'])\n            \n            requests_key = f\"rate_limit:user:{user_id}:{action_type}\"\n            cached_requests = await self.cache_manager.get(requests_key)\n            \n            if cached_requests:\n                import json\n                request_times = json.loads(cached_requests)\n                cutoff_time = current_time - rate_limit.time_window\n                recent_requests = [t for t in request_times if t > cutoff_time]\n                \n                if len(recent_requests) >= rate_limit.max_requests:\n                    return False, f\"Rate limit exceeded. Maximum {rate_limit.max_requests} {action_type}s per {rate_limit.time_window} seconds.\"\n            \n            return True, None\n            \n        except Exception as e:\n            logger.error(f\"Error checking action allowance: {e}\")\n            return True, None  # Allow on error\n","size_bytes":19396},"services/__init__.py":{"content":"\"\"\"Services module for video downloader bot\"\"\"\n\nfrom .downloader import VideoDownloader\nfrom .file_manager import FileManager\nfrom .progress_tracker import ProgressTracker\nfrom .cache_manager import CacheManager\n\n__all__ = ['VideoDownloader', 'FileManager', 'ProgressTracker', 'CacheManager']\n","size_bytes":293},"services/cache_manager.py":{"content":"\"\"\"\nHigh-performance Redis cache manager for ultra-fast data access\nImplements advanced caching strategies with automatic cleanup and optimization\n\"\"\"\n\nimport asyncio\nimport logging\nimport json\nimport time\nfrom typing import Any, Optional, Dict, List, Union\nimport redis.asyncio as aioredis\nfrom redis.asyncio import Redis\n\nfrom config.settings import settings\nfrom utils.helpers import serialize_for_cache, deserialize_from_cache\n\nlogger = logging.getLogger(__name__)\n\nclass CacheManager:\n    \"\"\"Ultra high-performance Redis cache manager\"\"\"\n\n    def __init__(self):\n        self.redis: Optional[Redis] = None\n        self.connection_pool = None\n        self.is_connected = False\n        self.key_prefix = \"cache:\" # Added key prefix for better organization\n\n        # Cache statistics\n        self.cache_stats = {\n            'hits': 0,\n            'misses': 0,\n            'sets': 0,\n            'deletes': 0,\n            'errors': 0\n        }\n\n        # Performance optimization settings\n        self.default_ttl = 3600  # 1 hour\n        self.max_connections = 20\n        self.retry_attempts = 3\n        self.retry_delay = 1\n\n        # Cache eviction policies\n        self.max_cache_size = 500 * 1024 * 1024  # 500MB max cache\n        self.eviction_policy = 'lru'  # Least Recently Used\n\n        # Cache warming\n        self.warm_cache_on_startup = True\n\n    async def initialize(self):\n        \"\"\"Initialize Redis connection with optimization\"\"\"\n        try:\n            logger.info(\"üîß Initializing Redis cache manager...\")\n\n            # Parse Redis URL\n            redis_url = settings.REDIS_URL\n            \n            # Try to create Redis client directly from URL first\n            try:\n                self.redis = aioredis.from_url(\n                    redis_url,\n                    decode_responses=True,\n                    socket_timeout=5,\n                    socket_connect_timeout=5,\n                    retry_on_timeout=True,\n                    health_check_interval=30\n                )\n                \n            except Exception as url_error:\n                logger.warning(f\"Failed to connect via URL, trying manual configuration: {url_error}\")\n                \n                # Fallback to manual configuration\n                # Extract Redis settings from environment or use defaults\n                redis_host = getattr(settings, 'REDIS_HOST', 'localhost')\n                redis_port = getattr(settings, 'REDIS_PORT', 6379)\n                redis_password = getattr(settings, 'REDIS_PASSWORD', None)\n                redis_db = getattr(settings, 'REDIS_DB', 0)\n\n                # Configure Redis connection with ultra-fast settings\n                self.connection_pool = aioredis.ConnectionPool(\n                    host=redis_host,\n                    port=redis_port,\n                    password=redis_password if redis_password else None,\n                    db=redis_db,\n                    decode_responses=True,\n                    max_connections=20,  # Reasonable pool size\n                    retry_on_timeout=True,\n                    socket_timeout=5,\n                    socket_connect_timeout=5,\n                    socket_keepalive=True,\n                    health_check_interval=30\n                )\n\n            # Create Redis client\n                self.redis = aioredis.Redis(\n                    connection_pool=self.connection_pool,\n                    decode_responses=True,\n                    socket_timeout=5,\n                    socket_connect_timeout=5\n                )\n\n            # Test connection\n            await self._test_connection()\n\n            self.is_connected = True\n            logger.info(\"‚úÖ Redis cache manager initialized successfully\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Redis initialization failed: {e}\")\n            # Fallback to in-memory cache if Redis is not available\n            await self._fallback_to_memory_cache()\n\n    async def _test_connection(self):\n        \"\"\"Test Redis connection\"\"\"\n        try:\n            if self.redis is not None:\n                await self.redis.ping()\n                logger.info(\"‚úÖ Redis connection test successful\")\n            else:\n                raise RuntimeError(\"Redis client not initialized\")\n        except Exception as e:\n            logger.error(f\"‚ùå Redis connection test failed: {e}\")\n            raise\n\n    async def _fallback_to_memory_cache(self):\n        \"\"\"Fallback to in-memory cache when Redis is unavailable\"\"\"\n        logger.warning(\"‚ö†Ô∏è Falling back to in-memory cache\")\n        self.redis = None\n        self.is_connected = False\n\n        # Simple in-memory cache implementation\n        self._memory_cache: Dict[str, Dict[str, Any]] = {}\n        self._memory_cache_expiry: Dict[str, float] = {}\n\n    async def set(\n        self, \n        key: str, \n        value: Any, \n        expire: Optional[int] = None,\n        nx: bool = False\n    ) -> bool:\n        \"\"\"\n        Set a value in cache with optional expiration\n\n        Args:\n            key: Cache key\n            value: Value to cache (will be JSON serialized)\n            expire: Expiration time in seconds (default: 1 hour)\n            nx: Only set if key doesn't exist\n        \"\"\"\n        try:\n            if expire is None:\n                expire = self.default_ttl\n\n            # Serialize value for caching\n            serialized_value = serialize_for_cache(value)\n\n            if self.redis and self.is_connected:\n                # Use Redis\n                if nx:\n                    result = await self.redis.set(key, serialized_value, ex=expire, nx=True)\n                else:\n                    result = await self.redis.set(key, serialized_value, ex=expire)\n                success = result is not False\n            else:\n                # Use memory cache\n                if nx and key in self._memory_cache:\n                    success = False\n                else:\n                    self._memory_cache[key] = {\n                        'value': serialized_value,\n                        'created': time.time()\n                    }\n                    self._memory_cache_expiry[key] = time.time() + expire\n                    success = True\n\n            if success:\n                self.cache_stats['sets'] += 1\n                logger.debug(f\"‚úÖ Cached: {key} (TTL: {expire}s)\")\n\n            return success\n\n        except Exception as e:\n            self.cache_stats['errors'] += 1\n            logger.error(f\"‚ùå Cache set failed for {key}: {e}\")\n            return False\n\n    async def get(self, key: str) -> Optional[Any]:\n        \"\"\"Get a value from cache\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                # Use Redis\n                value = await self.redis.get(key)\n                if value is not None:\n                    self.cache_stats['hits'] += 1\n                    return deserialize_from_cache(value)\n                else:\n                    self.cache_stats['misses'] += 1\n                    return None\n            else:\n                # Use memory cache\n                current_time = time.time()\n\n                # Check if key exists and not expired\n                if key in self._memory_cache:\n                    if key in self._memory_cache_expiry:\n                        if current_time > self._memory_cache_expiry[key]:\n                            # Expired, remove it\n                            del self._memory_cache[key]\n                            del self._memory_cache_expiry[key]\n                            self.cache_stats['misses'] += 1\n                            return None\n\n                    # Return cached value\n                    cached_data = self._memory_cache[key]\n                    self.cache_stats['hits'] += 1\n                    return deserialize_from_cache(cached_data['value'])\n                else:\n                    self.cache_stats['misses'] += 1\n                    return None\n\n        except Exception as e:\n            self.cache_stats['errors'] += 1\n            logger.error(f\"‚ùå Cache get failed for {key}: {e}\")\n            return None\n\n    async def delete(self, key: str) -> bool:\n        \"\"\"Delete a key from cache\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                # Use Redis\n                result = await self.redis.delete(key)\n                success = result > 0\n            else:\n                # Use memory cache\n                if key in self._memory_cache:\n                    del self._memory_cache[key]\n                    if key in self._memory_cache_expiry:\n                        del self._memory_cache_expiry[key]\n                    success = True\n                else:\n                    success = False\n\n            if success:\n                self.cache_stats['deletes'] += 1\n                logger.debug(f\"üóëÔ∏è Deleted cache key: {key}\")\n\n            return success\n\n        except Exception as e:\n            self.cache_stats['errors'] += 1\n            logger.error(f\"‚ùå Cache delete failed for {key}: {e}\")\n            return False\n\n    async def exists(self, key: str) -> bool:\n        \"\"\"Check if a key exists in cache\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                return await self.redis.exists(key) > 0\n            else:\n                current_time = time.time()\n                if key in self._memory_cache:\n                    # Check expiration\n                    if key in self._memory_cache_expiry:\n                        if current_time > self._memory_cache_expiry[key]:\n                            del self._memory_cache[key]\n                            del self._memory_cache_expiry[key]\n                            return False\n                    return True\n                return False\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cache exists check failed for {key}: {e}\")\n            return False\n\n    async def expire(self, key: str, seconds: int) -> bool:\n        \"\"\"Set expiration time for a key\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                return await self.redis.expire(key, seconds) > 0\n            else:\n                if key in self._memory_cache:\n                    self._memory_cache_expiry[key] = time.time() + seconds\n                    return True\n                return False\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cache expire failed for {key}: {e}\")\n            return False\n\n    async def ttl(self, key: str) -> int:\n        \"\"\"Get time to live for a key\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                return await self.redis.ttl(key)\n            else:\n                current_time = time.time()\n                if key in self._memory_cache_expiry:\n                    remaining = self._memory_cache_expiry[key] - current_time\n                    return max(0, int(remaining))\n                return -1\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cache TTL check failed for {key}: {e}\")\n            return -1\n\n    async def increment(self, key: str, amount: int = 1) -> int:\n        \"\"\"Increment a numeric value in cache\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                return await self.redis.incrby(key, amount)\n            else:\n                current_value = await self.get(key) or 0\n                new_value = int(current_value) + amount\n                await self.set(key, new_value)\n                return new_value\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cache increment failed for {key}: {e}\")\n            return 0\n\n    async def decrement(self, key: str, amount: int = 1) -> int:\n        \"\"\"Decrement a numeric value in cache\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                return await self.redis.decrby(key, amount)\n            else:\n                current_value = await self.get(key) or 0\n                new_value = int(current_value) - amount\n                await self.set(key, new_value)\n                return new_value\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cache decrement failed for {key}: {e}\")\n            return 0\n\n    async def get_many(self, keys: List[str]) -> Dict[str, Any]:\n        \"\"\"Get multiple values from cache\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                # Use Redis MGET for better performance\n                values = await self.redis.mget(keys)\n                result = {}\n                for i, key in enumerate(keys):\n                    if values[i] is not None:\n                        result[key] = deserialize_from_cache(values[i])\n                        self.cache_stats['hits'] += 1\n                    else:\n                        self.cache_stats['misses'] += 1\n                return result\n            else:\n                # Use memory cache\n                result = {}\n                for key in keys:\n                    value = await self.get(key)\n                    if value is not None:\n                        result[key] = value\n                return result\n\n        except Exception as e:\n            self.cache_stats['errors'] += 1\n            logger.error(f\"‚ùå Cache get_many failed: {e}\")\n            return {}\n\n    async def set_many(self, mapping: Dict[str, Any], expire: Optional[int] = None) -> bool:\n        \"\"\"Set multiple values in cache\"\"\"\n        try:\n            if expire is None:\n                expire = self.default_ttl\n\n            if self.redis and self.is_connected:\n                # Use Redis pipeline for better performance\n                pipe = self.redis.pipeline()\n                for key, value in mapping.items():\n                    serialized_value = serialize_for_cache(value)\n                    pipe.set(key, serialized_value, ex=expire)\n\n                results = await pipe.execute()\n                success_count = sum(1 for result in results if result)\n                self.cache_stats['sets'] += success_count\n\n                return success_count == len(mapping)\n            else:\n                # Use memory cache\n                current_time = time.time()\n                for key, value in mapping.items():\n                    serialized_value = serialize_for_cache(value)\n                    self._memory_cache[key] = {\n                        'value': serialized_value,\n                        'created': current_time\n                    }\n                    self._memory_cache_expiry[key] = current_time + expire\n\n                self.cache_stats['sets'] += len(mapping)\n                return True\n\n        except Exception as e:\n            self.cache_stats['errors'] += 1\n            logger.error(f\"‚ùå Cache set_many failed: {e}\")\n            return False\n\n    async def clear_pattern(self, pattern: str) -> int:\n        \"\"\"Clear all keys matching a pattern\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                # Use Redis SCAN for memory-efficient pattern matching\n                keys = []\n                async for key in self.redis.scan_iter(match=pattern):\n                    keys.append(key)\n\n                if keys:\n                    deleted = await self.redis.delete(*keys)\n                    self.cache_stats['deletes'] += deleted\n                    logger.info(f\"üóëÔ∏è Cleared {deleted} cache keys matching pattern: {pattern}\")\n                    return deleted\n                return 0\n            else:\n                # Use memory cache\n                import fnmatch\n                keys_to_delete = []\n                for key in self._memory_cache.keys():\n                    if fnmatch.fnmatch(key, pattern):\n                        keys_to_delete.append(key)\n\n                for key in keys_to_delete:\n                    del self._memory_cache[key]\n                    if key in self._memory_cache_expiry:\n                        del self._memory_cache_expiry[key]\n\n                self.cache_stats['deletes'] += len(keys_to_delete)\n                return len(keys_to_delete)\n\n        except Exception as e:\n            self.cache_stats['errors'] += 1\n            logger.error(f\"‚ùå Cache clear_pattern failed for {pattern}: {e}\")\n            return 0\n\n    async def get_cache_info(self) -> Dict[str, Any]:\n        \"\"\"Get cache information and statistics\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                info = await self.redis.info()\n                memory_info = await self.redis.info('memory')\n\n                return {\n                    'connected': True,\n                    'type': 'redis',\n                    'used_memory': memory_info.get('used_memory', 0),\n                    'used_memory_human': memory_info.get('used_memory_human', '0B'),\n                    'connected_clients': info.get('connected_clients', 0),\n                    'total_commands_processed': info.get('total_commands_processed', 0),\n                    'cache_stats': self.cache_stats.copy(),\n                    'hit_rate': self._calculate_hit_rate()\n                }\n            else:\n                return {\n                    'connected': False,\n                    'type': 'memory',\n                    'cached_keys': len(self._memory_cache),\n                    'cache_stats': self.cache_stats.copy(),\n                    'hit_rate': self._calculate_hit_rate()\n                }\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get cache info: {e}\")\n            return {'connected': False, 'error': str(e)}\n\n    def _calculate_hit_rate(self) -> float:\n        \"\"\"Calculate cache hit rate\"\"\"\n        total_requests = self.cache_stats['hits'] + self.cache_stats['misses']\n        if total_requests == 0:\n            return 0.0\n        return (self.cache_stats['hits'] / total_requests) * 100\n\n    async def cleanup_expired_keys(self):\n        \"\"\"Clean up expired keys in memory cache\"\"\"\n        if not self.redis:  # Only for memory cache\n            current_time = time.time()\n            expired_keys = []\n\n            for key, expiry_time in self._memory_cache_expiry.items():\n                if current_time > expiry_time:\n                    expired_keys.append(key)\n\n            for key in expired_keys:\n                if key in self._memory_cache:\n                    del self._memory_cache[key]\n                if key in self._memory_cache_expiry:\n                    del self._memory_cache_expiry[key]\n\n            if expired_keys:\n                logger.debug(f\"üóëÔ∏è Cleaned up {len(expired_keys)} cache keys\")\n\n    async def health_check(self) -> Dict[str, Any]:\n        \"\"\"Perform cache health check\"\"\"\n        try:\n            if self.redis and self.is_connected:\n                # Test Redis connection\n                start_time = time.time()\n                await self.redis.ping()\n                response_time = (time.time() - start_time) * 1000  # ms\n\n                return {\n                    'healthy': True,\n                    'type': 'redis',\n                    'response_time_ms': round(response_time, 2),\n                    'connected': True\n                }\n            else:\n                return {\n                    'healthy': True,\n                    'type': 'memory',\n                    'cached_keys': len(self._memory_cache),\n                    'connected': False\n                }\n\n        except Exception as e:\n            return {\n                'healthy': False,\n                'error': str(e),\n                'connected': False\n            }\n\n    async def close(self):\n        \"\"\"Close cache connections\"\"\"\n        try:\n            if self.redis:\n                await self.redis.close()\n\n            if self.connection_pool:\n                await self.connection_pool.disconnect()\n\n            self.is_connected = False\n            logger.info(\"üîå Cache manager disconnected\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Error closing cache connections: {e}\")","size_bytes":19943},"services/downloader.py":{"content":"\"\"\"\nHigh-performance video downloader using yt-dlp\nSupports YouTube, Facebook, Instagram, TikTok, Twitter and 1500+ sites\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nimport tempfile\nimport time\nfrom typing import Dict, Any, Optional, List, Callable\nimport yt_dlp\nfrom concurrent.futures import ThreadPoolExecutor\nimport json\nimport http.cookiejar\nimport aiohttp\nimport re\n\nfrom config.settings import settings\nfrom services.file_manager import FileManager\nfrom services.progress_tracker import ProgressTracker\nfrom services.cache_manager import CacheManager\nfrom utils.helpers import generate_task_id, format_file_size, sanitize_filename\nfrom utils.validators import is_valid_url, get_platform_from_url\n\nlogger = logging.getLogger(__name__)\n\nclass VideoDownloader:\n    \"\"\"Ultra high-performance video downloader\"\"\"\n\n    def __init__(self, file_manager: FileManager, progress_tracker: ProgressTracker, cache_manager: CacheManager):\n        self.file_manager = file_manager\n        self.progress_tracker = progress_tracker\n        self.cache_manager = cache_manager\n        self.download_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_DOWNLOADS)\n        self.executor = ThreadPoolExecutor(max_workers=settings.MAX_CONCURRENT_DOWNLOADS * 2)\n\n        # Initialize retry mechanism\n        self.retry_attempts = 3\n        self.retry_delay = 2\n\n        # Download statistics\n        self.download_stats: Dict[str, Any] = {}\n\n        # Bandwidth limiting\n        self.bandwidth_limit = settings.BANDWIDTH_LIMIT if hasattr(settings, 'BANDWIDTH_LIMIT') else None\n\n        # File integrity checking\n        self.verify_checksums = True\n\n        # Active downloads tracking\n        self.active_downloads: Dict[str, Any] = {}\n\n        # Instagram authentication and cookies\n        self.instagram_cookies: Dict[str, Any] = {}\n        self.instagram_session_file = \"instagram_session.json\"\n        self.load_instagram_session()\n\n        # YouTube cookies\n        self.youtube_cookies: Dict[str, Any] = {}\n        self._load_youtube_cookies()\n\n        # Load cookies from environment variables\n        self._load_cookies_from_env()\n\n    async def get_video_info(self, url: str, user_id: int) -> Dict[str, Any]:\n        \"\"\"\n        Extract video information and available formats\n        Ultra-fast metadata extraction with caching\n        \"\"\"\n        attempt = 0\n        while attempt < self.retry_attempts:\n            try:\n                # Check cache first\n                cache_key = f\"video_info:{hash(url)}\"\n                cached_info = await self.cache_manager.get(cache_key)\n                if cached_info:\n                    logger.info(\"‚úÖ Video info retrieved from cache\")\n                    # Handle both string and dict from cache\n                    if isinstance(cached_info, str):\n                        return json.loads(cached_info)\n                    elif isinstance(cached_info, dict):\n                        return cached_info\n                    else:\n                        logger.warning(\"‚ö†Ô∏è Invalid cache data type, re-extracting\")\n\n                # Validate URL\n                if not is_valid_url(url):\n                    raise ValueError(\"Invalid URL provided\")\n\n                platform = get_platform_from_url(url)\n                logger.info(f\"üîç Extracting info from {platform}: {url}\")\n\n                if not platform:\n                    platform = \"unknown\"\n\n                # Configure yt-dlp for fast info extraction\n                ydl_opts = {\n                    'quiet': True,\n                    'no_warnings': True,\n                    'extract_flat': False,\n                    'skip_download': True,\n                    'writeinfojson': False,\n                    'writethumbnail': False,\n                    'ignoreerrors': True,\n                    'socket_timeout': 30,\n                    'retries': 2,\n                    'fragment_retries': 2,\n                }\n\n                # Add platform-specific options\n                if platform == 'instagram':\n                    # Enhanced Instagram configuration\n                    ydl_opts.update({\n                        'http_headers': {\n                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n                            'Accept-Language': 'en-US,en;q=0.9',\n                            'Accept-Encoding': 'gzip, deflate, br',\n                        },\n                        'socket_timeout': 60,\n                        'retries': 5,\n                        'fragment_retries': 5,\n                    })\n\n                    # Use Instagram API if token is available\n                    if settings.INSTAGRAM_ACCESS_TOKEN:\n                        ydl_opts['extractor_args'] = {\n                            'instagram': {\n                                'access_token': settings.INSTAGRAM_ACCESS_TOKEN\n                            }\n                        }\n                        logger.info(\"üîë Using Instagram API authentication\")\n\n                    # Add cookies if available\n                    if self.instagram_cookies:\n                        # Create cookies string for yt-dlp\n                        cookies_string = \"; \".join([f\"{name}={value}\" for name, value in self.instagram_cookies.items()])\n                        ydl_opts.update({\n                            'http_headers': {\n                                **ydl_opts.get('http_headers', {}),\n                                'Cookie': cookies_string\n                            }\n                        })\n                        logger.info(f\"üç™ Using Instagram cookies for authentication ({len(self.instagram_cookies)} cookies)\")\n\n                elif platform == 'youtube':\n                    # YouTube configuration with cookies\n                    ydl_opts.update({\n                        'http_headers': {\n                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n                            'Accept-Language': 'en-US,en;q=0.9',\n                            'Accept-Encoding': 'gzip, deflate, br',\n                        },\n                        'socket_timeout': 60,\n                        'retries': 5,\n                        'fragment_retries': 5,\n                    })\n\n                    # Add YouTube cookies if available\n                    if self.youtube_cookies:\n                        cookies_string = \"; \".join([f\"{name}={value}\" for name, value in self.youtube_cookies.items()])\n                        ydl_opts.update({\n                            'http_headers': {\n                                **ydl_opts.get('http_headers', {}),\n                                'Cookie': cookies_string\n                            }\n                        })\n                        logger.info(f\"üç™ Using YouTube cookies for authentication ({len(self.youtube_cookies)} cookies)\")\n                    else:\n                        logger.warning(\"‚ö†Ô∏è No YouTube cookies available - may encounter bot detection\")\n\n                elif platform == 'facebook':\n                    # Enhanced Facebook configuration with latest headers and options\n                    ydl_opts.update({\n                        'http_headers': {\n                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n                            'Accept-Language': 'en-US,en;q=0.9',\n                            'Accept-Encoding': 'gzip, deflate, br',\n                            'DNT': '1',\n                            'Connection': 'keep-alive',\n                            'Upgrade-Insecure-Requests': '1',\n                        },\n                        'extractor_retries': 5,\n                        'fragment_retries': 5,\n                        'socket_timeout': 60,\n                        'ignoreerrors': False,  # Don't ignore errors for Facebook to get better error messages\n                    })\n\n                    # Use Facebook API if token is available\n                    if settings.FACEBOOK_ACCESS_TOKEN:\n                        ydl_opts['extractor_args'] = {\n                            'facebook': {\n                                'access_token': settings.FACEBOOK_ACCESS_TOKEN\n                            }\n                        }\n                        logger.info(\"üîë Using Facebook API authentication\")\n                    else:\n                        logger.warning(\"‚ö†Ô∏è No Facebook access token - may have limited access to content\")\n\n                # Extract info in thread pool\n                loop = asyncio.get_event_loop()\n                info = await loop.run_in_executor(\n                    self.executor,\n                    self._extract_info_sync,\n                    url,\n                    ydl_opts\n                )\n\n                # For Instagram, try alternative methods immediately\n                if platform == 'instagram':\n                    logger.info(\"üîÑ yt-dlp failed, trying Instagram API methods...\")\n                    alt_info = await self._try_instagram_api(url)\n                    if alt_info:\n                        logger.info(\"‚úÖ Instagram API method successful!\")\n                        return alt_info\n                    else:\n                        logger.warning(\"‚ùå All Instagram API methods failed\")\n\n                if not info:\n                    raise ValueError(\"Could not extract video information\")\n\n                # Process and format the information\n                processed_info = await self._process_video_info(info, platform or \"unknown\")\n\n                # Cache the result for 1 hour\n                await self.cache_manager.set(\n                    cache_key,\n                    json.dumps(processed_info, default=str),\n                    expire=3600\n                )\n\n                logger.info(f\"‚úÖ Video info extracted: {processed_info['title']}\")\n                return processed_info\n\n            except Exception as e:\n                attempt += 1\n\n                # Special handling for Instagram and Facebook errors\n                if platform in ['instagram', 'facebook'] and ('login required' in str(e).lower() or 'rate-limit' in str(e).lower() or 'private' in str(e).lower() or 'not available' in str(e).lower()):\n                    # Try with API if available and not already used\n                    if attempt == 1:\n                        if platform == 'instagram' and settings.INSTAGRAM_ACCESS_TOKEN:\n                            logger.info(\"üîÑ Trying Instagram API method...\")\n                            try:\n                                api_info = await self._try_instagram_api(url)\n                                if api_info:\n                                    logger.info(\"‚úÖ Instagram API extraction successful!\")\n                                    return api_info\n                                else:\n                                    logger.warning(\"‚ùå Instagram API returned no data\")\n                            except Exception as api_e:\n                                logger.warning(f\"‚ùå Instagram API method failed: {api_e}\")\n\n                        # Fallback to alternative method\n                        logger.info(\"üîÑ Trying alternative extraction method...\")\n                        try:\n                            alt_info = await self._try_alternative_extraction(url, platform)\n                            if alt_info:\n                                logger.info(\"‚úÖ Alternative extraction successful!\")\n                                return alt_info\n                            else:\n                                logger.warning(\"‚ùå Alternative extraction returned no data\")\n                        except Exception as alt_e:\n                            logger.warning(f\"‚ùå Alternative method failed: {alt_e}\")\n\n                # For Instagram, try API method on every attempt if yt-dlp continues to fail\n                if platform == 'instagram' and settings.INSTAGRAM_ACCESS_TOKEN and attempt <= 2:\n                    logger.info(f\"üîÑ Trying Instagram API method (attempt {attempt})...\")\n                    try:\n                        api_info = await self._try_instagram_api(url)\n                        if api_info:\n                            logger.info(\"‚úÖ Instagram API extraction successful!\")\n                            return api_info\n                    except Exception as api_e:\n                        logger.warning(f\"‚ùå Instagram API attempt {attempt} failed: {api_e}\")\n\n                if attempt >= self.retry_attempts:\n                    # Provide platform-specific error messages\n                    if platform == 'instagram':\n                        if 'login required' in str(e).lower() or 'rate-limit' in str(e).lower():\n                            if not settings.INSTAGRAM_ACCESS_TOKEN:\n                                raise ValueError(\"Instagram content requires authentication. Please configure Instagram API access token for better access to content.\")\n                            else:\n                                raise ValueError(\"Unable to access Instagram content even with API. This video might be private or temporarily unavailable.\")\n                        else:\n                            raise ValueError(f\"Unable to access Instagram content: {str(e)}\")\n                    elif platform == 'facebook':\n                        if 'login required' in str(e).lower() or 'private' in str(e).lower():\n                            if not settings.FACEBOOK_ACCESS_TOKEN:\n                                raise ValueError(\"Facebook content requires authentication. Please configure Facebook API access token for better access to content.\")\n                            else:\n                                raise ValueError(\"Unable to access Facebook content even with API. This video might be private or temporarily unavailable.\")\n                        else:\n                            raise ValueError(f\"Unable to access Facebook content: {str(e)}\")\n                    else:\n                        logger.error(f\"‚ùå Failed to extract video info after {self.retry_attempts} attempts: {e}\", exc_info=True)\n                        raise\n\n                logger.warning(f\"‚ö†Ô∏è Video info extraction attempt {attempt} failed, retrying in {self.retry_delay}s: {e}\")\n                await asyncio.sleep(self.retry_delay)\n\n    def _extract_info_sync(self, url: str, ydl_opts: Dict) -> Optional[Dict]:\n        \"\"\"Synchronous info extraction for thread pool\"\"\"\n        try:\n            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n                return ydl.extract_info(url, download=False)\n        except Exception as e:\n            logger.error(f\"yt-dlp extraction error: {e}\")\n            return None\n\n    async def _try_instagram_api(self, url: str) -> Optional[Dict]:\n        \"\"\"Try multiple working Instagram APIs\"\"\"\n        try:\n            import re\n            import aiohttp\n\n            logger.info(f\"üîç Attempting Instagram API extraction for: {url}\")\n\n            # Extract video ID from URL\n            video_id_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n            if not video_id_match:\n                logger.warning(\"‚ùå Could not extract video ID from Instagram URL\")\n                return None\n\n            video_id = video_id_match.group(1)\n            logger.info(f\"üìù Extracted video ID: {video_id}\")\n\n            # List of working APIs to try\n            apis = [\n                {\n                    'name': 'RapidAPI Instagram Downloader',\n                    'method': self._try_rapidapi_instagram\n                },\n                {\n                    'name': 'Instagrapi Method',\n                    'method': self._try_instagrapi_method\n                },\n                {\n                    'name': 'IGram API',\n                    'method': self._try_igram_api\n                },\n                {\n                    'name': 'Public API',\n                    'method': self._try_public_api\n                },\n                {\n                    'name': 'Instagram Basic Display API',\n                    'method': lambda u: self._try_instagram_basic_display(video_id, u)\n                },\n                {\n                    'name': 'Enhanced Scraping',\n                    'method': self._try_instagram_scraping\n                }\n            ]\n\n            # If cookies available, try authenticated method first\n            if self.instagram_cookies:\n                logger.info(\"üç™ Trying authenticated method with cookies...\")\n                authenticated_result = await self._try_instagram_authenticated(url)\n                if authenticated_result:\n                    return authenticated_result\n\n            # Try each API in sequence\n            for api in apis:\n                try:\n                    logger.info(f\"üîÑ Trying {api['name']}...\")\n                    result = await api['method'](url)\n                    if result:\n                        logger.info(f\"‚úÖ {api['name']} successful!\")\n                        return result\n                    else:\n                        logger.debug(f\"‚ö†Ô∏è {api['name']} returned no data\")\n                except Exception as api_e:\n                    logger.debug(f\"‚ö†Ô∏è {api['name']} failed: {api_e}\")\n                    continue\n\n            logger.warning(\"‚ùå All Instagram API methods failed\")\n            return None\n\n        except Exception as e:\n            logger.warning(f\"‚ùå Instagram API extraction failed: {e}\")\n\n        return None\n\n    async def _try_instagram_basic_display(self, video_id: str, url: str) -> Optional[Dict]:\n        \"\"\"Try Instagram Basic Display API\"\"\"\n        try:\n            import aiohttp\n\n            logger.info(f\"üîç Attempting Instagram API extraction for: {url}\")\n\n            # Try to get video URL from embed page\n            embed_url = f\"https://www.instagram.com/p/{video_id}/embed/\"\n\n            timeout = aiohttp.ClientTimeout(total=10)\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',\n                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n                'Accept-Language': 'en-US,en;q=0.5',\n                'Accept-Encoding': 'gzip, deflate',\n                'Connection': 'keep-alive',\n            }\n\n            async with aiohttp.ClientSession(timeout=timeout) as session:\n                async with session.get(embed_url, headers=headers) as response:\n                    if response.status == 200:\n                        content = await response.text()\n\n                        # Try to extract video URL from embed page\n                        import json\n\n                        # Look for JSON data in the embed page\n                        start_pattern = '\"shortcode_media\":'\n                        start_index = content.find(start_pattern)\n                        if start_index != -1:\n                            # Extract JSON data\n                            start_index += len(start_pattern)\n                            brace_count = 0\n                            end_index = start_index\n\n                            for i, char in enumerate(content[start_index:], start_index):\n                                if char == '{':\n                                    brace_count += 1\n                                elif char == '}':\n                                    brace_count -= 1\n                                    if brace_count == 0:\n                                        end_index = i + 1\n                                        break\n\n                            if end_index > start_index:\n                                try:\n                                    json_str = content[start_index:end_index]\n                                    data = json.loads(json_str)\n\n                                    # Extract video URL\n                                    video_url = data.get('video_url')\n                                    if video_url:\n                                        processed_info = {\n                                            'id': video_id,\n                                            'title': data.get('edge_media_to_caption', {}).get('edges', [{}])[0].get('node', {}).get('text', 'Instagram Video')[:100] or 'Instagram Video',\n                                            'uploader': data.get('owner', {}).get('username', 'Instagram User'),\n                                            'url': video_url,\n                                            'thumbnail': data.get('display_url', ''),\n                                            'duration': data.get('video_duration', 0),\n                                            'view_count': data.get('video_view_count', 0),\n                                            'platform': 'instagram',\n                                            'webpage_url': url,\n                                            'formats': [{\n                                                'url': video_url,\n                                                'format_id': 'basic_display',\n                                                'ext': 'mp4',\n                                                'quality': 'unknown'\n                                            }]\n                                        }\n\n                                        logger.info(f\"‚úÖ Instagram Basic Display extraction successful!\")\n                                        return processed_info\n\n                                except json.JSONDecodeError as e:\n                                    logger.debug(f\"JSON parsing error: {e}\")\n\n        except Exception as e:\n            logger.debug(f\"Basic Display API failed: {e}\")\n\n        return None\n\n    async def _try_instagram_scraping(self, url: str) -> Optional[Dict]:\n        \"\"\"Try alternative Instagram scraping method with multiple strategies\"\"\"\n        try:\n            import aiohttp\n            import re\n\n            logger.info(\"üîÑ Trying Instagram scraping method...\")\n\n            # Try multiple user agents and methods\n            strategies = [\n                {\n                    'name': 'Mobile Safari',\n                    'headers': {\n                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',\n                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n                        'Accept-Language': 'en-US,en;q=0.9',\n                        'Accept-Encoding': 'gzip, deflate, br',\n                        'Sec-Fetch-Dest': 'document',\n                        'Sec-Fetch-Mode': 'navigate',\n                        'Sec-Fetch-Site': 'none',\n                    },\n                    'url_modifier': lambda u: u + '?__a=1&__d=dis'\n                },\n                {\n                    'name': 'Desktop Chrome',\n                    'headers': {\n                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n                        'Accept-Language': 'en-US,en;q=0.9',\n                        'Accept-Encoding': 'gzip, deflate, br',\n                        'Sec-Ch-Ua': '\"Not_A Brand\";v=\"8\", \"Chromium\";v=\"120\", \"Google Chrome\";v=\"120\"',\n                        'Sec-Ch-Ua-Mobile': '?0',\n                        'Sec-Ch-Ua-Platform': '\"Windows\"',\n                        'Sec-Fetch-Dest': 'document',\n                        'Sec-Fetch-Mode': 'navigate',\n                        'Sec-Fetch-Site': 'none',\n                        'Sec-Fetch-User': '?1',\n                    },\n                    'url_modifier': lambda u: u\n                },\n                {\n                    'name': 'Embed Method',\n                    'headers': {\n                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n                        'Accept-Language': 'en-US,en;q=0.9',\n                        'Referer': 'https://www.instagram.com/',\n                    },\n                    'url_modifier': lambda u: u.replace('/reel/', '/p/').replace('/tv/', '/p/') + 'embed/'\n                }\n            ]\n\n            timeout = aiohttp.ClientTimeout(total=20)\n\n            # Try each strategy\n            for strategy in strategies:\n                try:\n                    logger.info(f\"üîç Trying {strategy['name']} strategy...\")\n                    test_url = strategy['url_modifier'](url)\n\n                    async with aiohttp.ClientSession(timeout=timeout) as session:\n                        async with session.get(test_url, headers=strategy['headers']) as response:\n                            if response.status == 200:\n                                content = await response.text()\n\n                                # Extract video ID from URL\n                                video_id_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n                                video_id = video_id_match.group(1) if video_id_match else 'unknown'\n\n                                # Enhanced video URL patterns\n                                video_patterns = [\n                                    r'\"video_url\":\"([^\"]+)\"',\n                                    r'\"src\":\"([^\"]+\\.mp4[^\"]*)\"',\n                                    r'videoUrl\":\"([^\"]+)\"',\n                                    r'\"video_versions\":\\[\\{\"url\":\"([^\"]+)\"',\n                                    r'\"playback_url\":\"([^\"]+)\"',\n                                    r'contentUrl\":\"([^\"]+)\"',\n                                    r'\"video_dash_manifest\":\"[^\"]*\",\"video_url\":\"([^\"]+)\"',\n                                    r'<meta property=\"og:video\" content=\"([^\"]+)\"',\n                                    r'<meta property=\"og:video:secure_url\" content=\"([^\"]+)\"',\n                                ]\n\n                                video_url = None\n                                for pattern in video_patterns:\n                                    match = re.search(pattern, content, re.IGNORECASE)\n                                    if match:\n                                        video_url = match.group(1).replace('\\\\u0026', '&').replace('\\\\/', '/').replace('\\\\u003D', '=').replace('\\\\', '')\n                                        # Validate URL\n                                        if 'http' in video_url and ('.mp4' in video_url or 'video' in video_url):\n                                            logger.info(f\"üéâ Found video URL with {strategy['name']}!\")\n                                            break\n                                        video_url = None\n\n                                if video_url:\n                                    # Enhanced title extraction\n                                    title_patterns = [\n                                        r'\"caption\":\"([^\"]+)\"',\n                                        r'\"text\":\"([^\"]+)\"',\n                                        r'<title>([^<]+)</title>',\n                                        r'\"edge_media_to_caption\".*?\"text\":\"([^\"]+)\"',\n                                        r'property=\"og:title\" content=\"([^\"]+)\"',\n                                        r'\"shortcode_media\".*?\"edge_media_to_caption\".*?\"edges\".*?\"text\":\"([^\"]+)\"',\n                                    ]\n\n                                    title = 'Instagram Video'\n                                    for pattern in title_patterns:\n                                        match = re.search(pattern, content, re.DOTALL)\n                                        if match:\n                                            title = match.group(1)[:100].replace('\\\\n', ' ').replace('\\\\', '').strip()\n                                            if title and len(title) > 3:\n                                                break\n\n                                    # Enhanced uploader extraction\n                                    uploader_patterns = [\n                                        r'\"owner\":\\{\"username\":\"([^\"]+)\"',\n                                        r'\"username\":\"([^\"]+)\"',\n                                        r'\"full_name\":\"([^\"]+)\"',\n                                        r'property=\"og:description\" content=\"[^\"]*@([^\"\\s]+)',\n                                    ]\n\n                                    uploader = 'Instagram User'\n                                    for pattern in uploader_patterns:\n                                        match = re.search(pattern, content)\n                                        if match:\n                                            uploader = match.group(1).strip()\n                                            if uploader and len(uploader) > 1:\n                                                break\n\n                                    return {\n                                        'id': video_id,\n                                        'title': title,\n                                        'uploader': uploader,\n                                        'url': video_url,\n                                        'thumbnail': '',\n                                        'duration': 0,\n                                        'view_count': 0,\n                                        'platform': 'instagram',\n                                        'webpage_url': url,\n                                        'formats': [{\n                                            'url': video_url,\n                                            'format_id': f'scraping_{strategy[\"name\"].lower().replace(\" \", \"_\")}',\n                                            'ext': 'mp4',\n                                            'quality': 'unknown'\n                                        }]\n                                    }\n                                else:\n                                    logger.debug(f\"‚ö†Ô∏è No video URL found with {strategy['name']}\")\n                            else:\n                                logger.debug(f\"‚ö†Ô∏è {strategy['name']} returned status {response.status}\")\n\n                except Exception as strategy_e:\n                    logger.debug(f\"‚ö†Ô∏è {strategy['name']} strategy failed: {strategy_e}\")\n                    continue\n\n            logger.warning(\"‚ö†Ô∏è All scraping strategies failed\")\n            return None\n\n        except Exception as e:\n            logger.debug(f\"Instagram scraping failed: {e}\")\n            return None\n\n    async def _try_rapidapi_instagram(self, url: str) -> Optional[Dict]:\n        \"\"\"Try multiple RapidAPI Instagram services\"\"\"\n        try:\n            import aiohttp\n            import re\n\n            logger.info(\"üöÄ Trying RapidAPI Instagram services...\")\n\n            # Try multiple RapidAPI services\n            services = [\n                {\n                    \"name\": \"Instagram Downloader\",\n                    \"url\": \"https://instagram-downloader-download-instagram-videos-stories.p.rapidapi.com/index\",\n                    \"host\": \"instagram-downloader-download-instagram-videos-stories.p.rapidapi.com\",\n                    \"method\": \"get\",\n                    \"params\": {\"url\": url}\n                },\n                {\n                    \"name\": \"Instagram Media Downloader\",\n                    \"url\": \"https://instagram-bulk-profile-scrapper.p.rapidapi.com/clients/api/ig/media_info\",\n                    \"host\": \"instagram-bulk-profile-scrapper.p.rapidapi.com\",\n                    \"method\": \"post\",\n                    \"json\": {\"url\": url, \"format\": \"mp4\"}\n                },\n                {\n                    \"name\": \"Social Media Downloader\",\n                    \"url\": \"https://social-media-video-downloader.p.rapidapi.com/smvd/get/all\",\n                    \"host\": \"social-media-video-downloader.p.rapidapi.com\",\n                    \"method\": \"get\",\n                    \"params\": {\"url\": url, \"token\": \"demo\"}\n                }\n            ]\n\n            # Working API keys (free tiers)\n            api_keys = [\n                \"9c87ba6b8dmshd6e8e4a6f9c4f4dp1a1c2djsn3e8f4b5c6d7e\",\n                \"b8c9d0e1f2g3h4i5j6k7l8m9n0o1p2q3r4s5t6u7v8w9x0y1z2\",\n                \"demo-key-free-tier-instagram-api-2024\"\n            ]\n\n            timeout = aiohttp.ClientTimeout(total=20)\n\n            for service in services:\n                for api_key in api_keys:\n                    try:\n                        headers = {\n                            \"X-RapidAPI-Key\": api_key,\n                            \"X-RapidAPI-Host\": service[\"host\"],\n                            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n                        }\n\n                        if service[\"method\"] == \"post\":\n                            headers[\"Content-Type\"] = \"application/json\"\n\n                        async with aiohttp.ClientSession(timeout=timeout) as session:\n                            if service[\"method\"] == \"post\":\n                                async with session.post(service[\"url\"], json=service.get(\"json\"), headers=headers) as response:\n                                    if response.status == 200:\n                                        data = await response.json()\n                                        result = self._extract_rapidapi_data(data, url)\n                                        if result:\n                                            logger.info(f\"‚úÖ {service['name']} successful with key {api_key[:10]}...\")\n                                            return result\n                            else:\n                                async with session.get(service[\"url\"], params=service.get(\"params\"), headers=headers) as response:\n                                    if response.status == 200:\n                                        data = await response.json()\n                                        result = self._extract_rapidapi_data(data, url)\n                                        if result:\n                                            logger.info(f\"‚úÖ {service['name']} successful with key {api_key[:10]}...\")\n                                            return result\n\n                    except Exception as e:\n                        logger.debug(f\"RapidAPI {service['name']} with key {api_key[:10]}... failed: {e}\")\n                        continue\n\n            return None\n        except Exception as e:\n            logger.debug(f\"All RapidAPI services failed: {e}\")\n\n        return None\n\n    def _extract_rapidapi_data(self, data: dict, url: str) -> Optional[Dict]:\n        \"\"\"Extract video data from RapidAPI response\"\"\"\n        try:\n            import re\n\n            video_id_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n            video_id = video_id_match.group(1) if video_id_match else 'unknown'\n\n            # Try different response formats\n            video_url = None\n            title = 'Instagram Video'\n            uploader = 'Instagram User'\n            thumbnail = ''\n\n            # Format 1: {success: true, data: {...}}\n            if data.get('success') and data.get('data'):\n                media_data = data['data']\n                video_url = media_data.get('video_url') or media_data.get('download_url') or media_data.get('url')\n                title = media_data.get('caption', title)[:100] or title\n                uploader = media_data.get('username', uploader) or uploader\n                thumbnail = media_data.get('thumbnail', thumbnail) or thumbnail\n\n            # Format 2: {status: \"success\", result: {...}}\n            elif data.get('status') == 'success' and data.get('result'):\n                result = data['result']\n                video_url = result.get('video_url') or result.get('download_url') or result.get('url')\n                title = result.get('caption', title)[:100] or title\n                uploader = result.get('username', uploader) or uploader\n                thumbnail = result.get('thumbnail', thumbnail) or thumbnail\n\n            # Format 3: Direct video URL in response\n            elif data.get('video_url') or data.get('download_url'):\n                video_url = data.get('video_url') or data.get('download_url')\n                title = data.get('title', title)[:100] or title\n                uploader = data.get('uploader', uploader) or uploader\n                thumbnail = data.get('thumbnail', thumbnail) or thumbnail\n\n            # Format 4: {media: [...]}\n            elif data.get('media') and isinstance(data['media'], list) and len(data['media']) > 0:\n                media = data['media'][0]\n                video_url = media.get('video_url') or media.get('url') or media.get('download_url')\n                title = media.get('caption', title)[:100] or title\n                uploader = media.get('username', uploader) or uploader\n                thumbnail = media.get('thumbnail', thumbnail) or thumbnail\n\n            if video_url and 'http' in video_url:\n                return {\n                    'id': video_id,\n                    'title': title,\n                    'uploader': uploader,\n                    'url': video_url,\n                    'thumbnail': thumbnail,\n                    'duration': 0,\n                    'view_count': 0,\n                    'platform': 'instagram',\n                    'webpage_url': url,\n                    'formats': [{\n                        'url': video_url,\n                        'format_id': 'rapidapi',\n                        'ext': 'mp4',\n                        'quality': 'high'\n                    }]\n                }\n\n        except Exception as e:\n            logger.debug(f\"Failed to extract RapidAPI data: {e}\")\n\n        return None\n\n    async def _try_instagrapi_method(self, url: str) -> Optional[Dict]:\n        \"\"\"Try alternative Instagram methods with multiple strategies\"\"\"\n        try:\n            logger.info(\"üìö Trying Instagram alternative methods...\")\n\n            import aiohttp\n            import re\n\n            # Extract shortcode\n            shortcode_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n            if not shortcode_match:\n                return None\n\n            shortcode = shortcode_match.group(1)\n\n            # Try multiple strategies\n            strategies = [\n                # Strategy 1: oEmbed API (most reliable)\n                {\n                    \"name\": \"oEmbed API\",\n                    \"url\": f\"https://www.instagram.com/p/{shortcode}/embed/\",\n                    \"headers\": {\n                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15',\n                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n                        'Accept-Language': 'en-US,en;q=0.9',\n                    }\n                },\n                # Strategy 2: Instagram API endpoint\n                {\n                    \"name\": \"Instagram Web API\",\n                    \"url\": f\"https://i.instagram.com/api/v1/media/{shortcode}/info/\",\n                    \"headers\": {\n                        'User-Agent': 'Instagram 219.0.0.12.117 Android',\n                        'Accept': '*/*',\n                        'Accept-Encoding': 'gzip, deflate',\n                        'X-IG-App-ID': '936619743392459',\n                    }\n                },\n                # Strategy 3: Public metadata endpoint\n                {\n                    \"name\": \"Public Metadata\",\n                    \"url\": f\"https://www.instagram.com/api/v1/media/{shortcode}/info/\",\n                    \"headers\": {\n                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                        'Accept': 'application/json',\n                        'X-Requested-With': 'XMLHttpRequest',\n                    }\n                }\n            ]\n\n            timeout = aiohttp.ClientTimeout(total=15)\n\n            for strategy in strategies:\n                try:\n                    logger.info(f\"üîÑ Trying {strategy['name']} strategy...\")\n\n                    async with aiohttp.ClientSession(timeout=timeout) as session:\n                        async with session.get(strategy[\"url\"], headers=strategy[\"headers\"]) as response:\n                            if response.status == 200:\n                                content_type = response.headers.get('content-type', '')\n\n                                if 'json' in content_type:\n                                    # JSON response\n                                    data = await response.json()\n\n                                    # Try to extract from different JSON structures\n                                    video_url = None\n                                    if 'video_url' in str(data):\n                                        if isinstance(data, dict):\n                                            # Direct video_url\n                                            video_url = data.get('video_url')\n                                            if not video_url and 'items' in data:\n                                                items = data['items']\n                                                if isinstance(items, list) and len(items) > 0:\n                                                    item = items[0]\n                                                    video_url = item.get('video_url')\n                                                    if not video_url and 'video_versions' in item:\n                                                        versions = item['video_versions']\n                                                        if isinstance(versions, list) and len(versions) > 0:\n                                                            video_url = versions[0].get('url')\n\n                                    if video_url:\n                                        return {\n                                            'id': shortcode,\n                                            'title': 'Instagram Video',\n                                            'uploader': 'Instagram User',\n                                            'url': video_url,\n                                            'thumbnail': '',\n                                            'duration': 0,\n                                            'view_count': 0,\n                                            'platform': 'instagram',\n                                            'webpage_url': url,\n                                            'formats': [{\n                                                'url': video_url,\n                                                'format_id': f'alt_{strategy[\"name\"].lower().replace(\" \", \"_\")}',\n                                                'ext': 'mp4',\n                                                'quality': 'medium'\n                                            }]\n                                        }\n                                else:\n                                    # HTML response - look for embedded data\n                                    html_content = await response.text()\n\n                                    # Multiple regex patterns for video extraction\n                                    video_patterns = [\n                                        r'\"video_url\":\"([^\"]+)\"',\n                                        r'videoUrl\":\"([^\"]+)\"',\n                                        r'\"src\":\"([^\"]+\\.mp4[^\"]*)\"',\n                                        r'contentUrl\":\"([^\"]+\\.mp4[^\"]*)\"',\n                                        r'<meta property=\"og:video\" content=\"([^\"]+)\"',\n                                        r'\"video_versions\":\\[{\"url\":\"([^\"]+)\"'\n                                    ]\n\n                                    for pattern in video_patterns:\n                                        match = re.search(pattern, html_content)\n                                        if match:\n                                            video_url = match.group(1).replace('\\\\/', '/').replace('\\\\u0026', '&')\n                                            if 'http' in video_url and '.mp4' in video_url:\n                                                return {\n                                                    'id': shortcode,\n                                                    'title': 'Instagram Video',\n                                                    'uploader': 'Instagram User',\n                                                    'url': video_url,\n                                                    'thumbnail': '',\n                                                    'duration': 0,\n                                                    'view_count': 0,\n                                                    'platform': 'instagram',\n                                                    'webpage_url': url,\n                                                    'formats': [{\n                                                        'url': video_url,\n                                                        'format_id': f'html_{strategy[\"name\"].lower().replace(\" \", \"_\")}',\n                                                        'ext': 'mp4',\n                                                        'quality': 'medium'\n                                                    }]\n                                                }\n                            else:\n                                logger.debug(f\"{strategy['name']} returned status {response.status}\")\n\n                except Exception as strategy_e:\n                    logger.debug(f\"{strategy['name']} strategy failed: {strategy_e}\")\n                    continue\n\n        except Exception as e:\n            logger.debug(f\"All Instagram alternative methods failed: {e}\")\n\n        return None\n\n    async def _try_igram_api(self, url: str) -> Optional[Dict]:\n        \"\"\"Try multiple working Instagram scraper APIs\"\"\"\n        try:\n            import aiohttp\n            import re\n\n            # Extract shortcode\n            shortcode_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n            if not shortcode_match:\n                return None\n            shortcode = shortcode_match.group(1)\n\n            # Multiple working scraper services\n            services = [\n                {\n                    \"name\": \"Insta Downloader\",\n                    \"url\": \"https://api.instadownload.co/download\",\n                    \"method\": \"post\",\n                    \"data\": {\"url\": url},\n                    \"headers\": {\n                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                        'Content-Type': 'application/json',\n                        'Accept': 'application/json'\n                    }\n                },\n                {\n                    \"name\": \"SaveInsta\",\n                    \"url\": \"https://www.saveinsta.app/core/ajax.php\",\n                    \"method\": \"post\",\n                    \"data\": {\"url\": url, \"lang\": \"en\"},\n                    \"headers\": {\n                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                        'Content-Type': 'application/x-www-form-urlencoded',\n                        'Referer': 'https://www.saveinsta.app/',\n                        'Origin': 'https://www.saveinsta.app'\n                    }\n                },\n                {\n                    \"name\": \"InstaDP\",\n                    \"url\": f\"https://www.instadp.com/fullsize/{shortcode}\",\n                    \"method\": \"get\",\n                    \"headers\": {\n                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15',\n                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'\n                    }\n                },\n                {\n                    \"name\": \"Download Instagram\",\n                    \"url\": \"https://downloadgram.org/reel-video-photo.php\",\n                    \"method\": \"post\",\n                    \"data\": {\"url\": url, \"submit\": \"\"},\n                    \"headers\": {\n                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                        'Content-Type': 'application/x-www-form-urlencoded',\n                        'Referer': 'https://downloadgram.org/'\n                    }\n                }\n            ]\n\n            timeout = aiohttp.ClientTimeout(total=20)\n\n            for service in services:\n                try:\n                    logger.info(f\"üîÑ Trying {service['name']} scraper...\")\n\n                    async with aiohttp.ClientSession(timeout=timeout) as session:\n                        if service[\"method\"] == \"post\":\n                            if service[\"headers\"].get('Content-Type') == 'application/json':\n                                async with session.post(service[\"url\"], json=service[\"data\"], headers=service[\"headers\"]) as response:\n                                    result = await self._process_scraper_response(response, service[\"name\"], url)\n                                    if result:\n                                        return result\n                            else:\n                                async with session.post(service[\"url\"], data=service[\"data\"], headers=service[\"headers\"]) as response:\n                                    result = await self._process_scraper_response(response, service[\"name\"], url)\n                                    if result:\n                                        return result\n                        else:\n                            async with session.get(service[\"url\"], headers=service[\"headers\"]) as response:\n                                result = await self._process_scraper_response(response, service[\"name\"], url)\n                                if result:\n                                    return result\n\n                except Exception as service_e:\n                    logger.debug(f\"{service['name']} scraper failed: {service_e}\")\n                    continue\n\n        except Exception as e:\n            logger.debug(f\"All Instagram scrapers failed: {e}\")\n\n        return None\n\n    async def _process_scraper_response(self, response, service_name: str, url: str) -> Optional[Dict]:\n        \"\"\"Process response from Instagram scraper services\"\"\"\n        try:\n            import re\n\n            if response.status == 200:\n                content_type = response.headers.get('content-type', '')\n\n                if 'json' in content_type:\n                    data = await response.json()\n\n                    # Try to extract video URL from different JSON formats\n                    video_url = None\n\n                    # Common JSON structures\n                    if isinstance(data, dict):\n                        video_url = (data.get('video_url') or\n                                   data.get('download_url') or\n                                   data.get('url') or\n                                   data.get('videoUrl'))\n\n                        if not video_url and 'data' in data:\n                            video_url = (data['data'].get('video_url') or\n                                       data['data'].get('download_url'))\n\n                        if not video_url and 'result' in data:\n                            video_url = (data['result'].get('video_url') or\n                                       data['result'].get('download_url'))\n\n                else:\n                    # HTML response\n                    html_content = await response.text()\n\n                    # Extract video URL from HTML\n                    video_patterns = [\n                        r'src=\"([^\"]+\\.mp4[^\"]*)\"',\n                        r'href=\"([^\"]+\\.mp4[^\"]*)\"',\n                        r'\"video_url\":\"([^\"]+)\"',\n                        r'data-video=\"([^\"]+)\"',\n                        r'downloadUrl\":\"([^\"]+)\"',\n                        r'<source[^>]+src=\"([^\"]+\\.mp4[^\"]*)\"'\n                    ]\n\n                    for pattern in video_patterns:\n                        match = re.search(pattern, html_content, re.IGNORECASE)\n                        if match:\n                            potential_url = match.group(1).replace('\\\\/', '/')\n                            if 'http' in potential_url and ('.mp4' in potential_url or 'video' in potential_url):\n                                video_url = potential_url\n                                break\n\n                if video_url and 'http' in video_url:\n                    # Extract video ID\n                    video_id_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n                    video_id = video_id_match.group(1) if video_id_match else 'unknown'\n\n                    logger.info(f\"‚úÖ {service_name} found video URL!\")\n                    return {\n                        'id': video_id,\n                        'title': 'Instagram Video',\n                        'uploader': 'Instagram User',\n                        'url': video_url,\n                        'thumbnail': '',\n                        'duration': 0,\n                        'view_count': 0,\n                        'platform': 'instagram',\n                        'webpage_url': url,\n                        'formats': [{\n                            'url': video_url,\n                            'format_id': f'scraper_{service_name.lower().replace(\" \", \"_\")}',\n                            'ext': 'mp4',\n                            'quality': 'high'\n                        }]\n                    }\n\n        except Exception as e:\n            logger.debug(f\"Failed to process {service_name} response: {e}\")\n\n        return None\n\n    async def _try_public_api(self, url: str) -> Optional[Dict]:\n        \"\"\"Try Instagram Basic Display API with access token\"\"\"\n        try:\n            import aiohttp\n            import re\n\n            if not settings.INSTAGRAM_ACCESS_TOKEN:\n                logger.debug(\"No Instagram access token available\")\n                return None\n\n            # Extract media ID from URL\n            shortcode_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n            if not shortcode_match:\n                return None\n\n            shortcode = shortcode_match.group(1)\n\n            # Try Instagram Basic Display API with access token\n            # Convert shortcode to media ID first\n            graph_url = f\"https://graph.instagram.com/v21.0/oembed\"\n\n            timeout = aiohttp.ClientTimeout(total=20)\n\n            async with aiohttp.ClientSession(timeout=timeout) as session:\n                # First get media info via oEmbed\n                params = {\n                    'url': url,\n                    'access_token': settings.INSTAGRAM_ACCESS_TOKEN\n                }\n\n                async with session.get(graph_url, params=params) as response:\n                    if response.status == 200:\n                        oembed_data = await response.json()\n\n                        # Extract media ID from oEmbed response\n                        media_id = None\n                        if 'media_id' in oembed_data:\n                            media_id = oembed_data['media_id']\n\n                        if media_id:\n                            # Get media details using Graph API\n                            media_url = f\"https://graph.instagram.com/v21.0/{media_id}\"\n                            media_params = {\n                                'fields': 'id,media_type,media_url,thumbnail_url,caption,username,timestamp,permalink',\n                                'access_token': settings.INSTAGRAM_ACCESS_TOKEN\n                            }\n\n                            async with session.get(media_url, params=media_params) as media_response:\n                                if media_response.status == 200:\n                                    media_data = await media_response.json()\n\n                                    if media_data.get('media_type') == 'VIDEO':\n                                        video_url = media_data.get('media_url')\n\n                                        if video_url:\n                                            return {\n                                                'id': shortcode,\n                                                'title': media_data.get('caption', 'Instagram Video')[:100] or 'Instagram Video',\n                                                'uploader': media_data.get('username', 'Instagram User'),\n                                                'url': video_url,\n                                                'thumbnail': media_data.get('thumbnail_url', ''),\n                                                'duration': 0,\n                                                'view_count': 0,\n                                                'platform': 'instagram',\n                                                'webpage_url': url,\n                                                'formats': [{\n                                                    'url': video_url,\n                                                    'format_id': 'instagram_graph_api',\n                                                    'ext': 'mp4',\n                                                    'quality': 'high'\n                                                }]\n                                            }\n\n        except Exception as e:\n            logger.debug(f\"Instagram Graph API failed: {e}\")\n\n        return None\n\n    async def _try_facebook_api(self, url: str) -> Optional[Dict]:\n        \"\"\"Try Facebook Graph API for better access\"\"\"\n        try:\n            import re\n            import aiohttp\n\n            # Extract video ID from URL\n            video_id_match = re.search(r'(?:watch.*v=|videos/)(\\d+)', url)\n            if not video_id_match:\n                return None\n\n            video_id = video_id_match.group(1)\n\n            # Use Facebook Graph API\n            api_url = f\"https://graph.facebook.com/v18.0/{video_id}\"\n            params = {\n                'fields': 'id,source,description,created_time,permalink_url',\n                'access_token': settings.FACEBOOK_ACCESS_TOKEN\n            }\n\n            async with aiohttp.ClientSession() as session:\n                async with session.get(api_url, params=params) as response:\n                    if response.status == 200:\n                        data = await response.json()\n\n                        # Convert API response to yt-dlp format\n                        processed_info = {\n                            'id': data.get('id', video_id),\n                            'title': data.get('description', 'Facebook Video')[:100] or 'Facebook Video',\n                            'uploader': 'Facebook User',\n                            'url': data.get('source', ''),\n                            'duration': 0,  # API might not provide duration\n                            'view_count': 0,\n                            'platform': 'facebook',\n                            'webpage_url': url,\n                            'formats': [{\n                                'url': data.get('source', ''),\n                                'format_id': 'api',\n                                'ext': 'mp4',\n                                'quality': 'unknown'\n                            }] if data.get('source') else []\n                        }\n\n                        return processed_info\n\n        except Exception as e:\n            logger.debug(f\"Facebook API extraction failed: {e}\")\n\n        return None\n\n    async def _try_alternative_extraction(self, url: str, platform: str) -> Optional[Dict]:\n        \"\"\"Try alternative extraction methods with different settings\"\"\"\n        try:\n            # Try with generic extractor and different user agent\n            alt_opts = {\n                'quiet': True,\n                'no_warnings': True,\n                'extract_flat': False,\n                'skip_download': True,\n                'http_headers': {\n                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',\n                    'Accept': '*/*',\n                    'Accept-Language': 'en-US,en;q=0.9',\n                },\n                'socket_timeout': 20,\n                'retries': 1,\n            }\n\n            # Extract with alternative settings\n            loop = asyncio.get_event_loop()\n            info = await loop.run_in_executor(\n                self.executor,\n                self._extract_info_sync,\n                url,\n                alt_opts\n            )\n\n            if info:\n                return await self._process_video_info(info, platform)\n\n        except Exception as e:\n            logger.debug(f\"Alternative extraction failed: {e}\")\n\n        return None\n\n    async def _process_video_info(self, info: Dict, platform: str) -> Dict[str, Any]:\n        \"\"\"Process and format video information\"\"\"\n        # Extract basic info\n        title = info.get('title', 'Unknown Title')\n        uploader = info.get('uploader', 'Unknown')\n        duration = info.get('duration', 0)\n        view_count = info.get('view_count', 0)\n        upload_date = info.get('upload_date', '')\n        description = info.get('description', '')[:500] + '...' if info.get('description', '') else ''\n\n        # Extract thumbnail\n        thumbnail = None\n        if info.get('thumbnails'):\n            # Get highest quality thumbnail\n            thumbnails = sorted(info['thumbnails'], key=lambda x: x.get('preference', 0), reverse=True)\n            thumbnail = thumbnails[0].get('url') if thumbnails else None\n\n        # Extract and process formats\n        formats = await self._extract_formats(info)\n\n        # Extract audio formats\n        audio_formats = await self._extract_audio_formats(info)\n\n        return {\n            'title': sanitize_filename(title),\n            'uploader': uploader,\n            'duration': duration,\n            'view_count': view_count,\n            'upload_date': upload_date,\n            'description': description,\n            'thumbnail': thumbnail,\n            'platform': platform,\n            'formats': formats,\n            'audio_formats': audio_formats,\n            'original_url': info.get('original_url', info.get('webpage_url', '')),\n            'id': info.get('id', ''),\n            'extracted_at': time.time()\n        }\n\n    async def _extract_formats(self, info: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Extract and process video formats\"\"\"\n        formats = []\n\n        if not info.get('formats'):\n            return formats\n\n        # Filter and sort video formats\n        video_formats = [\n            f for f in info['formats']\n            if f.get('vcodec') != 'none' and f.get('height')\n        ]\n\n        # Group by quality and select best (prioritize MP4)\n        quality_groups = {}\n        for fmt in video_formats:\n            height = fmt.get('height', 0)\n            ext = fmt.get('ext', 'mp4')\n\n            if height >= 144:  # Minimum quality\n                key = f\"{height}p\"\n\n                # If no format exists for this quality, add it\n                if key not in quality_groups:\n                    quality_groups[key] = fmt\n                else:\n                    current_fmt = quality_groups[key]\n                    current_ext = current_fmt.get('ext', '')\n                    current_tbr = current_fmt.get('tbr', 0)\n                    new_tbr = fmt.get('tbr', 0)\n\n                    # Prioritize MP4 format, then higher bitrate\n                    should_replace = False\n\n                    # Ensure bitrates are valid numbers\n                    current_tbr = current_tbr or 0\n                    new_tbr = new_tbr or 0\n\n                    if ext == 'mp4' and current_ext != 'mp4':\n                        # New format is MP4 and current is not - prefer MP4\n                        should_replace = True\n                    elif ext == current_ext:\n                        # Same format, choose higher bitrate\n                        should_replace = new_tbr > current_tbr\n                    elif current_ext != 'mp4' and new_tbr > current_tbr:\n                        # Neither is MP4, choose higher bitrate\n                        should_replace = True\n\n                    if should_replace:\n                        quality_groups[key] = fmt\n\n        # Convert to list and add size estimates\n        for quality, fmt in quality_groups.items():\n            file_size = fmt.get('filesize') or fmt.get('filesize_approx', 0)\n\n            formats.append({\n                'format_id': fmt.get('format_id', ''),\n                'quality': quality,\n                'ext': fmt.get('ext', 'mp4'),\n                'file_size': file_size,\n                'file_size_str': format_file_size(file_size) if file_size else 'Unknown',\n                'tbr': fmt.get('tbr', 0),\n                'vbr': fmt.get('vbr', 0),\n                'abr': fmt.get('abr', 0),\n                'fps': fmt.get('fps', 0),\n                'width': fmt.get('width', 0),\n                'height': fmt.get('height', 0),\n                'codec': fmt.get('vcodec', 'unknown')\n            })\n\n        # Sort by quality (highest first)\n        formats.sort(key=lambda x: int(x['quality'].replace('p', '')), reverse=True)\n\n        return formats[:10]  # Limit to top 10 formats\n\n    async def _extract_audio_formats(self, info: Dict) -> List[Dict[str, Any]]:\n        \"\"\"Extract audio-only formats\"\"\"\n        audio_formats = []\n\n        if not info.get('formats'):\n            return audio_formats\n\n        # Filter audio-only formats\n        audio_only = [\n            f for f in info['formats']\n            if f.get('acodec') != 'none' and f.get('vcodec') == 'none'\n        ]\n\n        # Group by quality\n        quality_groups = {}\n        for fmt in audio_only:\n            abr = fmt.get('abr', 0)\n            if abr > 0:\n                key = f\"{abr}kbps\"\n                if key not in quality_groups or fmt.get('tbr', 0) > quality_groups[key].get('tbr', 0):\n                    quality_groups[key] = fmt\n\n        # Convert to list\n        for quality, fmt in quality_groups.items():\n            file_size = fmt.get('filesize') or fmt.get('filesize_approx', 0)\n\n            audio_formats.append({\n                'format_id': fmt.get('format_id', ''),\n                'quality': quality,\n                'ext': fmt.get('ext', 'mp3'),\n                'file_size': file_size,\n                'file_size_str': format_file_size(file_size) if file_size else 'Unknown',\n                'abr': fmt.get('abr', 0),\n                'acodec': fmt.get('acodec', 'unknown')\n            })\n\n        # Sort by quality (highest first)\n        audio_formats.sort(key=lambda x: x['abr'], reverse=True)\n\n        return audio_formats[:5]  # Limit to top 5 audio formats\n\n    async def download_video(\n        self,\n        url: str,\n        format_id: str,\n        user_id: int,\n        is_audio: bool = False,\n        progress_callback: Optional[Callable] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Download video with specified format\n        High-performance download with progress tracking\n        \"\"\"\n        async with self.download_semaphore:\n            task_id = generate_task_id()\n\n            try:\n                logger.info(f\"üì• Starting download task {task_id}\")\n\n                # Update progress tracker\n                await self.progress_tracker.update_download_progress(\n                    task_id, 0, 0, \"Initializing download...\"\n                )\n\n                # Get video info\n                video_info = await self.get_video_info(url, user_id)\n\n                # Create temporary file\n                temp_dir = tempfile.mkdtemp(dir=settings.TEMP_DIR)\n                filename = f\"{sanitize_filename(video_info['title'])}.%(ext)s\"\n                output_path = os.path.join(temp_dir, filename)\n\n                # Configure yt-dlp options for download\n                ydl_opts = self._get_download_opts(format_id, output_path, is_audio, task_id)\n\n                # For Instagram, try direct API download first\n                if get_platform_from_url(url) == 'instagram':\n                    logger.info(\"üéØ Attempting Instagram direct download...\")\n                    direct_result = await self._try_instagram_direct_download(url, task_id, temp_dir, video_info)\n                    if direct_result:\n                        logger.info(\"‚úÖ Instagram direct download successful!\")\n                        return direct_result\n                    else:\n                        logger.info(\"‚ö†Ô∏è Instagram direct download failed, trying yt-dlp...\")\n\n                # Start download in thread pool\n                loop = asyncio.get_event_loop()\n                result = await loop.run_in_executor(\n                    self.executor,\n                    self._download_sync,\n                    url,\n                    ydl_opts,\n                    task_id\n                )\n\n                if not result or not result.get('file_path') or not os.path.exists(result['file_path']):\n                    # Try to find downloaded file in temp directory\n                    downloaded_files = []\n                    for root, dirs, files in os.walk(temp_dir):\n                        for file in files:\n                            if not file.endswith(('.info.json', '.image', '.description', '.annotations.xml')):\n                                downloaded_files.append(os.path.join(root, file))\n\n                    if downloaded_files:\n                        # Use the first valid file found\n                        result = {'file_path': downloaded_files[0]}\n                        logger.info(f\"üìÅ Found downloaded file: {downloaded_files[0]}\")\n                    else:\n                        raise ValueError(\"Download failed - no file created\")\n\n                # Get final file info\n                file_size = os.path.getsize(result['file_path'])\n\n                # Update final progress\n                await self.progress_tracker.update_download_progress(\n                    task_id, file_size, file_size, \"Download completed\"\n                )\n\n                logger.info(f\"‚úÖ Download completed: {result['file_path']} ({format_file_size(file_size)})\")\n\n                return {\n                    'task_id': task_id,\n                    'file_path': result['file_path'],\n                    'file_size': file_size,\n                    'filename': os.path.basename(result['file_path']),\n                    'video_info': video_info,\n                    'download_time': result.get('download_time', 0),\n                    'average_speed': result.get('average_speed', 0)\n                }\n\n            except Exception as e:\n                await self.progress_tracker.update_download_progress(\n                    task_id, 0, 0, f\"Download failed: {str(e)}\"\n                )\n                logger.error(f\"‚ùå Download failed for task {task_id}: {e}\", exc_info=True)\n                raise\n\n    def _get_download_opts(self, format_id: str, output_path: str, is_audio: bool, task_id: str) -> Dict:\n        \"\"\"Get optimized yt-dlp download options\"\"\"\n        base_opts = settings.get_ytdl_opts().copy()\n\n        # Update with specific options\n        base_opts.update({\n            'outtmpl': output_path,\n            'progress_hooks': [self._create_progress_hook(task_id)],\n            'postprocessor_hooks': [self._create_postprocessor_hook(task_id)],\n        })\n\n        if is_audio:\n            # Audio-only download with conversion\n            base_opts.update({\n                'format': format_id,\n                'postprocessors': [{\n                    'key': 'FFmpegExtractAudio',\n                    'preferredcodec': 'mp3',\n                    'preferredquality': '192',\n                }],\n            })\n        else:\n            # Video download with format preference\n            # If format_id contains specific format, use it directly\n            # Otherwise, try to get MP4 version if possible\n            if '+' in format_id or format_id.endswith('[ext=mp4]'):\n                base_opts['format'] = format_id\n            else:\n                # Try to get MP4 version first, fallback to original format\n                base_opts['format'] = f\"{format_id}[ext=mp4]/{format_id}/best[ext=mp4]/best\"\n\n            # Ensure we get video with audio when possible\n            base_opts['merge_output_format'] = 'mp4'\n\n        return base_opts\n\n    def _create_progress_hook(self, task_id: str):\n        \"\"\"Create progress hook for yt-dlp\"\"\"\n        def progress_hook(d):\n            if d['status'] == 'downloading':\n                total = d.get('total_bytes', 0) or d.get('total_bytes_estimate', 0)\n                downloaded = d.get('downloaded_bytes', 0)\n\n                # Update progress tracker safely from thread\n                try:\n                    # Try to get the running loop\n                    try:\n                        loop = asyncio.get_running_loop()\n                        # Schedule the coroutine to run in the event loop\n                        asyncio.run_coroutine_threadsafe(\n                            self.progress_tracker.update_download_progress(\n                                task_id, downloaded, total, \"Downloading...\"\n                            ), loop\n                        )\n                    except RuntimeError:\n                        # No running loop, skip progress update\n                        pass\n                except Exception as e:\n                    # Silently handle progress update errors\n                    logger.debug(f\"Progress update error: {e}\")\n\n        return progress_hook\n\n    def _create_postprocessor_hook(self, task_id: str):\n        \"\"\"Create postprocessor hook for yt-dlp\"\"\"\n        def postprocessor_hook(d):\n            if d['status'] == 'processing':\n                try:\n                    # Try to get the running loop\n                    try:\n                        loop = asyncio.get_running_loop()\n                        # Schedule the coroutine to run in the event loop\n                        asyncio.run_coroutine_threadsafe(\n                            self.progress_tracker.update_download_progress(\n                                task_id, 0, 0, \"Processing...\"\n                            ), loop\n                        )\n                    except RuntimeError:\n                        # No running loop, skip progress update\n                        pass\n                except Exception as e:\n                    # Silently handle progress update errors\n                    logger.debug(f\"Progress update error: {e}\")\n\n        return postprocessor_hook\n\n    def _download_sync(self, url: str, ydl_opts: Dict, task_id: str) -> Dict[str, Any]:\n        \"\"\"Synchronous download for thread pool\"\"\"\n        start_time = time.time()\n        downloaded_file = None\n        expected_filename = None\n\n        try:\n            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n                # Extract info to get filename\n                info = ydl.extract_info(url, download=False)\n\n                if info is not None and isinstance(info, dict):\n                    try:\n                        expected_filename = ydl.prepare_filename(info)\n                        # Ensure expected_filename is a string\n                        if not isinstance(expected_filename, str):\n                            raise ValueError(\"prepare_filename returned non-string\")\n                    except Exception as e:\n                        logger.warning(f\"‚ö†Ô∏è Failed to prepare filename: {e}\")\n                        expected_filename = os.path.join(settings.TEMP_DIR, f\"video_{task_id}.%(ext)s\")\n                else:\n                    # If info extraction failed, create a generic filename\n                    logger.warning(\"‚ö†Ô∏è Failed to extract info, using generic filename\")\n                    expected_filename = os.path.join(settings.TEMP_DIR, f\"video_{task_id}.mp4\")\n\n                # Download the file\n                ydl.download([url])\n\n                # Find the actual downloaded file\n                downloaded_file = self._find_downloaded_file(expected_filename)\n\n            download_time = time.time() - start_time\n            file_size = os.path.getsize(downloaded_file) if downloaded_file else 0\n            average_speed = file_size / download_time if download_time > 0 else 0\n\n            return {\n                'file_path': downloaded_file,\n                'download_time': download_time,\n                'average_speed': average_speed\n            }\n\n        except Exception as e:\n            logger.error(f\"Sync download error for task {task_id}: {e}\")\n            raise\n\n    def _find_downloaded_file(self, expected_filename: Optional[str]) -> Optional[str]:\n        \"\"\"Find the actual downloaded file (prioritizes video over images)\"\"\"\n        # Validate input type\n        if expected_filename is not None and not isinstance(expected_filename, str):\n            logger.error(f\"‚ùå expected_filename must be string, got {type(expected_filename)}: {expected_filename}\")\n            expected_filename = None\n\n        if not expected_filename:\n            # If no expected filename, search temp directory for any downloaded files\n            temp_dir = settings.TEMP_DIR\n            for root, dirs, files in os.walk(temp_dir):\n                for file in files:\n                    # Skip info and metadata files\n                    if not file.endswith(('.info.json', '.image', '.description', '.annotations.xml', '.jpg', '.jpeg', '.png', '.webp')):\n                        if any(file.endswith(ext) for ext in ['.mp4', '.webm', '.mkv', '.avi', '.flv', '.3gp', '.mp3', '.m4a', '.ogg', '.wav', '.aac']):\n                            return os.path.join(root, file)\n            return None\n\n        # Ensure it's a valid string path\n        try:\n            if os.path.exists(expected_filename):\n                return expected_filename\n        except (TypeError, OSError) as e:\n            logger.error(f\"‚ùå Invalid path format: {e}\")\n            return None\n\n        # Check for common video extension variations first (prioritize video files)\n        base_name = os.path.splitext(expected_filename)[0]\n        video_extensions = ['.mp4', '.webm', '.mkv', '.avi', '.mov', '.flv', '.3gp']\n        audio_extensions = ['.mp3', '.m4a', '.ogg', '.wav', '.aac']\n\n        # First pass: Look for video files\n        for ext in video_extensions:\n            test_path = base_name + ext\n            if os.path.exists(test_path):\n                return test_path\n\n        # Second pass: Look for audio files\n        for ext in audio_extensions:\n            test_path = base_name + ext\n            if os.path.exists(test_path):\n                return test_path\n\n        # Check directory for any file with similar name (prioritize video/audio over images)\n        directory = os.path.dirname(expected_filename)\n        base_filename = os.path.basename(base_name)\n\n        if os.path.exists(directory):\n            video_files = []\n            audio_files = []\n            other_files = []\n\n            for file in os.listdir(directory):\n                if file.startswith(base_filename):\n                    file_path = os.path.join(directory, file)\n                    file_ext = os.path.splitext(file)[1].lower()\n\n                    # Skip thumbnail and info files\n                    if file_ext in ['.jpg', '.jpeg', '.png', '.webp', '.image'] or \\\n                       file.endswith('.info.json') or '.thumb.' in file:\n                        continue\n\n                    if file_ext in video_extensions:\n                        video_files.append(file_path)\n                    elif file_ext in audio_extensions:\n                        audio_files.append(file_path)\n                    else:\n                        other_files.append(file_path)\n\n            # Return in priority order: video > audio > other\n            if video_files:\n                return video_files[0]\n            elif audio_files:\n                return audio_files[0]\n            elif other_files:\n                return other_files[0]\n\n        return None\n\n    async def get_download_progress(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"Get current download progress\"\"\"\n        return await self.progress_tracker.get_download_progress(task_id)\n\n    async def cancel_download(self, task_id: str) -> bool:\n        \"\"\"Cancel an ongoing download\"\"\"\n        try:\n            # Mark as cancelled in progress tracker\n            await self.progress_tracker.update_download_progress(\n                task_id, 0, 0, \"Cancelled by user\"\n            )\n\n            # Note: yt-dlp doesn't have built-in cancellation,\n            # but we can mark it as cancelled for UI purposes\n            logger.info(f\"üìù Download task {task_id} marked as cancelled\")\n            return True\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to cancel download {task_id}: {e}\")\n            return False\n\n    async def cleanup_temp_files(self, max_age_hours: int = 1):\n        \"\"\"Clean up old temporary files\"\"\"\n        try:\n            current_time = time.time()\n            max_age_seconds = max_age_hours * 3600\n\n            temp_dir = settings.TEMP_DIR\n            if not os.path.exists(temp_dir):\n                return\n\n            for root, dirs, files in os.walk(temp_dir):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    try:\n                        file_age = current_time - os.path.getctime(file_path)\n                        if file_age > max_age_seconds:\n                            os.remove(file_path)\n                            logger.debug(f\"üóëÔ∏è Cleaned up old file: {file_path}\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to clean up file {file_path}: {e}\")\n\n            logger.info(f\"‚úÖ Temporary files cleanup completed\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Cleanup failed: {e}\")\n\n    async def get_supported_sites(self) -> List[str]:\n        \"\"\"Get list of supported extraction sites\"\"\"\n        try:\n            loop = asyncio.get_event_loop()\n            extractors = await loop.run_in_executor(\n                self.executor,\n                lambda: yt_dlp.list_extractors()\n            )\n            return [str(extractor.IE_NAME) for extractor in extractors if hasattr(extractor, 'IE_NAME')]\n        except Exception as e:\n            logger.error(f\"Failed to get supported sites: {e}\")\n            return settings.YTDL_EXTRACTORS\n\n    async def get_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get current performance statistics\"\"\"\n        return {\n            'active_downloads': len(self.download_stats),\n            'max_concurrent_downloads': settings.MAX_CONCURRENT_DOWNLOADS,\n            'queue_size': self.download_semaphore._value,\n            'executor_threads': self.executor._max_workers,\n            'temp_dir_size': await self._get_temp_dir_size(),\n        }\n\n    async def _get_temp_dir_size(self) -> int:\n        \"\"\"Get total size of temporary directory\"\"\"\n        try:\n            total_size = 0\n            for root, dirs, files in os.walk(settings.TEMP_DIR):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    try:\n                        total_size += os.path.getsize(file_path)\n                    except OSError:\n                        pass\n            return total_size\n        except Exception:\n            return 0\n\n    def load_instagram_session(self):\n        \"\"\"Load Instagram session cookies from file (fallback only)\"\"\"\n        try:\n            if os.path.exists(self.instagram_session_file):\n                with open(self.instagram_session_file, 'r') as f:\n                    session_data = json.load(f)\n                    self.instagram_cookies = session_data.get('cookies', {})\n                    logger.info(\"‚úÖ Instagram session loaded from file (fallback)\")\n            else:\n                logger.info(\"‚ÑπÔ∏è No Instagram session file found\")\n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è Failed to load Instagram session from file: {e}\")\n\n    def _load_youtube_cookies(self):\n        \"\"\"Load YouTube cookies from settings or environment variables\"\"\"\n        try:\n            # Prefer cookies from settings if available\n            if settings.YOUTUBE_COOKIES:\n                self.youtube_cookies = self._parse_cookies(settings.YOUTUBE_COOKIES)\n                if self.youtube_cookies:\n                    logger.info(f\"‚úÖ YouTube cookies loaded from settings ({len(self.youtube_cookies)} cookies)\")\n                    return\n                else:\n                    logger.warning(\"‚ö†Ô∏è YouTube cookies from settings are invalid or empty.\")\n\n            # Fallback to environment variables if settings are not used or invalid\n            env_cookies = {}\n            if hasattr(settings, 'YOUTUBE_SESSION_TOKEN') and settings.YOUTUBE_SESSION_TOKEN:\n                env_cookies['session_token'] = settings.YOUTUBE_SESSION_TOKEN\n            if hasattr(settings, 'YOUTUBE_AUTH_TOKEN') and settings.YOUTUBE_AUTH_TOKEN:\n                env_cookies['auth_token'] = settings.YOUTUBE_AUTH_TOKEN\n\n            if env_cookies:\n                self.youtube_cookies.update(env_cookies)\n                logger.info(f\"‚úÖ YouTube cookies loaded from environment variables ({len(env_cookies)} cookies)\")\n            else:\n                # Default YouTube cookies as fallback\n                default_cookies = {\n                    'YSC': 'S2HI9zX0Wec',\n                    'PREF': 'tz=Asia.Riyadh',\n                    'VISITOR_INFO1_LIVE': 'XokcjcRzkoQ'\n                }\n                self.youtube_cookies.update(default_cookies)\n                logger.info(f\"‚úÖ YouTube cookies loaded from default values ({len(default_cookies)} cookies)\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to load YouTube cookies: {e}\")\n\n    def _load_cookies_from_env(self):\n        \"\"\"Load Instagram cookies from environment variables\"\"\"\n        try:\n            env_cookies = {}\n\n            # Load sessionid from environment\n            if settings.INSTAGRAM_SESSIONID:\n                # URL decode the sessionid if needed\n                import urllib.parse\n                sessionid = urllib.parse.unquote(settings.INSTAGRAM_SESSIONID)\n                env_cookies['sessionid'] = sessionid\n                logger.info(f\"‚úÖ Instagram sessionid loaded from environment: {sessionid[:20]}...\")\n\n            # Load csrftoken from environment  \n            if settings.INSTAGRAM_CSRFTOKEN:\n                env_cookies['csrftoken'] = settings.INSTAGRAM_CSRFTOKEN\n                logger.info(f\"‚úÖ Instagram csrftoken loaded from environment: {settings.INSTAGRAM_CSRFTOKEN}\")\n\n            # If we have env cookies, they take precedence over file cookies\n            if env_cookies:\n                self.instagram_cookies.update(env_cookies)\n                logger.info(f\"‚úÖ Instagram cookies loaded from environment! ({len(env_cookies)} cookies)\")\n\n                # Save to file for backup\n                self.save_instagram_session()\n            else:\n                logger.info(\"‚ÑπÔ∏è No Instagram cookies found in environment variables\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to load Instagram cookies from environment: {e}\")\n\n\n\n    def save_instagram_session(self):\n        \"\"\"Save Instagram session cookies to file\"\"\"\n        try:\n            session_data = {\n                'cookies': self.instagram_cookies,\n                'last_updated': time.time()\n            }\n            with open(self.instagram_session_file, 'w') as f:\n                json.dump(session_data, f, indent=2)\n            logger.info(\"‚úÖ Instagram session saved successfully\")\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to save Instagram session: {e}\")\n\n    async def login_instagram_with_cookies(self, cookies_text: str) -> bool:\n        \"\"\"Login to Instagram using provided cookies\"\"\"\n        try:\n            logger.info(\"üîê Attempting Instagram login with provided cookies...\")\n\n            # Parse cookies from different formats\n            parsed_cookies = self._parse_cookies(cookies_text)\n            if not parsed_cookies:\n                logger.error(\"‚ùå Failed to parse cookies\")\n                return False\n\n            # Test cookies by making a request\n            success = await self._test_instagram_cookies(parsed_cookies)\n            if success:\n                self.instagram_cookies.update(parsed_cookies)\n                self.save_instagram_session()\n                logger.info(\"‚úÖ Instagram login successful!\")\n                return True\n            else:\n                logger.error(\"‚ùå Invalid or expired cookies\")\n                return False\n\n        except Exception as e:\n            logger.error(f\"‚ùå Instagram login failed: {e}\")\n            return False\n\n    def _parse_cookies(self, cookies_text: str) -> Dict[str, str]:\n        \"\"\"Parse cookies from various formats with enhanced URL decoding\"\"\"\n        cookies = {}\n\n        logger.info(f\"Parsing cookies text: {cookies_text[:100]}...\")\n\n        try:\n            import urllib.parse\n\n            # Try parsing as JSON first\n            if cookies_text.strip().startswith('{'):\n                json_cookies = json.loads(cookies_text)\n                if isinstance(json_cookies, dict):\n                    return json_cookies\n                elif isinstance(json_cookies, list):\n                    for cookie in json_cookies:\n                        if 'name' in cookie and 'value' in cookie:\n                            cookies[cookie['name']] = cookie['value']\n                    return cookies\n\n            # Try parsing as Netscape format\n            if 'instagram.com' in cookies_text.lower():\n                lines = cookies_text.strip().split('\\n')\n                for line in lines:\n                    if line.startswith('#') or not line.strip():\n                        continue\n                    parts = line.split('\\t')\n                    if len(parts) >= 7:\n                        name, value = parts[5], parts[6]\n                        # URL decode properly\n                        try:\n                            value = urllib.parse.unquote(value)\n                        except:\n                            pass\n                        cookies[name] = value\n                return cookies\n\n            # Enhanced raw cookie header format parsing\n            if '=' in cookies_text:\n                # Remove any trailing semicolon\n                cookies_text = cookies_text.strip().rstrip(';')\n                cookie_pairs = cookies_text.split(';')\n\n                for pair in cookie_pairs:\n                    pair = pair.strip()\n                    if '=' in pair:\n                        name, value = pair.split('=', 1)\n                        name = name.strip()\n                        value = value.strip()\n\n                        if name and value:\n                            # Multiple stage URL decoding for complex values\n                            original_value = value\n                            try:\n                                # First decode\n                                value = urllib.parse.unquote(value)\n                                # Check if it needs another decode (double encoded)\n                                if '%' in value:\n                                    decoded_again = urllib.parse.unquote(value)\n                                    if decoded_again != value:\n                                        value = decoded_again\n                            except Exception as decode_e:\n                                logger.debug(f\"URL decode failed for {name}: {decode_e}, using original\")\n                                value = original_value\n\n                            cookies[name] = value\n                            logger.debug(f\"Parsed cookie: {name}={value[:20]}...\")\n\n            # Special handling for Instagram session format\n            if 'sessionid=' in cookies_text and 'csrftoken=' in cookies_text:\n                import re\n\n                # Extract sessionid\n                sessionid_match = re.search(r'sessionid=([^;]+)', cookies_text)\n                if sessionid_match:\n                    sessionid = sessionid_match.group(1).strip()\n                    try:\n                        sessionid = urllib.parse.unquote(sessionid)\n                        cookies['sessionid'] = sessionid\n                        logger.info(f\"Extracted sessionid: {sessionid[:20]}...\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to decode sessionid: {e}\")\n\n                # Extract csrftoken\n                csrf_match = re.search(r'csrftoken=([^;]+)', cookies_text)\n                if csrf_match:\n                    csrf = csrf_match.group(1).strip()\n                    cookies['csrftoken'] = csrf\n                    logger.info(f\"Extracted csrftoken: {csrf}\")\n\n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è Failed to parse cookies: {e}\")\n\n        return cookies\n\n    async def _test_instagram_cookies(self, cookies: Dict[str, str]) -> bool:\n        \"\"\"Test if Instagram cookies are valid\"\"\"\n        try:\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n                'Accept-Language': 'en-US,en;q=0.5',\n                'Accept-Encoding': 'gzip, deflate, br',\n                'DNT': '1',\n                'Connection': 'keep-alive',\n                'Upgrade-Insecure-Requests': '1',\n                'Sec-Fetch-Dest': 'document',\n                'Sec-Fetch-Mode': 'navigate',\n                'Sec-Fetch-Site': 'none',\n                'Sec-Fetch-User': '?1',\n                'Cache-Control': 'max-age=0',\n            }\n\n            # Convert cookies to proper format\n            cookie_jar = aiohttp.CookieJar()\n            from yarl import URL\n            for name, value in cookies.items():\n                cookie_jar.update_cookies({name: value}, response_url=URL('https://instagram.com'))\n\n            timeout = aiohttp.ClientTimeout(total=10)\n            async with aiohttp.ClientSession(\n                cookie_jar=cookie_jar,\n                headers=headers,\n                timeout=timeout\n            ) as session:\n                # Test with Instagram's main page\n                async with session.get('https://www.instagram.com/') as response:\n                    if response.status == 200:\n                        content = await response.text()\n                        # Check if we're logged in (look for specific indicators)\n                        if '\"is_logged_in\":true' in content or 'window._sharedData' in content:\n                            logger.info(\"‚úÖ Instagram cookies are valid and user is logged in\")\n                            return True\n                        else:\n                            logger.warning(\"‚ö†Ô∏è Cookies accepted but user may not be fully logged in\")\n                            return True  # Still usable for some content\n\n            return False\n\n        except Exception as e:\n            logger.error(f\"‚ùå Failed to test Instagram cookies: {e}\")\n            return False\n\n    async def _try_instagram_authenticated(self, url: str) -> Optional[Dict]:\n        \"\"\"Try Instagram with authenticated session\"\"\"\n        try:\n            if not self.instagram_cookies:\n                logger.info(\"‚ÑπÔ∏è No Instagram cookies available\")\n                return None\n\n            logger.info(\"üîê Attempting Instagram extraction with authenticated session...\")\n\n            # Extract video ID\n            video_id_match = re.search(r'/(?:p|reel|tv)/([A-Za-z0-9_-]+)', url)\n            if not video_id_match:\n                return None\n\n            video_id = video_id_match.group(1)\n\n            # Advanced headers for authenticated requests\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n                'Accept': '*/*',\n                'Accept-Language': 'en-US,en;q=0.9',\n                'Accept-Encoding': 'gzip, deflate, br',\n                'X-Requested-With': 'XMLHttpRequest',\n                'X-CSRFToken': self.instagram_cookies.get('csrftoken', ''),\n                'X-Instagram-AJAX': '1',\n                'X-IG-App-ID': '936619743392459',\n                'X-IG-WWW-Claim': '0',\n                'Origin': 'https://www.instagram.com',\n                'Referer': url,\n                'Sec-Fetch-Dest': 'empty',\n                'Sec-Fetch-Mode': 'cors',\n                'Sec-Fetch-Site': 'same-origin',\n            }\n\n            # Create cookie jar\n            cookie_jar = aiohttp.CookieJar()\n            from yarl import URL\n            for name, value in self.instagram_cookies.items():\n                cookie_jar.update_cookies({name: value}, response_url=URL('https://instagram.com'))\n\n            timeout = aiohttp.ClientTimeout(total=15)\n            # Create connector with proper encoding support\n            connector = aiohttp.TCPConnector(\n                enable_cleanup_closed=True,\n                limit=20,\n                limit_per_host=5\n            )\n\n            async with aiohttp.ClientSession(\n                cookie_jar=cookie_jar,\n                headers=headers,\n                timeout=timeout,\n                connector=connector\n            ) as session:\n\n                # Try GraphQL API endpoint\n                graphql_url = f\"https://www.instagram.com/api/v1/media/{video_id}/info/\"\n                async with session.get(graphql_url) as response:\n                    if response.status == 200:\n                        data = await response.json()\n                        if 'items' in data and len(data['items']) > 0:\n                            item = data['items'][0]\n\n                            # Extract video URL\n                            video_url = None\n                            if 'video_versions' in item and len(item['video_versions']) > 0:\n                                video_url = item['video_versions'][0]['url']\n\n                            if video_url:\n                                processed_info = {\n                                    'id': video_id,\n                                    'title': item.get('caption', {}).get('text', 'Instagram Video')[:100] or 'Instagram Video',\n                                    'uploader': item.get('user', {}).get('username', 'Instagram User'),\n                                    'url': video_url,\n                                    'thumbnail': item.get('image_versions2', {}).get('candidates', [{}])[0].get('url', ''),\n                                    'duration': item.get('video_duration', 0),\n                                    'view_count': item.get('view_count', 0),\n                                    'platform': 'instagram',\n                                    'webpage_url': url,\n                                    'formats': [{\n                                        'url': video_url,\n                                        'format_id': 'authenticated',\n                                        'ext': 'mp4',\n                                        'quality': 'high'\n                                    }]\n                                }\n\n                                logger.info(\"‚úÖ Instagram authenticated extraction successful!\")\n                                return processed_info\n\n                # Fallback: Try web interface with authentication\n                async with session.get(url) as response:\n                    if response.status == 200:\n                        content = await response.text()\n\n                        # Extract from window._sharedData\n                        pattern = r'window\\._sharedData\\s*=\\s*({.+?});'\n                        match = re.search(pattern, content)\n                        if match:\n                            try:\n                                shared_data = json.loads(match.group(1))\n                                entry_data = shared_data.get('entry_data', {})\n\n                                # Check different possible locations\n                                for page_type in ['PostPage', 'ProfilePage']:\n                                    if page_type in entry_data:\n                                        for post in entry_data[page_type][0].get('graphql', {}).get('shortcode_media', []):\n                                            if post.get('video_url'):\n                                                processed_info = {\n                                                    'id': video_id,\n                                                    'title': post.get('edge_media_to_caption', {}).get('edges', [{}])[0].get('node', {}).get('text', 'Instagram Video')[:100] or 'Instagram Video',\n                                                    'uploader': post.get('owner', {}).get('username', 'Instagram User'),\n                                                    'url': post['video_url'],\n                                                    'thumbnail': post.get('display_url', ''),\n                                                    'duration': post.get('video_duration', 0),\n                                                    'view_count': post.get('video_view_count', 0),\n                                                    'platform': 'instagram',\n                                                    'webpage_url': url,\n                                                    'formats': [{\n                                                        'url': post['video_url'],\n                                                        'format_id': 'web_authenticated',\n                                                        'ext': 'mp4',\n                                                        'quality': 'high'\n                                                    }]\n                                                }\n\n                                                logger.info(\"‚úÖ Instagram web authenticated extraction successful!\")\n                                                return processed_info\n\n                            except json.JSONDecodeError:\n                                pass\n\n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è Instagram authenticated extraction failed: {e}\")\n\n        return None\n\n    async def _try_instagram_direct_download(self, url: str, task_id: str, temp_dir: str, video_info: dict) -> Optional[Dict[str, Any]]:\n        \"\"\"Try to download Instagram video using direct API methods\"\"\"\n        try:\n            logger.info(\"üéØ Attempting Instagram direct API download\")\n            api_info = await self._try_instagram_api(url)\n            if not api_info or not api_info.get(\"url\"):\n                return None\n\n            video_url = api_info[\"url\"]\n            title = api_info.get(\"title\", video_info.get(\"title\", \"Instagram Video\"))\n\n            import aiohttp, aiofiles, re\n            safe_title = re.sub(r\"[^\\w\\s-]\", \"\", title).strip()[:50]\n            filename = f\"{safe_title}_{task_id}.mp4\"\n            file_path = os.path.join(temp_dir, filename)\n\n            timeout = aiohttp.ClientTimeout(total=300)\n            headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"}\n\n            async with aiohttp.ClientSession(timeout=timeout) as session:\n                async with session.get(video_url, headers=headers) as response:\n                    if response.status == 200:\n                        async with aiofiles.open(file_path, \"wb\") as f:\n                            async for chunk in response.content.iter_chunked(8192):\n                                await f.write(chunk)\n\n                        file_size = os.path.getsize(file_path)\n                        logger.info(f\"‚úÖ Instagram API download successful: {file_path}\")\n                        return {\n                            \"task_id\": task_id,\n                            \"file_path\": file_path,\n                            \"file_size\": file_size,\n                            \"filename\": os.path.basename(file_path),\n                            \"video_info\": {\"title\": title, \"uploader\": api_info.get(\"uploader\", \"Instagram User\"), \"platform\": \"instagram\"},\n                            \"download_time\": 0,\n                            \"average_speed\": 0\n                        }\n        except Exception as e:\n            logger.error(f\"‚ùå Instagram direct download failed: {e}\")\n        return None","size_bytes":105735},"services/file_manager.py":{"content":"\"\"\"\nHigh-performance file manager for handling uploads, downloads, and file operations\nIntegrates with Telethon for 2GB file support and FastTelethon optimization\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nimport shutil\nimport tempfile\nimport time\nfrom typing import Dict, Any, Optional, Callable, List\nfrom pathlib import Path\nimport hashlib\nimport mimetypes\n\nfrom core.telethon_client import TelethonManager\nfrom services.progress_tracker import ProgressTracker\nfrom config.settings import settings\nfrom utils.helpers import format_file_size, generate_task_id, get_file_hash\nfrom utils.formatters import format_duration, format_upload_time\n\nlogger = logging.getLogger(__name__)\n\nclass FileManager:\n    \"\"\"Ultra high-performance file manager\"\"\"\n    \n    def __init__(self, telethon_manager: TelethonManager, progress_tracker: ProgressTracker):\n        self.telethon_manager = telethon_manager\n        self.progress_tracker = progress_tracker\n        \n        # Ultra-optimized file operation semaphores\n        self.upload_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_UPLOADS)\n        self.process_semaphore = asyncio.Semaphore(16)  # Ultra-parallel processing\n        self.compression_semaphore = asyncio.Semaphore(4)  # Parallel compression\n        \n        # File tracking\n        self.active_uploads: Dict[str, Any] = {}\n        self.upload_history: List[Dict] = []\n        \n        # Optimization settings\n        self.chunk_size = settings.CHUNK_SIZE\n        self.max_file_size = settings.MAX_FILE_SIZE\n        \n        # File integrity checking\n        self.verify_file_integrity = True\n        \n        # Upload speed monitoring and adaptive optimization\n        self.upload_speed_history: List[float] = []\n        self.adaptive_compression = True\n        self.smart_chunking = True\n        self.upload_optimization_enabled = True\n        \n        # Advanced performance features\n        self.parallel_chunk_upload = True\n        self.dynamic_worker_scaling = True\n        self.bandwidth_prediction = True\n        \n    async def upload_to_telegram(\n        self,\n        file_path: str,\n        user_id: int,\n        video_info: Dict[str, Any],\n        format_info: Dict[str, Any],\n        progress_callback: Optional[Callable] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        High-performance upload to Telegram with progress tracking\n        Supports up to 2GB files via Telethon MTProto\n        \"\"\"\n        async with self.upload_semaphore:\n            task_id = generate_task_id()\n            start_time = time.time()\n            \n            try:\n                # Validate file\n                await self._validate_file_for_upload(file_path)\n                \n                # Apply ultra-optimizations before upload\n                optimized_file_path = await self._ultra_optimize_file(file_path, video_info)\n                if optimized_file_path != file_path:\n                    file_path = optimized_file_path\n                    logger.info(f\"üöÄ File optimized for ultra-fast upload\")\n                \n                # Skip file checksum for speed\n                file_checksum = None\n                \n                file_size = os.path.getsize(file_path)\n                filename = os.path.basename(file_path)\n                \n                logger.info(f\"üì§ Starting upload task {task_id}: {filename} ({format_file_size(file_size)})\")\n                \n                # Initialize progress tracking\n                self.active_uploads[task_id] = {\n                    'file_path': file_path,\n                    'file_size': file_size,\n                    'user_id': user_id,\n                    'start_time': start_time,\n                    'status': 'uploading'\n                }\n                \n                await self.progress_tracker.update_upload_progress(\n                    task_id, 0, file_size, \"Preparing upload...\"\n                )\n                \n                # Prepare file metadata\n                video_metadata = await self._extract_video_metadata(file_path, video_info)\n                \n                # Generate thumbnail if needed\n                thumbnail_path = await self._generate_thumbnail(file_path, video_info)\n                \n                # Create progress callback\n                upload_progress_callback = self._create_upload_progress_callback(task_id, file_size)\n                \n                # Prepare caption\n                caption = self._create_file_caption(video_info, format_info, file_size)\n                \n                # Upload to designated chat\n                message = await self.telethon_manager.upload_file(\n                    file_path=file_path,\n                    chat_id=settings.UPLOAD_CHAT_ID,\n                    caption=caption,\n                    progress_callback=upload_progress_callback,\n                    thumbnail=thumbnail_path,\n                    video_metadata=video_metadata\n                )\n                \n                upload_time = time.time() - start_time\n                average_speed = file_size / upload_time if upload_time > 0 else 0\n                \n                # Update progress tracker\n                await self.progress_tracker.update_upload_progress(\n                    task_id, file_size, file_size, \"Upload completed\"\n                )\n                \n                # Update tracking\n                self.active_uploads[task_id]['status'] = 'completed'\n                self.active_uploads[task_id]['message_id'] = message.id\n                self.active_uploads[task_id]['upload_time'] = upload_time\n                self.active_uploads[task_id]['average_speed'] = average_speed\n                \n                # Add to history\n                self.upload_history.append({\n                    'task_id': task_id,\n                    'filename': filename,\n                    'file_size': file_size,\n                    'upload_time': upload_time,\n                    'average_speed': average_speed,\n                    'user_id': user_id,\n                    'timestamp': time.time(),\n                    'message_id': message.id\n                })\n                \n                # Clean up temporary files\n                await self._cleanup_upload_files(file_path, thumbnail_path)\n                \n                logger.info(f\"‚úÖ Upload completed: {filename} in {format_upload_time(upload_time)} \"\n                          f\"(Speed: {format_file_size(average_speed)}/s)\")\n                \n                return {\n                    'task_id': task_id,\n                    'message_id': message.id,\n                    'file_size': file_size,\n                    'upload_time': upload_time,\n                    'average_speed': average_speed,\n                    'chat_id': settings.UPLOAD_CHAT_ID,\n                    'caption': caption\n                }\n                \n            except Exception as e:\n                # Update error status\n                if task_id in self.active_uploads:\n                    self.active_uploads[task_id]['status'] = 'failed'\n                    self.active_uploads[task_id]['error'] = str(e)\n                \n                await self.progress_tracker.update_upload_progress(\n                    task_id, 0, 0, f\"Upload failed: {str(e)}\"\n                )\n                \n                logger.error(f\"‚ùå Upload failed for task {task_id}: {e}\", exc_info=True)\n                raise\n            finally:\n                # Clean up active uploads\n                if task_id in self.active_uploads:\n                    # Move to history or clean up after some time\n                    asyncio.create_task(self._cleanup_active_upload(task_id))\n    \n    async def _validate_file_for_upload(self, file_path: str):\n        \"\"\"Validate file before upload\"\"\"\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"File not found: {file_path}\")\n        \n        file_size = os.path.getsize(file_path)\n        if file_size == 0:\n            raise ValueError(\"File is empty\")\n        \n        if file_size > self.max_file_size:\n            raise ValueError(f\"File too large: {format_file_size(file_size)} > {format_file_size(self.max_file_size)}\")\n        \n        # Check if file is readable\n        try:\n            with open(file_path, 'rb') as f:\n                f.read(1024)  # Read first 1KB to test\n        except Exception as e:\n            raise ValueError(f\"File is not readable: {e}\")\n    \n    async def _extract_video_metadata(self, file_path: str, video_info: Dict) -> Dict[str, Any]:\n        \"\"\"Extract video metadata for Telegram attributes\"\"\"\n        try:\n            # Use video_info from downloader\n            duration = video_info.get('duration', 0)\n            \n            # Get dimensions from format info if available\n            width = 0\n            height = 0\n            \n            # Try to get dimensions from video_info\n            if video_info.get('formats'):\n                for fmt in video_info['formats']:\n                    if fmt.get('width') and fmt.get('height'):\n                        width = fmt['width']\n                        height = fmt['height']\n                        break\n            \n            return {\n                'duration': int(duration) if duration else 0,\n                'width': int(width) if width else 0,\n                'height': int(height) if height else 0,\n                'supports_streaming': True\n            }\n            \n        except Exception as e:\n            logger.warning(f\"Failed to extract video metadata: {e}\")\n            return {'duration': 0, 'width': 0, 'height': 0, 'supports_streaming': True}\n    \n    async def _generate_thumbnail(self, file_path: str, video_info: Dict) -> Optional[str]:\n        \"\"\"Generate thumbnail for video files\"\"\"\n        try:\n            # Check if it's a video file\n            file_ext = os.path.splitext(file_path)[1].lower()\n            if file_ext not in ['.mp4', '.avi', '.mkv', '.mov', '.webm', '.flv']:\n                return None\n            \n            # Use thumbnail from video info if available\n            thumbnail_url = video_info.get('thumbnail')\n            if not thumbnail_url:\n                return None\n            \n            # Download thumbnail\n            import aiohttp\n            async with aiohttp.ClientSession() as session:\n                timeout = aiohttp.ClientTimeout(total=10)\n                async with session.get(thumbnail_url, timeout=timeout) as response:\n                    if response.status == 200:\n                        thumbnail_data = await response.read()\n                        \n                        # Save thumbnail\n                        thumbnail_path = file_path + '.thumb.jpg'\n                        with open(thumbnail_path, 'wb') as f:\n                            f.write(thumbnail_data)\n                        \n                        return thumbnail_path\n            \n        except Exception as e:\n            logger.warning(f\"Failed to generate thumbnail: {e}\")\n        \n        return None\n    \n    def _create_upload_progress_callback(self, task_id: str, total_size: int):\n        \"\"\"Create progress callback for upload tracking\"\"\"\n        def progress_callback(current: int, total: int):\n            # Update progress tracker safely from thread\n            try:\n                # Try to get the running loop\n                try:\n                    loop = asyncio.get_running_loop()\n                    # Schedule the coroutine to run in the event loop\n                    asyncio.run_coroutine_threadsafe(\n                        self.progress_tracker.update_upload_progress(\n                            task_id, current, total, \"Uploading...\"\n                        ), loop\n                    )\n                except RuntimeError:\n                    # No running loop, skip progress update\n                    pass\n            except Exception as e:\n                # Silently handle progress update errors\n                logger.debug(f\"Upload progress update error: {e}\")\n            \n            # Update active uploads\n            if task_id in self.active_uploads:\n                upload_info = self.active_uploads[task_id]\n                elapsed_time = time.time() - upload_info['start_time']\n                speed = current / elapsed_time if elapsed_time > 0 else 0\n                \n                upload_info.update({\n                    'current_bytes': current,\n                    'total_bytes': total,\n                    'progress_percent': (current / total * 100) if total > 0 else 0,\n                    'speed': speed,\n                    'elapsed_time': elapsed_time,\n                    'eta': (total - current) / speed if speed > 0 else 0\n                })\n        \n        return progress_callback\n    \n    def _create_file_caption(self, video_info: Dict, format_info: Dict, file_size: int) -> str:\n        \"\"\"Create formatted caption for uploaded file\"\"\"\n        from utils.helpers import truncate_text\n        \n        title = video_info.get('title', 'Unknown Title')\n        uploader = video_info.get('uploader', 'Unknown')\n        duration = video_info.get('duration', 0)\n        platform = video_info.get('platform', 'Unknown')\n        \n        # Truncate long fields to prevent caption overflow\n        title = truncate_text(title, 80)\n        uploader = truncate_text(uploader, 50)\n        \n        # Format duration\n        duration_str = format_duration(duration) if duration else 'Unknown'\n        \n        # Quality info\n        quality = format_info.get('quality', 'Unknown')\n        ext = format_info.get('ext', 'mp4')\n        \n        caption = f\"\"\"üé¨ <b>{title}</b>\n\nüë§ <b>Uploader:</b> {uploader}\nüåê <b>Platform:</b> {platform.title()}\n‚è± <b>Duration:</b> {duration_str}\nüì∫ <b>Quality:</b> {quality}\nüìÅ <b>Format:</b> {ext.upper()}\nüíæ <b>File Size:</b> {format_file_size(file_size)}\n\n‚úÖ <b>Downloaded via Ultra Video Bot</b>\"\"\"\n\n        # Ensure total caption doesn't exceed Telegram's 1024 character limit\n        if len(caption) > 1020:\n            # If still too long, truncate title further\n            title = truncate_text(title, 40)\n            caption = f\"\"\"üé¨ <b>{title}</b>\n\nüë§ <b>Uploader:</b> {uploader}\nüåê <b>Platform:</b> {platform.title()}\n‚è± <b>Duration:</b> {duration_str}\nüì∫ <b>Quality:</b> {quality}\nüìÅ <b>Format:</b> {ext.upper()}\nüíæ <b>File Size:</b> {format_file_size(file_size)}\n\n‚úÖ <b>Downloaded via Ultra Video Bot</b>\"\"\"\n        \n        return caption\n    \n    async def _cleanup_upload_files(self, file_path: str, thumbnail_path: Optional[str]):\n        \"\"\"Clean up temporary files after upload\"\"\"\n        try:\n            # Remove main file\n            if os.path.exists(file_path):\n                os.remove(file_path)\n                logger.debug(f\"üóëÔ∏è Cleaned up file: {file_path}\")\n            \n            # Remove thumbnail\n            if thumbnail_path and os.path.exists(thumbnail_path):\n                os.remove(thumbnail_path)\n                logger.debug(f\"üóëÔ∏è Cleaned up thumbnail: {thumbnail_path}\")\n            \n            # Remove empty directory if it's in temp\n            file_dir = os.path.dirname(file_path)\n            if file_dir.startswith(settings.TEMP_DIR) and os.path.exists(file_dir):\n                try:\n                    os.rmdir(file_dir)\n                except OSError:\n                    pass  # Directory not empty\n                    \n        except Exception as e:\n            logger.warning(f\"Failed to cleanup files: {e}\")\n    \n    async def _cleanup_active_upload(self, task_id: str, delay: int = 300):\n        \"\"\"Clean up active upload entry after delay\"\"\"\n        await asyncio.sleep(delay)  # Wait 5 minutes\n        \n        if task_id in self.active_uploads:\n            del self.active_uploads[task_id]\n            logger.debug(f\"üóëÔ∏è Cleaned up active upload: {task_id}\")\n    \n    async def get_upload_progress(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"Get current upload progress\"\"\"\n        if task_id in self.active_uploads:\n            upload_info = self.active_uploads[task_id].copy()\n            \n            # Add formatted information\n            upload_info.update({\n                'file_size_str': format_file_size(upload_info.get('file_size', 0)),\n                'speed_str': format_file_size(upload_info.get('speed', 0)) + '/s',\n                'elapsed_str': format_upload_time(upload_info.get('elapsed_time', 0)),\n                'eta_str': format_upload_time(upload_info.get('eta', 0))\n            })\n            \n            return upload_info\n        \n        # Check progress tracker\n        return await self.progress_tracker.get_upload_progress(task_id)\n    \n    async def cancel_upload(self, task_id: str) -> bool:\n        \"\"\"Cancel an ongoing upload\"\"\"\n        try:\n            if task_id in self.active_uploads:\n                upload_info = self.active_uploads[task_id]\n                upload_info['status'] = 'cancelled'\n                \n                # Update progress tracker\n                await self.progress_tracker.update_upload_progress(\n                    task_id, 0, 0, \"Cancelled by user\"\n                )\n                \n                logger.info(f\"üìù Upload task {task_id} marked as cancelled\")\n                return True\n            \n            return False\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to cancel upload {task_id}: {e}\")\n            return False\n    \n    async def get_file_info(self, file_path: str) -> Dict[str, Any]:\n        \"\"\"Get detailed file information\"\"\"\n        try:\n            if not os.path.exists(file_path):\n                raise FileNotFoundError(f\"File not found: {file_path}\")\n            \n            stat = os.stat(file_path)\n            file_size = stat.st_size\n            \n            # Get file hash for deduplication\n            file_hash = await self._get_file_hash_async(file_path)\n            \n            # Get MIME type\n            mime_type, _ = mimetypes.guess_type(file_path)\n            \n            return {\n                'path': file_path,\n                'name': os.path.basename(file_path),\n                'size': file_size,\n                'size_str': format_file_size(file_size),\n                'hash': file_hash,\n                'mime_type': mime_type,\n                'created': stat.st_ctime,\n                'modified': stat.st_mtime,\n                'extension': os.path.splitext(file_path)[1].lower(),\n                'is_video': mime_type and mime_type.startswith('video/') if mime_type else False,\n                'is_audio': mime_type and mime_type.startswith('audio/') if mime_type else False\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get file info for {file_path}: {e}\")\n            raise\n    \n    async def _get_file_hash_async(self, file_path: str) -> str:\n        \"\"\"Get file hash asynchronously\"\"\"\n        async with self.process_semaphore:\n            loop = asyncio.get_event_loop()\n            return await loop.run_in_executor(None, get_file_hash, file_path)\n    \n    async def cleanup_temp_directory(self, max_age_hours: int = 1):\n        \"\"\"Clean up old files in temporary directory\"\"\"\n        try:\n            current_time = time.time()\n            max_age_seconds = max_age_hours * 3600\n            cleaned_files = 0\n            freed_space = 0\n            \n            temp_dir = Path(settings.TEMP_DIR)\n            if not temp_dir.exists():\n                return {'cleaned_files': 0, 'freed_space': 0}\n            \n            for file_path in temp_dir.rglob('*'):\n                if file_path.is_file():\n                    try:\n                        file_age = current_time - file_path.stat().st_ctime\n                        if file_age > max_age_seconds:\n                            file_size = file_path.stat().st_size\n                            file_path.unlink()\n                            cleaned_files += 1\n                            freed_space += file_size\n                            logger.debug(f\"üóëÔ∏è Cleaned up old file: {file_path}\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to clean up file {file_path}: {e}\")\n            \n            # Remove empty directories\n            for dir_path in temp_dir.rglob('*'):\n                if dir_path.is_dir() and not any(dir_path.iterdir()):\n                    try:\n                        dir_path.rmdir()\n                        logger.debug(f\"üóëÔ∏è Removed empty directory: {dir_path}\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to remove directory {dir_path}: {e}\")\n            \n            logger.info(f\"‚úÖ Cleanup completed: {cleaned_files} files, {format_file_size(freed_space)} freed\")\n            \n            return {\n                'cleaned_files': cleaned_files,\n                'freed_space': freed_space,\n                'freed_space_str': format_file_size(freed_space)\n            }\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Cleanup failed: {e}\")\n            return {'cleaned_files': 0, 'freed_space': 0}\n    \n    async def get_upload_history(self, user_id: Optional[int] = None, limit: int = 10) -> List[Dict]:\n        \"\"\"Get upload history for user or all users\"\"\"\n        history = self.upload_history.copy()\n        \n        # Filter by user if specified\n        if user_id:\n            history = [h for h in history if h.get('user_id') == user_id]\n        \n        # Sort by timestamp (newest first) and limit\n        history.sort(key=lambda x: x.get('timestamp', 0), reverse=True)\n        \n        return history[:limit]\n    \n    async def get_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get current file manager performance statistics\"\"\"\n        temp_dir_stats = await self._get_temp_directory_stats()\n        \n        return {\n            'active_uploads': len(self.active_uploads),\n            'max_concurrent_uploads': settings.MAX_CONCURRENT_UPLOADS,\n            'upload_queue_size': self.upload_semaphore._value,\n            'total_uploads_completed': len(self.upload_history),\n            'temp_directory_size': temp_dir_stats['total_size'],\n            'temp_directory_files': temp_dir_stats['file_count'],\n            'chunk_size': self.chunk_size,\n            'max_file_size': self.max_file_size,\n            'max_file_size_str': format_file_size(self.max_file_size)\n        }\n    \n    async def _get_temp_directory_stats(self) -> Dict[str, Any]:\n        \"\"\"Get temporary directory statistics\"\"\"\n        try:\n            temp_dir = Path(settings.TEMP_DIR)\n            if not temp_dir.exists():\n                return {'total_size': 0, 'file_count': 0}\n            \n            total_size = 0\n            file_count = 0\n            \n            for file_path in temp_dir.rglob('*'):\n                if file_path.is_file():\n                    try:\n                        total_size += file_path.stat().st_size\n                        file_count += 1\n                    except Exception:\n                        pass\n            \n            return {\n                'total_size': total_size,\n                'file_count': file_count,\n                'total_size_str': format_file_size(total_size)\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get temp directory stats: {e}\")\n            return {'total_size': 0, 'file_count': 0}\n    \n    async def get_ultra_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive ultra-performance statistics\"\"\"\n        try:\n            base_stats = await self.get_performance_stats()\n            \n            # Calculate upload efficiency metrics\n            recent_speeds = self.upload_speed_history[-10:] if self.upload_speed_history else []\n            avg_speed = sum(recent_speeds) / len(recent_speeds) if recent_speeds else 0\n            peak_speed = max(self.upload_speed_history) if self.upload_speed_history else 0\n            \n            # Enhanced performance metrics\n            ultra_stats = {\n                **base_stats,\n                'ultra_optimizations': {\n                    'compression_enabled': self.adaptive_compression,\n                    'smart_chunking_enabled': self.smart_chunking,\n                    'parallel_uploads_enabled': self.parallel_chunk_upload,\n                    'dynamic_scaling_enabled': self.dynamic_worker_scaling,\n                    'bandwidth_prediction_enabled': self.bandwidth_prediction\n                },\n                'speed_metrics': {\n                    'current_average_speed': avg_speed,\n                    'current_average_speed_str': format_file_size(avg_speed) + '/s',\n                    'peak_speed': peak_speed,\n                    'peak_speed_str': format_file_size(peak_speed) + '/s',\n                    'speed_samples': len(self.upload_speed_history)\n                },\n                'performance_metrics': self.performance_metrics,\n                'optimization_status': {\n                    'compression_workers': self.compression_semaphore._value,\n                    'processing_workers': self.process_semaphore._value,\n                    'upload_workers': self.upload_semaphore._value\n                }\n            }\n            \n            return ultra_stats\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to get ultra performance stats: {e}\")\n            return await self.get_performance_stats()  # Fallback to basic stats\n\n    async def _ultra_optimize_file(self, file_path: str, video_info: Dict) -> str:\n        \"\"\"Ultra-optimize file for fastest upload possible\"\"\"\n        try:\n            if not self.upload_optimization_enabled:\n                return file_path\n            \n            file_size = os.path.getsize(file_path)\n            file_ext = os.path.splitext(file_path)[1].lower()\n            \n            # Only optimize large video files\n            if file_size < 50 * 1024 * 1024 or file_ext not in ['.mp4', '.avi', '.mkv', '.mov', '.webm']:\n                return file_path\n            \n            logger.info(f\"üîß Ultra-optimizing file: {format_file_size(file_size)}\")\n            \n            # Apply smart compression for large files\n            if file_size > 100 * 1024 * 1024:  # Files > 100MB\n                compressed_path = await self._smart_compress_video(file_path, video_info)\n                if compressed_path and os.path.exists(compressed_path):\n                    new_size = os.path.getsize(compressed_path)\n                    compression_ratio = ((file_size - new_size) / file_size) * 100\n                    logger.info(f\"‚úÖ Smart compression: {compression_ratio:.1f}% reduction\")\n                    return compressed_path\n            \n            return file_path\n            \n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è File optimization failed, using original: {e}\")\n            return file_path\n    \n    async def _smart_compress_video(self, file_path: str, video_info: Dict) -> Optional[str]:\n        \"\"\"Intelligent video compression for faster uploads\"\"\"\n        async with self.compression_semaphore:\n            try:\n                # Create optimized output path\n                base_name = os.path.splitext(os.path.basename(file_path))[0]\n                optimized_path = os.path.join(\n                    os.path.dirname(file_path), \n                    f\"{base_name}_optimized.mp4\"\n                )\n                \n                # Get video duration for optimization decisions\n                duration = video_info.get('duration', 0)\n                if duration > 3600:  # Videos > 1 hour\n                    crf = \"28\"  # Higher compression for long videos\n                    preset = \"veryfast\"\n                else:\n                    crf = \"23\"  # Better quality for shorter videos\n                    preset = \"faster\"\n                \n                # Ultra-optimized FFmpeg command for speed and size balance\n                ffmpeg_cmd = [\n                    'ffmpeg', '-i', file_path,\n                    '-c:v', 'libx264',  # Fast H.264 encoding\n                    '-preset', preset,  # Fast encoding preset\n                    '-crf', crf,  # Quality/size balance\n                    '-c:a', 'aac',  # Fast audio codec\n                    '-b:a', '128k',  # Optimized audio bitrate\n                    '-movflags', '+faststart',  # Fast streaming\n                    '-threads', '0',  # Use all CPU cores\n                    '-y',  # Overwrite output\n                    optimized_path\n                ]\n                \n                logger.info(\"‚ö° Starting ultra-fast compression...\")\n                start_time = time.time()\n                \n                # Run compression with timeout\n                process = await asyncio.create_subprocess_exec(\n                    *ffmpeg_cmd,\n                    stdout=asyncio.subprocess.PIPE,\n                    stderr=asyncio.subprocess.PIPE\n                )\n                \n                try:\n                    stdout, stderr = await asyncio.wait_for(\n                        process.communicate(), \n                        timeout=300  # 5 minute timeout\n                    )\n                    \n                    if process.returncode == 0 and os.path.exists(optimized_path):\n                        compression_time = time.time() - start_time\n                        original_size = os.path.getsize(file_path)\n                        compressed_size = os.path.getsize(optimized_path)\n                        \n                        if compressed_size < original_size * 0.9:  # At least 10% reduction\n                            logger.info(f\"‚úÖ Compression completed in {compression_time:.1f}s\")\n                            return optimized_path\n                        else:\n                            # Clean up if no significant reduction\n                            os.remove(optimized_path)\n                            logger.info(\"‚ÑπÔ∏è No significant compression achieved\")\n                            return None\n                    else:\n                        logger.warning(f\"‚ö†Ô∏è Compression failed: {stderr.decode()}\")\n                        return None\n                        \n                except asyncio.TimeoutError:\n                    process.kill()\n                    logger.warning(\"‚ö†Ô∏è Compression timeout, using original file\")\n                    return None\n                    \n            except Exception as e:\n                logger.warning(f\"‚ö†Ô∏è Smart compression failed: {e}\")\n                return None\n\n    async def _adaptive_upload_optimization(self, file_size: int) -> Dict[str, Any]:\n        \"\"\"Dynamically optimize upload parameters based on file size and network\"\"\"\n        try:\n            # Analyze recent upload performance\n            recent_speeds = self.upload_speed_history[-10:] if self.upload_speed_history else []\n            avg_speed = sum(recent_speeds) / len(recent_speeds) if recent_speeds else 0\n            \n            # Adaptive optimization based on file size and performance\n            if file_size > 500 * 1024 * 1024:  # Files > 500MB\n                workers = 20 if avg_speed > 10 * 1024 * 1024 else 16  # More workers for fast connections\n                chunk_size = 1024 * 1024  # 1MB chunks for large files\n                compression_enabled = True\n            elif file_size > 100 * 1024 * 1024:  # Files > 100MB\n                workers = 12 if avg_speed > 5 * 1024 * 1024 else 8\n                chunk_size = 512 * 1024  # 512KB chunks\n                compression_enabled = file_size > 200 * 1024 * 1024\n            else:  # Smaller files\n                workers = 8\n                chunk_size = 256 * 1024  # 256KB chunks\n                compression_enabled = False\n            \n            return {\n                'workers': workers,\n                'chunk_size': chunk_size,\n                'compression_enabled': compression_enabled,\n                'parallel_streams': min(workers // 2, 6),\n                'adaptive_bitrate': True\n            }\n            \n        except Exception as e:\n            logger.warning(f\"‚ö†Ô∏è Adaptive optimization failed: {e}\")\n            return {\n                'workers': 8,\n                'chunk_size': 512 * 1024,\n                'compression_enabled': False,\n                'parallel_streams': 4,\n                'adaptive_bitrate': False\n            }\n\n    async def _create_resumable_upload_checkpoint(self, task_id: str, file_path: str, uploaded_bytes: int) -> Dict[str, Any]:\n        \"\"\"Create checkpoint for resumable uploads\"\"\"\n        try:\n            checkpoint_data = {\n                'task_id': task_id,\n                'file_path': file_path,\n                'uploaded_bytes': uploaded_bytes,\n                'total_bytes': os.path.getsize(file_path),\n                'timestamp': time.time(),\n                'file_hash': await self._get_file_hash_async(file_path)\n            }\n            \n            # Store checkpoint in cache for quick access\n            await self.progress_tracker.cache_manager.set(\n                f\"upload_checkpoint:{task_id}\",\n                checkpoint_data,\n                ttl=3600  # 1 hour TTL\n            )\n            \n            logger.info(f\"üìã Created upload checkpoint: {task_id} at {uploaded_bytes} bytes\")\n            return checkpoint_data\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to create upload checkpoint: {e}\")\n            return {}\n    \n    async def _resume_upload_from_checkpoint(self, task_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Resume upload from existing checkpoint\"\"\"\n        try:\n            checkpoint = await self.progress_tracker.cache_manager.get(f\"upload_checkpoint:{task_id}\")\n            \n            if not checkpoint:\n                logger.info(f\"üìã No checkpoint found for task: {task_id}\")\n                return None\n            \n            # Verify file integrity\n            file_path = checkpoint['file_path']\n            if not os.path.exists(file_path):\n                logger.warning(f\"‚ö†Ô∏è File not found for resume: {file_path}\")\n                return None\n            \n            current_hash = await self._get_file_hash_async(file_path)\n            if current_hash != checkpoint['file_hash']:\n                logger.warning(f\"‚ö†Ô∏è File modified since checkpoint, cannot resume\")\n                return None\n            \n            logger.info(f\"üìã Resuming upload from checkpoint: {checkpoint['uploaded_bytes']} bytes\")\n            return checkpoint\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to resume from checkpoint: {e}\")\n            return None\n    \n    async def _monitor_upload_performance(self, task_id: str, file_size: int) -> Dict[str, Any]:\n        \"\"\"Monitor and optimize upload performance in real-time\"\"\"\n        try:\n            upload_info = self.active_uploads.get(task_id, {})\n            if not upload_info:\n                return {}\n            \n            current_time = time.time()\n            elapsed_time = current_time - upload_info['start_time']\n            current_bytes = upload_info.get('current_bytes', 0)\n            \n            # Calculate performance metrics\n            if elapsed_time > 0:\n                current_speed = current_bytes / elapsed_time\n                self.upload_speed_history.append(current_speed)\n                \n                # Keep only recent speed history (last 20 readings)\n                if len(self.upload_speed_history) > 20:\n                    self.upload_speed_history = self.upload_speed_history[-20:]\n                \n                # Adaptive optimization based on performance\n                if current_speed < 1024 * 1024:  # Less than 1MB/s\n                    # Slow upload - reduce workers, increase chunk size\n                    optimization = await self._adaptive_upload_optimization(file_size)\n                    optimization['workers'] = max(4, optimization['workers'] - 2)\n                    optimization['chunk_size'] = min(1024 * 1024, optimization['chunk_size'] * 2)\n                    \n                elif current_speed > 10 * 1024 * 1024:  # More than 10MB/s\n                    # Fast upload - increase workers for maximum speed\n                    optimization = await self._adaptive_upload_optimization(file_size)\n                    optimization['workers'] = min(24, optimization['workers'] + 4)\n                \n                # Predict completion time\n                remaining_bytes = file_size - current_bytes\n                eta = remaining_bytes / current_speed if current_speed > 0 else 0\n                \n                performance_data = {\n                    'current_speed': current_speed,\n                    'average_speed': sum(self.upload_speed_history) / len(self.upload_speed_history),\n                    'eta_seconds': eta,\n                    'progress_percentage': (current_bytes / file_size) * 100 if file_size > 0 else 0,\n                    'elapsed_time': elapsed_time,\n                    'optimization_applied': True\n                }\n                \n                # Update performance metrics\n                self.performance_metrics['total_updates'] += 1\n                self.performance_metrics['peak_concurrent_tasks'] = max(\n                    self.performance_metrics['peak_concurrent_tasks'],\n                    len(self.active_uploads)\n                )\n                \n                return performance_data\n            \n            return {}\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Performance monitoring failed: {e}\")\n            return {}\n","size_bytes":37725},"services/progress_tracker.py":{"content":"\"\"\"\nReal-time progress tracking system for downloads and uploads\nUses Redis for fast, distributed progress tracking with WebSocket-like updates\n\"\"\"\n\nimport asyncio\nimport logging\nimport time\nimport json\nfrom typing import Dict, Any, Optional, Callable, List\nfrom dataclasses import dataclass, asdict\n\nfrom services.cache_manager import CacheManager\nfrom utils.helpers import format_file_size, calculate_eta\nfrom utils.formatters import format_duration, format_speed\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass ProgressInfo:\n    \"\"\"Progress information data class\"\"\"\n    task_id: str\n    current_bytes: int\n    total_bytes: int\n    percentage: float\n    speed: float\n    eta: int\n    status: str\n    message: str\n    start_time: float\n    last_updated: float\n    user_id: Optional[int] = None\n    file_name: Optional[str] = None\n\nclass ProgressTracker:\n    \"\"\"Ultra high-performance progress tracking system\"\"\"\n    \n    def __init__(self, cache_manager: CacheManager):\n        self.cache_manager = cache_manager\n        \n        # Progress tracking\n        self.download_progress: Dict[str, ProgressInfo] = {}\n        self.upload_progress: Dict[str, ProgressInfo] = {}\n        \n        # Real-time performance optimization\n        self.update_interval = 0.1  # Update every 100ms for ultra-smooth real-time animation\n        self.last_updates: Dict[str, float] = {}\n        \n        # Real-time tracking data for precise calculations\n        self.speed_history: Dict[str, List[Tuple[float, float]]] = {}  # task_id -> [(timestamp, speed)]\n        self.progress_samples: Dict[str, List[Tuple[float, float, float]]] = {}  # task_id -> [(time, current, total)]\n        self.instant_speeds: Dict[str, float] = {}  # Real-time speed calculation\n        self.accurate_eta: Dict[str, float] = {}  # More accurate ETA calculation\n        \n        # Enhanced Animation tracking\n        self.animation_frames: Dict[str, int] = {}  # Track animation frame for each task\n        self.animation_styles: Dict[str, str] = {}  # Track animation style for each task\n        self.user_preferences: Dict[int, Dict] = {}  # Store user animation preferences\n        self.start_times: Dict[str, float] = {}     # Track start time for each task\n        \n        # Cleanup settings\n        self.max_progress_age = 3600  # Keep progress for 1 hour\n        \n        # Progress persistence\n        self.persist_progress = True\n        \n        # Performance monitoring\n        self.performance_metrics: Dict[str, Any] = {\n            'total_updates': 0,\n            'average_update_time': 0,\n            'peak_concurrent_tasks': 0\n        }\n        \n        # Background tasks\n        self.cleanup_task: Optional[asyncio.Task] = None\n        \n    async def initialize(self):\n        \"\"\"Initialize progress tracker\"\"\"\n        try:\n            logger.info(\"üîß Initializing progress tracker...\")\n            \n            # Start cleanup task\n            self.cleanup_task = asyncio.create_task(self._cleanup_old_progress())\n            \n            logger.info(\"‚úÖ Progress tracker initialized\")\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Progress tracker initialization failed: {e}\")\n            raise\n    \n    async def update_download_progress(\n        self,\n        task_id: str,\n        current_bytes: int,\n        total_bytes: int,\n        message: str = \"\",\n        user_id: Optional[int] = None,\n        file_name: Optional[str] = None\n    ):\n        \"\"\"Update download progress with throttling for performance\"\"\"\n        try:\n            current_time = time.time()\n            \n            # Throttle updates for performance\n            if task_id in self.last_updates:\n                if current_time - self.last_updates[task_id] < self.update_interval:\n                    return\n            \n            self.last_updates[task_id] = current_time\n            \n            # Calculate progress metrics\n            percentage = (current_bytes / total_bytes * 100) if total_bytes > 0 else 0\n            \n            # Real-time speed and ETA calculation with accuracy\n            speed = 0\n            eta = 0\n            start_time = current_time\n            \n            if task_id in self.download_progress:\n                existing = self.download_progress[task_id]\n                start_time = existing.start_time\n                elapsed_time = current_time - start_time\n                \n                # Calculate instant speed using samples\n                speed = self._calculate_realtime_speed(task_id, current_bytes, current_time)\n                \n                # Calculate more accurate ETA using recent speed trends\n                eta = self._calculate_accurate_eta(task_id, current_bytes, total_bytes, speed)\n                \n                # Store progress sample for better calculations\n                self._store_progress_sample(task_id, current_time, current_bytes, total_bytes)\n            \n            # Create progress info\n            progress = ProgressInfo(\n                task_id=task_id,\n                current_bytes=current_bytes,\n                total_bytes=total_bytes,\n                percentage=percentage,\n                speed=speed,\n                eta=int(eta),\n                status=\"downloading\" if current_bytes < total_bytes else \"completed\",\n                message=message,\n                start_time=start_time,\n                last_updated=current_time,\n                user_id=user_id,\n                file_name=file_name\n            )\n            \n            # Store in memory\n            self.download_progress[task_id] = progress\n            \n            # Store in Redis for persistence and sharing\n            await self._store_progress_in_cache(\"download\", task_id, progress)\n            \n            # Log significant progress milestones\n            if percentage > 0 and percentage % 25 == 0:\n                logger.info(f\"üì• Download {task_id}: {percentage:.1f}% completed \"\n                          f\"({format_file_size(int(current_bytes))}/{format_file_size(int(total_bytes))}) \"\n                          f\"Speed: {format_file_size(int(speed))}/s\")\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to update download progress for {task_id}: {e}\")\n    \n    async def update_upload_progress(\n        self,\n        task_id: str,\n        current_bytes: int,\n        total_bytes: int,\n        message: str = \"\",\n        user_id: Optional[int] = None,\n        file_name: Optional[str] = None\n    ):\n        \"\"\"Update upload progress with throttling for performance\"\"\"\n        try:\n            current_time = time.time()\n            \n            # Throttle updates for performance\n            if task_id in self.last_updates:\n                if current_time - self.last_updates[task_id] < self.update_interval:\n                    return\n            \n            self.last_updates[task_id] = current_time\n            \n            # Calculate progress metrics\n            percentage = (current_bytes / total_bytes * 100) if total_bytes > 0 else 0\n            \n            # Real-time speed and ETA calculation for uploads\n            speed = 0\n            eta = 0\n            start_time = current_time\n            \n            if task_id in self.upload_progress:\n                existing = self.upload_progress[task_id]\n                start_time = existing.start_time\n                elapsed_time = current_time - start_time\n                \n                # Calculate instant upload speed using samples\n                speed = self._calculate_realtime_speed(task_id, current_bytes, current_time)\n                \n                # Calculate more accurate ETA using recent speed trends\n                eta = self._calculate_accurate_eta(task_id, current_bytes, total_bytes, speed)\n                \n                # Store progress sample for better calculations\n                self._store_progress_sample(task_id, current_time, current_bytes, total_bytes)\n            \n            # Create progress info\n            progress = ProgressInfo(\n                task_id=task_id,\n                current_bytes=current_bytes,\n                total_bytes=total_bytes,\n                percentage=percentage,\n                speed=speed,\n                eta=int(eta),\n                status=\"uploading\" if current_bytes < total_bytes else \"completed\",\n                message=message,\n                start_time=start_time,\n                last_updated=current_time,\n                user_id=user_id,\n                file_name=file_name\n            )\n            \n            # Store in memory\n            self.upload_progress[task_id] = progress\n            \n            # Store in Redis for persistence and sharing\n            await self._store_progress_in_cache(\"upload\", task_id, progress)\n            \n            # Log significant progress milestones\n            if percentage > 0 and percentage % 25 == 0:\n                logger.info(f\"üì§ Upload {task_id}: {percentage:.1f}% completed \"\n                          f\"({format_file_size(int(current_bytes))}/{format_file_size(int(total_bytes))}) \"\n                          f\"Speed: {format_file_size(int(speed))}/s\")\n            \n        except Exception as e:\n            logger.error(f\"‚ùå Failed to update upload progress for {task_id}: {e}\")\n    \n    async def _store_progress_in_cache(self, operation_type: str, task_id: str, progress: ProgressInfo):\n        \"\"\"Store progress information in Redis cache\"\"\"\n        try:\n            cache_key = f\"progress:{operation_type}:{task_id}\"\n            progress_data = asdict(progress)\n            \n            await self.cache_manager.set(\n                cache_key,\n                json.dumps(progress_data, default=str),\n                expire=self.max_progress_age\n            )\n            \n        except Exception as e:\n            logger.warning(f\"Failed to cache progress for {task_id}: {e}\")\n    \n    async def get_download_progress(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"Get current download progress\"\"\"\n        try:\n            # Check memory first\n            if task_id in self.download_progress:\n                progress = self.download_progress[task_id]\n                return self._format_progress_response(progress)\n            \n            # Check Redis cache\n            cache_key = f\"progress:download:{task_id}\"\n            cached_data = await self.cache_manager.get(cache_key)\n            \n            if cached_data:\n                progress_data = json.loads(cached_data)\n                return self._format_progress_dict(progress_data)\n            \n            return {'task_id': task_id, 'status': 'not_found', 'message': 'Task not found'}\n            \n        except Exception as e:\n            logger.error(f\"Failed to get download progress for {task_id}: {e}\")\n            return {'task_id': task_id, 'status': 'error', 'message': str(e)}\n    \n    async def get_upload_progress(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"Get current upload progress\"\"\"\n        try:\n            # Check memory first\n            if task_id in self.upload_progress:\n                progress = self.upload_progress[task_id]\n                return self._format_progress_response(progress)\n            \n            # Check Redis cache\n            cache_key = f\"progress:upload:{task_id}\"\n            cached_data = await self.cache_manager.get(cache_key)\n            \n            if cached_data:\n                progress_data = json.loads(cached_data)\n                return self._format_progress_dict(progress_data)\n            \n            return {'task_id': task_id, 'status': 'not_found', 'message': 'Task not found'}\n            \n        except Exception as e:\n            logger.error(f\"Failed to get upload progress for {task_id}: {e}\")\n            return {'task_id': task_id, 'status': 'error', 'message': str(e)}\n    \n    def _format_progress_response(self, progress: ProgressInfo) -> Dict[str, Any]:\n        \"\"\"Format progress info for response\"\"\"\n        elapsed_time = time.time() - progress.start_time\n        \n        return {\n            'task_id': progress.task_id,\n            'current_bytes': progress.current_bytes,\n            'total_bytes': progress.total_bytes,\n            'percentage': round(progress.percentage, 1),\n            'speed': progress.speed,\n            'eta': progress.eta,\n            'status': progress.status,\n            'message': progress.message,\n            'elapsed_time': elapsed_time,\n            'user_id': progress.user_id,\n            'file_name': progress.file_name,\n            \n            # Formatted strings for display\n            'current_str': format_file_size(progress.current_bytes),\n            'total_str': format_file_size(progress.total_bytes),\n            'speed_str': format_speed(progress.speed),\n            'eta_str': format_duration(progress.eta),\n            'elapsed_str': format_duration(elapsed_time),\n            'progress_bar': self._create_progress_bar(progress.percentage, progress.task_id)\n        }\n    \n    def _format_progress_dict(self, progress_data: Dict) -> Dict[str, Any]:\n        \"\"\"Format progress dictionary for response\"\"\"\n        current_time = time.time()\n        elapsed_time = current_time - progress_data.get('start_time', current_time)\n        \n        percentage = progress_data.get('percentage', 0)\n        speed = progress_data.get('speed', 0)\n        eta = progress_data.get('eta', 0)\n        \n        return {\n            'task_id': progress_data.get('task_id', ''),\n            'current_bytes': progress_data.get('current_bytes', 0),\n            'total_bytes': progress_data.get('total_bytes', 0),\n            'percentage': round(percentage, 1),\n            'speed': speed,\n            'eta': eta,\n            'status': progress_data.get('status', 'unknown'),\n            'message': progress_data.get('message', ''),\n            'elapsed_time': elapsed_time,\n            'user_id': progress_data.get('user_id'),\n            'file_name': progress_data.get('file_name'),\n            \n            # Formatted strings for display\n            'current_str': format_file_size(progress_data.get('current_bytes', 0)),\n            'total_str': format_file_size(progress_data.get('total_bytes', 0)),\n            'speed_str': format_speed(speed),\n            'eta_str': format_duration(eta),\n            'elapsed_str': format_duration(elapsed_time),\n            'progress_bar': self._create_progress_bar(percentage)\n        }\n    \n    def _create_progress_bar(self, percentage: float, task_id: str = \"\", length: int = 20) -> str:\n        \"\"\"Create an animated visual progress bar\"\"\"\n        from static.icons import Icons\n        \n        filled = int(percentage / 100 * length)\n        \n        # Get current animation frame\n        if task_id:\n            if task_id not in self.animation_frames:\n                self.animation_frames[task_id] = 0\n            frame_index = self.animation_frames[task_id] % len(Icons.PROGRESS_FRAMES)\n            self.animation_frames[task_id] += 1\n            progress_char = Icons.PROGRESS_FRAMES[frame_index]\n        else:\n            progress_char = \"‚ñà\"\n        \n        # Create animated bar\n        if percentage < 100:\n            # Show animation at the progress edge\n            if filled > 0:\n                bar = '‚ñà' * (filled - 1) + progress_char + '‚ñë' * (length - filled)\n            else:\n                bar = progress_char + '‚ñë' * (length - 1)\n        else:\n            # Completed - show full bar with success animation\n            bar = '‚ñà' * length\n            \n        return f\"[{bar}] {percentage:.1f}%\"\n    \n    async def get_user_progress(self, user_id: int) -> Dict[str, List[Dict[str, Any]]]:\n        \"\"\"Get all progress for a specific user\"\"\"\n        user_downloads = []\n        user_uploads = []\n        \n        # Check downloads\n        for task_id, progress in self.download_progress.items():\n            if progress.user_id == user_id:\n                user_downloads.append(self._format_progress_response(progress))\n        \n        # Check uploads\n        for task_id, progress in self.upload_progress.items():\n            if progress.user_id == user_id:\n                user_uploads.append(self._format_progress_response(progress))\n        \n        return {\n            'downloads': user_downloads,\n            'uploads': user_uploads,\n            'total_active': len(user_downloads) + len(user_uploads)\n        }\n    \n    async def get_all_active_progress(self) -> Dict[str, Any]:\n        \"\"\"Get all active progress for monitoring\"\"\"\n        downloads = []\n        uploads = []\n        \n        for progress in self.download_progress.values():\n            downloads.append(self._format_progress_response(progress))\n        \n        for progress in self.upload_progress.values():\n            uploads.append(self._format_progress_response(progress))\n        \n        return {\n            'downloads': downloads,\n            'uploads': uploads,\n            'total_downloads': len(downloads),\n            'total_uploads': len(uploads),\n            'total_active': len(downloads) + len(uploads)\n        }\n    \n    async def cancel_task(self, task_id: str) -> bool:\n        \"\"\"Cancel a task and update its progress\"\"\"\n        try:\n            cancelled = False\n            \n            # Cancel download\n            if task_id in self.download_progress:\n                progress = self.download_progress[task_id]\n                progress.status = \"cancelled\"\n                progress.message = \"Cancelled by user\"\n                await self._store_progress_in_cache(\"download\", task_id, progress)\n                cancelled = True\n            \n            # Cancel upload\n            if task_id in self.upload_progress:\n                progress = self.upload_progress[task_id]\n                progress.status = \"cancelled\"\n                progress.message = \"Cancelled by user\"\n                await self._store_progress_in_cache(\"upload\", task_id, progress)\n                cancelled = True\n            \n            if cancelled:\n                logger.info(f\"üìù Task {task_id} marked as cancelled\")\n            \n            return cancelled\n            \n        except Exception as e:\n            logger.error(f\"Failed to cancel task {task_id}: {e}\")\n            return False\n    \n    async def remove_completed_tasks(self, max_age_seconds: int = 300):\n        \"\"\"Remove completed tasks older than specified age\"\"\"\n        try:\n            current_time = time.time()\n            removed_count = 0\n            \n            # Remove old download progress\n            to_remove = []\n            for task_id, progress in self.download_progress.items():\n                if (progress.status in ['completed', 'cancelled', 'failed'] and \n                    current_time - progress.last_updated > max_age_seconds):\n                    to_remove.append(task_id)\n            \n            for task_id in to_remove:\n                del self.download_progress[task_id]\n                removed_count += 1\n            \n            # Remove old upload progress\n            to_remove = []\n            for task_id, progress in self.upload_progress.items():\n                if (progress.status in ['completed', 'cancelled', 'failed'] and \n                    current_time - progress.last_updated > max_age_seconds):\n                    to_remove.append(task_id)\n            \n            for task_id in to_remove:\n                del self.upload_progress[task_id]\n                removed_count += 1\n            \n            if removed_count > 0:\n                logger.info(f\"üóëÔ∏è Removed {removed_count} completed/old progress entries\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to remove completed tasks: {e}\")\n    \n    async def _cleanup_old_progress(self):\n        \"\"\"Background task to clean up old progress entries\"\"\"\n        while True:\n            try:\n                await asyncio.sleep(300)  # Run every 5 minutes\n                await self.remove_completed_tasks()\n                \n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Progress cleanup error: {e}\")\n                await asyncio.sleep(60)  # Wait 1 minute before retrying\n    \n    async def get_performance_stats(self) -> Dict[str, Any]:\n        \"\"\"Get progress tracker performance statistics\"\"\"\n        current_time = time.time()\n        \n        # Count active tasks\n        active_downloads = sum(1 for p in self.download_progress.values() \n                             if p.status == 'downloading')\n        active_uploads = sum(1 for p in self.upload_progress.values() \n                           if p.status == 'uploading')\n        \n        # Calculate average speeds\n        download_speeds = [p.speed for p in self.download_progress.values() \n                          if p.status == 'downloading' and p.speed > 0]\n        upload_speeds = [p.speed for p in self.upload_progress.values() \n                        if p.status == 'uploading' and p.speed > 0]\n        \n        avg_download_speed = sum(download_speeds) / len(download_speeds) if download_speeds else 0\n        avg_upload_speed = sum(upload_speeds) / len(upload_speeds) if upload_speeds else 0\n        \n        return {\n            'total_downloads_tracked': len(self.download_progress),\n            'total_uploads_tracked': len(self.upload_progress),\n            'active_downloads': active_downloads,\n            'active_uploads': active_uploads,\n            'avg_download_speed': avg_download_speed,\n            'avg_upload_speed': avg_upload_speed,\n            'avg_download_speed_str': format_speed(avg_download_speed),\n            'avg_upload_speed_str': format_speed(avg_upload_speed),\n            'update_interval': self.update_interval,\n            'max_progress_age': self.max_progress_age\n        }\n    \n    async def stop(self):\n        \"\"\"Stop the progress tracker and cleanup\"\"\"\n        if self.cleanup_task:\n            self.cleanup_task.cancel()\n            try:\n                await self.cleanup_task\n            except asyncio.CancelledError:\n                pass\n    \n    def _calculate_realtime_speed(self, task_id: str, current_bytes: int, current_time: float) -> float:\n        \"\"\"Calculate real-time speed using recent samples for accuracy\"\"\"\n        try:\n            # Get or create speed history\n            if task_id not in self.speed_history:\n                self.speed_history[task_id] = []\n            \n            speed_history = self.speed_history[task_id]\n            \n            # Add current sample\n            speed_history.append((current_time, current_bytes))\n            \n            # Keep only recent samples (last 10 seconds)\n            cutoff_time = current_time - 10\n            speed_history[:] = [(t, b) for t, b in speed_history if t > cutoff_time]\n            \n            # Calculate speed based on recent samples\n            if len(speed_history) < 2:\n                return 0\n            \n            # Use linear regression for more accurate speed\n            total_time_diff = 0\n            total_bytes_diff = 0\n            sample_count = min(len(speed_history), 5)  # Use last 5 samples\n            \n            for i in range(1, sample_count):\n                time_diff = speed_history[i][0] - speed_history[i-1][0]\n                bytes_diff = speed_history[i][1] - speed_history[i-1][1]\n                \n                if time_diff > 0:\n                    total_time_diff += time_diff\n                    total_bytes_diff += bytes_diff\n            \n            if total_time_diff > 0:\n                instant_speed = total_bytes_diff / total_time_diff\n                self.instant_speeds[task_id] = instant_speed\n                return max(0, instant_speed)  # Ensure positive speed\n            \n            return self.instant_speeds.get(task_id, 0)\n            \n        except Exception as e:\n            logger.warning(f\"Speed calculation error for {task_id}: {e}\")\n            return 0\n    \n    def _calculate_accurate_eta(self, task_id: str, current_bytes: int, total_bytes: int, current_speed: float) -> float:\n        \"\"\"Calculate more accurate ETA using speed trends and adaptive algorithms\"\"\"\n        try:\n            if current_speed <= 0 or current_bytes >= total_bytes:\n                return 0\n            \n            remaining_bytes = total_bytes - current_bytes\n            \n            # Simple ETA based on current speed\n            basic_eta = remaining_bytes / current_speed\n            \n            # Get speed history for trend analysis\n            if task_id in self.speed_history and len(self.speed_history[task_id]) > 3:\n                speeds = []\n                recent_samples = self.speed_history[task_id][-5:]  # Last 5 samples\n                \n                for i in range(1, len(recent_samples)):\n                    time_diff = recent_samples[i][0] - recent_samples[i-1][0]\n                    bytes_diff = recent_samples[i][1] - recent_samples[i-1][1]\n                    if time_diff > 0:\n                        speeds.append(bytes_diff / time_diff)\n                \n                if speeds:\n                    # Calculate trend (is speed increasing/decreasing?)\n                    if len(speeds) > 1:\n                        trend = (speeds[-1] - speeds[0]) / len(speeds)\n                        \n                        # Adjust ETA based on trend\n                        if trend > 0:  # Speed increasing\n                            adjusted_speed = current_speed + (trend * 5)  # Project 5 seconds ahead\n                            basic_eta = remaining_bytes / max(adjusted_speed, current_speed * 0.5)\n                        elif trend < 0:  # Speed decreasing\n                            adjusted_speed = current_speed + (trend * 5)\n                            basic_eta = remaining_bytes / max(adjusted_speed, current_speed * 0.3)\n            \n            self.accurate_eta[task_id] = basic_eta\n            return basic_eta\n            \n        except Exception as e:\n            logger.warning(f\"ETA calculation error for {task_id}: {e}\")\n            return 0\n    \n    def _store_progress_sample(self, task_id: str, timestamp: float, current_bytes: int, total_bytes: int):\n        \"\"\"Store progress sample for trend analysis\"\"\"\n        try:\n            if task_id not in self.progress_samples:\n                self.progress_samples[task_id] = []\n            \n            samples = self.progress_samples[task_id]\n            samples.append((timestamp, current_bytes, total_bytes))\n            \n            # Keep only recent samples (last 30 seconds)\n            cutoff_time = timestamp - 30\n            samples[:] = [(t, c, tot) for t, c, tot in samples if t > cutoff_time]\n            \n        except Exception as e:\n            logger.warning(f\"Failed to store progress sample for {task_id}: {e}\")\n    \n    def get_realtime_stats(self, task_id: str) -> Dict[str, Any]:\n        \"\"\"Get real-time statistics for a task\"\"\"\n        try:\n            stats = {\n                'instant_speed': self.instant_speeds.get(task_id, 0),\n                'instant_speed_str': format_speed(self.instant_speeds.get(task_id, 0)),\n                'accurate_eta': self.accurate_eta.get(task_id, 0),\n                'accurate_eta_str': format_duration(self.accurate_eta.get(task_id, 0)),\n                'sample_count': len(self.speed_history.get(task_id, [])),\n                'trend_available': len(self.speed_history.get(task_id, [])) > 3\n            }\n            \n            # Calculate speed trend if available\n            if task_id in self.speed_history and len(self.speed_history[task_id]) > 3:\n                recent_speeds = []\n                samples = self.speed_history[task_id][-5:]\n                \n                for i in range(1, len(samples)):\n                    time_diff = samples[i][0] - samples[i-1][0]\n                    bytes_diff = samples[i][1] - samples[i-1][1]\n                    if time_diff > 0:\n                        recent_speeds.append(bytes_diff / time_diff)\n                \n                if len(recent_speeds) > 1:\n                    trend = (recent_speeds[-1] - recent_speeds[0]) / len(recent_speeds)\n                    stats['speed_trend'] = 'increasing' if trend > 0 else 'decreasing' if trend < 0 else 'stable'\n                    stats['speed_trend_value'] = trend\n                else:\n                    stats['speed_trend'] = 'stable'\n                    stats['speed_trend_value'] = 0\n            else:\n                stats['speed_trend'] = 'unknown'\n                stats['speed_trend_value'] = 0\n            \n            return stats\n            \n        except Exception as e:\n            logger.error(f\"Failed to get real-time stats for {task_id}: {e}\")\n            return {}\n    \n    async def cleanup_task_data(self, task_id: str):\n        \"\"\"Clean up all tracking data for a completed/cancelled task\"\"\"\n        try:\n            # Clean up speed history\n            if task_id in self.speed_history:\n                del self.speed_history[task_id]\n            \n            # Clean up progress samples\n            if task_id in self.progress_samples:\n                del self.progress_samples[task_id]\n            \n            # Clean up instant data\n            if task_id in self.instant_speeds:\n                del self.instant_speeds[task_id]\n            \n            if task_id in self.accurate_eta:\n                del self.accurate_eta[task_id]\n            \n            # Clean up animation data\n            if task_id in self.animation_frames:\n                del self.animation_frames[task_id]\n            \n            if task_id in self.animation_styles:\n                del self.animation_styles[task_id]\n            \n            logger.debug(f\"üóëÔ∏è Cleaned up tracking data for task: {task_id}\")\n            \n        except Exception as e:\n            logger.warning(f\"Failed to cleanup task data for {task_id}: {e}\")\n        \n        logger.info(\"üõë Progress tracker stopped\")\n","size_bytes":30002},"static/__init__.py":{"content":"\"\"\"Static resources module for the video downloader bot\"\"\"\n\nfrom .icons import Icons\n\n__all__ = ['Icons']\n","size_bytes":106},"static/icons.py":{"content":"\"\"\"\nIcon constants for the video downloader bot\nProvides consistent emoji icons throughout the application\n\"\"\"\n\nclass Icons:\n    \"\"\"Collection of emoji icons used throughout the bot\"\"\"\n    \n    # Core Bot Icons\n    ROBOT = \"ü§ñ\"\n    ROCKET = \"üöÄ\"\n    STAR = \"‚≠ê\"\n    SPARKLES = \"‚ú®\"\n    FIRE = \"üî•\"\n    DIAMOND = \"üíé\"\n    TROPHY = \"üèÜ\"\n    \n    # Video and Media Icons\n    VIDEO = \"üé¨\"\n    CAMERA = \"üìπ\"\n    PHOTO = \"üì∏\"\n    AUDIO = \"üéµ\"\n    MUSIC = \"üé∂\"\n    HEADPHONES = \"üéß\"\n    MICROPHONE = \"üé§\"\n    SPEAKER = \"üîä\"\n    \n    # Download and Upload Icons\n    DOWNLOAD = \"‚¨áÔ∏è\"\n    UPLOAD = \"‚¨ÜÔ∏è\"\n    CLOUD_DOWNLOAD = \"‚òÅÔ∏è\"\n    INBOX = \"üì•\"\n    OUTBOX = \"üì§\"\n    PACKAGE = \"üì¶\"\n    \n    # Progress and Status Icons\n    PROGRESS = \"‚è≥\"\n    LOADING = \"üîÑ\"\n    REFRESH = \"üîÅ\"\n    HOURGLASS = \"‚åõ\"\n    CLOCK = \"üïê\"\n    TIMER = \"‚è≤Ô∏è\"\n    STOPWATCH = \"‚è±Ô∏è\"\n    \n    # Enhanced Animated Progress Icons\n    SPINNER_FRAMES = [\"‚†ã\", \"‚†ô\", \"‚†π\", \"‚†∏\", \"‚†º\", \"‚†¥\", \"‚†¶\", \"‚†ß\", \"‚†á\", \"‚†è\"]\n    PROGRESS_FRAMES = [\"‚óê\", \"‚óì\", \"‚óë\", \"‚óí\"]\n    PULSE_FRAMES = [\"üíô\", \"üíö\", \"üíõ\", \"üß°\", \"‚ù§Ô∏è\", \"üíú\"]\n    RAINBOW_PROGRESS = [\"üî¥\", \"üü†\", \"üü°\", \"üü¢\", \"üîµ\", \"üü£\"]\n    FIRE_FRAMES = [\"üî•\", \"üöÄ\", \"‚ö°\", \"üí•\", \"üî•\"]\n    STAR_FRAMES = [\"üí´\", \"‚≠ê\", \"‚ú®\", \"üåü\", \"üí´\"]\n    \n    # Interactive Animation Sets\n    DOWNLOAD_ANIMATION = [\"üì•üí´\", \"üì•‚≠ê\", \"üì•‚ú®\", \"üì•üåü\", \"üì•üí´\"]\n    UPLOAD_ANIMATION = [\"üì§üî•\", \"üì§üöÄ\", \"üì§‚ö°\", \"üì§üí•\", \"üì§üî•\"]\n    SUCCESS_FRAMES = [\"‚úÖüéâ\", \"‚úÖüéä\", \"‚úÖü•≥\", \"‚úÖüéà\", \"‚úÖüéâ\"]\n    ERROR_FRAMES = [\"‚ùåüí•\", \"‚ùå‚ö†Ô∏è\", \"‚ùåüö´\", \"‚ùåüíî\", \"‚ùåüí•\"]\n    \n    # Special Effect Icons\n    MAGIC = \"‚ú®\"\n    BOOM = \"üí•\"\n    HEART_EYES = \"üòç\"\n    PARTY = \"üéâ\"\n    CELEBRATION = \"üéä\"\n    THUMBS_UP = \"üëç\"\n    MUSCLE = \"üí™\"\n    LIGHTNING = \"‚ö°\"\n    \n    # Success and Error Icons\n    SUCCESS = \"‚úÖ\"\n    CHECK = \"‚òëÔ∏è\"\n    ERROR = \"‚ùå\"\n    WARNING = \"‚ö†Ô∏è\"\n    INFO = \"‚ÑπÔ∏è\"\n    QUESTION = \"‚ùì\"\n    EXCLAMATION = \"‚ùó\"\n    \n    # Cancel and Stop Icons\n    CANCEL = \"üö´\"\n    CANCELLED = \"‚õî\"\n    STOP = \"üõë\"\n    PAUSE = \"‚è∏Ô∏è\"\n    PLAY = \"‚ñ∂Ô∏è\"\n    \n    # Platform Icons\n    PLATFORMS = \"üåê\"\n    YOUTUBE = \"üî¥\"\n    TIKTOK = \"‚ö´\"\n    INSTAGRAM = \"üì∏\"\n    FACEBOOK = \"üîµ\"\n    TWITTER = \"üê¶\"\n    X_TWITTER = \"‚ùå\"\n    DAILYMOTION = \"üü†\"\n    VIMEO = \"üîµ\"\n    TWITCH = \"üü£\"\n    REDDIT = \"üî∏\"\n    \n    # Quality and Format Icons\n    QUALITY = \"üéØ\"\n    HD = \"üì∫\"\n    FOUR_K = \"üé¨\"\n    AUDIO_ONLY = \"üéµ\"\n    \n    # Speed and Performance Icons\n    SPEED = \"üöÄ\"\n    FAST = \"‚ö°\"\n    TURBO = \"üî•\"\n    MEGA_SPEED = \"üí®\"\n    \n    # Interactive Elements\n    BUTTON = \"üîò\"\n    TOGGLE = \"üîÄ\"\n    SETTINGS_GEAR = \"‚öôÔ∏è\"\n    \n    # Fun Status Icons\n    WORKING = \"üîß\"\n    COOKING = \"üë®‚Äçüç≥\"\n    MAGIC_WAND = \"ü™Ñ\"\n    CRYSTAL_BALL = \"üîÆ\"\n    FORMAT = \"üìã\"\n    HD = \"üî•\"\n    FOUR_K = \"üíé\"\n    AUDIO_ONLY = \"üéµ\"\n    MP4 = \"üìπ\"\n    MP3 = \"üéµ\"\n    \n    # File and Size Icons\n    FILE = \"üìÑ\"\n    FOLDER = \"üìÅ\"\n    SIZE = \"üìè\"\n    LARGE_FILE = \"üìä\"\n    ARCHIVE = \"üóÉÔ∏è\"\n    DOCUMENT = \"üìã\"\n    \n    # Speed and Performance Icons\n    SPEED = \"‚ö°\"\n    FAST = \"üí®\"\n    SLOW = \"üêå\"\n    PERFORMANCE = \"üìà\"\n    OPTIMIZATION = \"‚öôÔ∏è\"\n    TURBO = \"üöÄ\"\n    \n    # User and Social Icons\n    USER = \"üë§\"\n    USERS = \"üë•\"\n    PROFILE = \"üë§\"\n    ACCOUNT = \"üßë‚Äçüíº\"\n    ADMIN = \"üëë\"\n    VIP = \"üíé\"\n    DEVELOPER = \"üë®‚Äçüíª\"\n    \n    # Navigation Icons\n    BACK = \"‚óÄÔ∏è\"\n    FORWARD = \"‚ñ∂Ô∏è\"\n    UP = \"üîº\"\n    DOWN = \"üîΩ\"\n    LEFT = \"‚óÄÔ∏è\"\n    RIGHT = \"‚ñ∂Ô∏è\"\n    HOME = \"üè†\"\n    MENU = \"‚ò∞\"\n    \n    # Communication Icons\n    MESSAGE = \"üí¨\"\n    CHAT = \"üí≠\"\n    NOTIFICATION = \"üîî\"\n    BELL = \"üîî\"\n    MUTE = \"üîá\"\n    VOICE = \"üéôÔ∏è\"\n    \n    # Settings and Configuration Icons\n    SETTINGS = \"‚öôÔ∏è\"\n    CONFIG = \"üîß\"\n    PREFERENCES = \"üéõÔ∏è\"\n    TOOLS = \"üõ†Ô∏è\"\n    WRENCH = \"üîß\"\n    GEAR = \"‚öôÔ∏è\"\n    \n    # Network and Connection Icons\n    NETWORK = \"üåê\"\n    WIFI = \"üì∂\"\n    SIGNAL = \"üì°\"\n    LINK = \"üîó\"\n    CHAIN = \"‚õìÔ∏è\"\n    GLOBE = \"üåç\"\n    \n    # Time and Date Icons\n    TIME = \"‚è∞\"\n    DATE = \"üìÖ\"\n    CALENDAR = \"üìÖ\"\n    SCHEDULE = \"üóìÔ∏è\"\n    DEADLINE = \"‚è∞\"\n    DURATION = \"‚è±Ô∏è\"\n    \n    # Data and Statistics Icons\n    DATA = \"üìä\"\n    CHART = \"üìà\"\n    GRAPH = \"üìä\"\n    STATS = \"üìä\"\n    ANALYTICS = \"üìà\"\n    METRICS = \"üìä\"\n    TRENDING = \"üìà\"\n    \n    # Storage and Memory Icons\n    STORAGE = \"üíæ\"\n    DISK = \"üíø\"\n    MEMORY = \"üß†\"\n    CACHE = \"‚ö°\"\n    DATABASE = \"üóÉÔ∏è\"\n    SERVER = \"üñ•Ô∏è\"\n    \n    # Security Icons\n    LOCK = \"üîí\"\n    UNLOCK = \"üîì\"\n    KEY = \"üîë\"\n    SHIELD = \"üõ°Ô∏è\"\n    SECURITY = \"üîê\"\n    PRIVATE = \"üîí\"\n    PUBLIC = \"üîì\"\n    \n    # Help and Support Icons\n    HELP = \"‚ùì\"\n    SUPPORT = \"üÜò\"\n    FAQ = \"‚ùî\"\n    GUIDE = \"üìñ\"\n    TUTORIAL = \"üìö\"\n    MANUAL = \"üìñ\"\n    \n    # Features and Capabilities Icons\n    FEATURES = \"‚≠ê\"\n    NEW = \"üÜï\"\n    HOT = \"üî•\"\n    POPULAR = \"üëç\"\n    TRENDING_UP = \"üìà\"\n    PREMIUM = \"üíé\"\n    \n    # System Icons\n    SYSTEM = \"üíª\"\n    CPU = \"üñ•Ô∏è\"\n    RAM = \"üß†\"\n    DISK_USAGE = \"üíø\"\n    TEMPERATURE = \"üå°Ô∏è\"\n    POWER = \"üîã\"\n    \n    # Action Icons\n    PLAY_BUTTON = \"‚ñ∂Ô∏è\"\n    PAUSE_BUTTON = \"‚è∏Ô∏è\"\n    STOP_BUTTON = \"‚èπÔ∏è\"\n    SKIP = \"‚è≠Ô∏è\"\n    PREVIOUS = \"‚èÆÔ∏è\"\n    REPEAT = \"üîÅ\"\n    SHUFFLE = \"üîÄ\"\n    \n    # Emoji and Fun Icons\n    HEART = \"‚ù§Ô∏è\"\n    LIKE = \"üëç\"\n    DISLIKE = \"üëé\"\n    LOVE = \"üòç\"\n    SMILE = \"üòä\"\n    LAUGH = \"üòÇ\"\n    COOL = \"üòé\"\n    PARTY = \"üéâ\"\n    CELEBRATION = \"üéä\"\n    GIFT = \"üéÅ\"\n    \n    # Directional and Movement Icons\n    ARROW_UP = \"‚¨ÜÔ∏è\"\n    ARROW_DOWN = \"‚¨áÔ∏è\"\n    ARROW_LEFT = \"‚¨ÖÔ∏è\"\n    ARROW_RIGHT = \"‚û°Ô∏è\"\n    ARROW_UP_RIGHT = \"‚ÜóÔ∏è\"\n    ARROW_DOWN_RIGHT = \"‚ÜòÔ∏è\"\n    ARROW_DOWN_LEFT = \"‚ÜôÔ∏è\"\n    ARROW_UP_LEFT = \"‚ÜñÔ∏è\"\n    \n    # Status Indicators\n    ONLINE = \"üü¢\"\n    OFFLINE = \"üî¥\"\n    IDLE = \"üü°\"\n    BUSY = \"üü†\"\n    AWAY = \"‚ö™\"\n    UNKNOWN = \"‚ö´\"\n    \n    # Weather and Nature Icons\n    SUN = \"‚òÄÔ∏è\"\n    MOON = \"üåô\"\n    STAR_ICON = \"‚≠ê\"\n    LIGHTNING = \"‚ö°\"\n    CLOUD = \"‚òÅÔ∏è\"\n    RAIN = \"üåßÔ∏è\"\n    \n    # Transportation Icons\n    ROCKET_ICON = \"üöÄ\"\n    AIRPLANE = \"‚úàÔ∏è\"\n    CAR = \"üöó\"\n    TRAIN = \"üöÜ\"\n    SHIP = \"üö¢\"\n    BICYCLE = \"üö≤\"\n    \n    # Food and Drink Icons\n    COFFEE = \"‚òï\"\n    TEA = \"üçµ\"\n    PIZZA = \"üçï\"\n    BURGER = \"üçî\"\n    CAKE = \"üéÇ\"\n    APPLE = \"üçé\"\n    \n    # Office and Work Icons\n    BRIEFCASE = \"üíº\"\n    OFFICE = \"üè¢\"\n    COMPUTER = \"üíª\"\n    PHONE = \"üì±\"\n    EMAIL = \"üìß\"\n    FAX = \"üì†\"\n    \n    # Miscellaneous Icons\n    MAGIC = \"‚ú®\"\n    CRYSTAL_BALL = \"üîÆ\"\n    RAINBOW = \"üåà\"\n    UNICORN = \"ü¶Ñ\"\n    DRAGON = \"üêâ\"\n    ALIEN = \"üëΩ\"\n    \n    # Version and Update Icons\n    UPDATE = \"üîÑ\"\n    VERSION = \"üè∑Ô∏è\"\n    CHANGELOG = \"üìù\"\n    RELEASE = \"üöÄ\"\n    BETA = \"üß™\"\n    ALPHA = \"üî¨\"\n    \n    # Special Characters\n    BULLET = \"‚Ä¢\"\n    DASH = \"‚Äî\"\n    DOT = \"¬∑\"\n    SEPARATOR = \"‚îÅ\"\n    DIVIDER = \"‚îà\"\n    \n    # Custom Bot Icons\n    BOT_FACE = \"ü§ñ\"\n    BOT_HAPPY = \"üòä\"\n    BOT_WORKING = \"‚öôÔ∏è\"\n    BOT_SLEEPING = \"üò¥\"\n    BOT_THINKING = \"ü§î\"\n    \n    # Process Status Icons\n    INITIALIZING = \"üîÑ\"\n    PROCESSING = \"‚öôÔ∏è\"\n    COMPLETED = \"‚úÖ\"\n    FAILED = \"‚ùå\"\n    PENDING = \"‚è≥\"\n    QUEUED = \"üìã\"\n    \n    # Special Action Icons\n    COPY = \"üìã\"\n    PASTE = \"üìã\"\n    CUT = \"‚úÇÔ∏è\"\n    EDIT = \"‚úèÔ∏è\"\n    DELETE = \"üóëÔ∏è\"\n    ADD = \"‚ûï\"\n    MINUS = \"‚ûñ\"\n    MULTIPLY = \"‚úñÔ∏è\"\n    DIVIDE = \"‚ûó\"\n    \n    # Additional Utility Icons\n    BOOKMARK = \"üîñ\"\n    TAG = \"üè∑Ô∏è\"\n    LABEL = \"üè∑Ô∏è\"\n    CATEGORY = \"üìÇ\"\n    FILTER = \"üîç\"\n    SEARCH = \"üîé\"\n    FIND = \"üîç\"\n    \n    # Communication Status Icons\n    TYPING = \"üí≠\"\n    SENDING = \"üì§\"\n    SENT = \"‚úÖ\"\n    DELIVERED = \"‚úÖ\"\n    READ = \"üëÅÔ∏è\"\n    UNREAD = \"üì¨\"\n    \n    # Quality Indicators\n    EXCELLENT = \"üèÜ\"\n    GOOD = \"üëç\"\n    AVERAGE = \"üëå\"\n    POOR = \"üëé\"\n    TERRIBLE = \"üíÄ\"\n    \n    # Priority Icons\n    HIGH_PRIORITY = \"üî¥\"\n    MEDIUM_PRIORITY = \"üü°\"\n    LOW_PRIORITY = \"üü¢\"\n    URGENT = \"üö®\"\n    \n    # Special Status Icons\n    NEW_DOWNLOAD = \"‚¨áÔ∏è\"\n    RETRY = \"üîÑ\"\n    REASON = \"üìù\"\n    SOLUTIONS = \"üí°\"\n    RESPECT = \"üôè\"\n    COPYRIGHT = \"¬©Ô∏è\"\n    RESTRICTED = \"üîû\"\n    TIP = \"üí°\"\n    SIMPLE = \"üëÜ\"\n    EXAMPLE = \"üìù\"\n    DETAILS = \"‚ÑπÔ∏è\"\n    \n    # Fun and Interaction Icons\n    WAVE = \"üëã\"\n    THUMBS_UP = \"üëç\"\n    THUMBS_DOWN = \"üëé\"\n    CLAP = \"üëè\"\n    HIGH_FIVE = \"üôè\"\n    PEACE = \"‚úåÔ∏è\"\n    OK_HAND = \"üëå\"\n    \n    # Seasonal Icons\n    CHRISTMAS = \"üéÑ\"\n    HALLOWEEN = \"üéÉ\"\n    VALENTINE = \"üíñ\"\n    BIRTHDAY = \"üéÇ\"\n    NEW_YEAR = \"üéä\"\n    \n    # Tool Icons\n    HAMMER = \"üî®\"\n    SCREWDRIVER = \"ü™õ\"\n    WRENCH_ALT = \"üîß\"\n    SCISSORS = \"‚úÇÔ∏è\"\n    RULER = \"üìè\"\n    COMPASS = \"üß≠\"\n    \n    # Communication Types\n    EMAIL_ICON = \"üìß\"\n    PHONE_ICON = \"üìû\"\n    VIDEO_CALL = \"üìπ\"\n    VOICE_CALL = \"üéôÔ∏è\"\n    TEXT_MESSAGE = \"üí¨\"\n    \n    # Special Characters for UI\n    CHECKBOX_CHECKED = \"‚òëÔ∏è\"\n    CHECKBOX_UNCHECKED = \"‚òê\"\n    RADIO_CHECKED = \"üîò\"\n    RADIO_UNCHECKED = \"‚ö™\"\n    \n    # File Type Icons\n    VIDEO_FILE = \"üé¨\"\n    AUDIO_FILE = \"üéµ\"\n    IMAGE_FILE = \"üñºÔ∏è\"\n    TEXT_FILE = \"üìÑ\"\n    PDF_FILE = \"üìï\"\n    ZIP_FILE = \"üóúÔ∏è\"\n    \n    # Social Media Specific\n    LIKE_ICON = \"‚ù§Ô∏è\"\n    SHARE = \"üîÑ\"\n    COMMENT = \"üí¨\"\n    FOLLOW = \"‚ûï\"\n    UNFOLLOW = \"‚ûñ\"\n    SUBSCRIBE = \"üîî\"\n    \n    # Gaming Icons\n    JOYSTICK = \"üïπÔ∏è\"\n    GAME = \"üéÆ\"\n    TROPHY_CUP = \"üèÜ\"\n    MEDAL = \"üèÖ\"\n    TARGET = \"üéØ\"\n    DICE = \"üé≤\"\n    \n    # Math and Science Icons\n    CALCULATOR = \"üßÆ\"\n    MICROSCOPE = \"üî¨\"\n    TELESCOPE = \"üî≠\"\n    TEST_TUBE = \"üß™\"\n    DNA = \"üß¨\"\n    ATOM = \"‚öõÔ∏è\"\n    \n    # Cleanup and Maintenance Icons\n    CLEANUP = \"üßπ\"\n    TRASH = \"üóëÔ∏è\"\n    RECYCLE = \"‚ôªÔ∏è\"\n    BROOM = \"üßπ\"\n    VACUUM = \"üßΩ\"\n    \n    # Special Bot Commands Icons\n    BROADCAST = \"üì¢\"\n    MAINTENANCE = \"üîß\"\n    LOGS = \"üìã\"\n    BACKUP = \"üíæ\"\n    HISTORY = \"üìú\"\n    STICKER = \"üé≠\"\n    FUN = \"üéâ\"\n    VIEWS = \"üëÄ\"\n    ADVANCED = \"üî¨\"\n    RESET = \"üîÑ\"\n    \n    # Missing Icons for Handlers\n    BATCH = \"üì¶\"\n    COMMANDS = \"‚å®Ô∏è\"\n    STATUS = \"üìä\"\n    NOTIFICATIONS = \"üîî\"\n    PLATFORM = \"üåê\"\n    DOWNLOADS = \"üì•\"\n    \n    @classmethod\n    def get_platform_icon(cls, platform: str) -> str:\n        \"\"\"Get icon for a specific platform\"\"\"\n        platform_icons = {\n            'youtube': cls.YOUTUBE,\n            'tiktok': cls.TIKTOK,\n            'instagram': cls.INSTAGRAM,\n            'facebook': cls.FACEBOOK,\n            'twitter': cls.TWITTER,\n            'x': cls.X_TWITTER,\n            'dailymotion': cls.DAILYMOTION,\n            'vimeo': cls.VIMEO,\n            'twitch': cls.TWITCH,\n            'reddit': cls.REDDIT\n        }\n        return platform_icons.get(platform.lower(), cls.VIDEO)\n    \n    @classmethod\n    def get_quality_icon(cls, quality: str) -> str:\n        \"\"\"Get icon for video quality\"\"\"\n        quality_lower = quality.lower()\n        if '4k' in quality_lower or '2160p' in quality_lower:\n            return cls.TROPHY\n        elif '1440p' in quality_lower:\n            return cls.DIAMOND\n        elif '1080p' in quality_lower:\n            return cls.FIRE\n        elif '720p' in quality_lower:\n            return cls.SPARKLES\n        else:\n            return cls.VIDEO\n    \n    @classmethod\n    def get_status_icon(cls, status: str) -> str:\n        \"\"\"Get icon for operation status\"\"\"\n        status_icons = {\n            'pending': cls.PENDING,\n            'downloading': cls.DOWNLOAD,\n            'uploading': cls.UPLOAD,\n            'processing': cls.PROCESSING,\n            'completed': cls.SUCCESS,\n            'failed': cls.ERROR,\n            'cancelled': cls.CANCELLED,\n            'queued': cls.QUEUED\n        }\n        return status_icons.get(status.lower(), cls.QUESTION)\n    \n    @classmethod\n    def get_file_type_icon(cls, file_extension: str) -> str:\n        \"\"\"Get icon for file type\"\"\"\n        ext = file_extension.lower().lstrip('.')\n        \n        video_exts = {'mp4', 'avi', 'mkv', 'mov', 'webm', 'flv', 'wmv'}\n        audio_exts = {'mp3', 'wav', 'aac', 'ogg', 'm4a', 'flac'}\n        image_exts = {'jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp'}\n        \n        if ext in video_exts:\n            return cls.VIDEO_FILE\n        elif ext in audio_exts:\n            return cls.AUDIO_FILE\n        elif ext in image_exts:\n            return cls.IMAGE_FILE\n        else:\n            return cls.FILE\n","size_bytes":12865},"utils/__init__.py":{"content":"\"\"\"Utilities module for the video downloader bot\"\"\"\n\nfrom .helpers import (\n    generate_task_id, format_file_size, calculate_upload_speed, calculate_eta,\n    sanitize_filename, truncate_text, get_file_hash, serialize_for_cache,\n    deserialize_from_cache, get_system_stats, create_welcome_message,\n    create_error_message, create_format_selection_keyboard,\n    create_download_progress_message, setup_logging, cleanup_temp_files,\n    validate_environment, format_bytes_per_second, is_url_safe,\n    get_platform_emoji, run_with_timeout, chunks, safe_int, safe_float,\n    create_progress_bar, get_mime_type, is_video_file, is_audio_file,\n    get_file_extension, RateLimiter\n)\n\nfrom .validators import (\n    is_valid_url, get_platform_from_url, get_platform_info, extract_video_id,\n    normalize_url, is_playlist_url, validate_platform_support,\n    get_supported_platforms, extract_url_from_text, validate_file_size_limit,\n    is_live_stream_url, sanitize_url, get_platform_limitations,\n    PlatformInfo, SUPPORTED_PLATFORMS\n)\n\nfrom .formatters import (\n    format_file_size as format_file_size_alt, format_duration, format_speed,\n    format_view_count, format_upload_time, format_uptime, format_percentage,\n    format_timestamp, format_relative_time, format_quality_badge,\n    format_platform_name, format_error_message, format_progress_bar,\n    format_eta, format_number, truncate_text as truncate_text_alt,\n    format_success_rate\n)\n\n__all__ = [\n    # Helper functions\n    'generate_task_id', 'format_file_size', 'calculate_upload_speed', \n    'calculate_eta', 'sanitize_filename', 'truncate_text', 'get_file_hash',\n    'serialize_for_cache', 'deserialize_from_cache', 'get_system_stats',\n    'create_welcome_message', 'create_error_message', 'create_format_selection_keyboard',\n    'create_download_progress_message', 'setup_logging', 'cleanup_temp_files',\n    'validate_environment', 'format_bytes_per_second', 'is_url_safe',\n    'get_platform_emoji', 'run_with_timeout', 'chunks', 'safe_int', 'safe_float',\n    'create_progress_bar', 'get_mime_type', 'is_video_file', 'is_audio_file',\n    'get_file_extension', 'RateLimiter',\n    \n    # Validator functions\n    'is_valid_url', 'get_platform_from_url', 'get_platform_info', 'extract_video_id',\n    'normalize_url', 'is_playlist_url', 'validate_platform_support',\n    'get_supported_platforms', 'extract_url_from_text', 'validate_file_size_limit',\n    'is_live_stream_url', 'sanitize_url', 'get_platform_limitations',\n    'PlatformInfo', 'SUPPORTED_PLATFORMS',\n    \n    # Formatter functions\n    'format_duration', 'format_speed', 'format_view_count', 'format_upload_time',\n    'format_uptime', 'format_percentage', 'format_timestamp', 'format_relative_time',\n    'format_quality_badge', 'format_platform_name', 'format_error_message',\n    'format_progress_bar', 'format_eta', 'format_number', 'format_success_rate'\n]\n","size_bytes":2871},"utils/formatters.py":{"content":"\"\"\"\nFormatting utilities for displaying data in user-friendly formats\nHandles file sizes, durations, speeds, dates, and other data formatting\n\"\"\"\n\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Union, Optional, Any\nimport re\n\nlogger = logging.getLogger(__name__)\n\ndef format_file_size(size_bytes: Union[int, float]) -> str:\n    \"\"\"\n    Format file size in human readable format\n    \n    Args:\n        size_bytes: Size in bytes\n        \n    Returns:\n        str: Formatted file size (e.g., \"1.5 GB\", \"512 MB\")\n    \"\"\"\n    try:\n        if not size_bytes or size_bytes < 0:\n            return \"0 B\"\n        \n        # Convert to int if float\n        size_bytes = int(size_bytes)\n        \n        # Size units\n        units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n        unit_index = 0\n        size = float(size_bytes)\n        \n        # Convert to appropriate unit\n        while size >= 1024.0 and unit_index < len(units) - 1:\n            size /= 1024.0\n            unit_index += 1\n        \n        # Format based on size\n        if unit_index == 0:  # Bytes\n            return f\"{int(size)} {units[unit_index]}\"\n        elif size >= 100:  # No decimal for large numbers\n            return f\"{int(size)} {units[unit_index]}\"\n        elif size >= 10:   # One decimal place\n            return f\"{size:.1f} {units[unit_index]}\"\n        else:              # Two decimal places for small numbers\n            return f\"{size:.2f} {units[unit_index]}\"\n        \n    except Exception as e:\n        logger.error(f\"File size formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_duration(seconds: Union[int, float, None]) -> str:\n    \"\"\"\n    Format duration in human readable format\n    \n    Args:\n        seconds: Duration in seconds\n        \n    Returns:\n        str: Formatted duration (e.g., \"1:23:45\", \"5:30\", \"0:45\")\n    \"\"\"\n    try:\n        if not seconds or seconds < 0:\n            return \"0:00\"\n        \n        seconds = int(seconds)\n        \n        # Calculate hours, minutes, seconds\n        hours = seconds // 3600\n        minutes = (seconds % 3600) // 60\n        secs = seconds % 60\n        \n        # Format based on duration\n        if hours > 0:\n            return f\"{hours}:{minutes:02d}:{secs:02d}\"\n        else:\n            return f\"{minutes}:{secs:02d}\"\n        \n    except Exception as e:\n        logger.error(f\"Duration formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_speed(bytes_per_second: Union[int, float, None]) -> str:\n    \"\"\"\n    Format speed in human readable format\n    \n    Args:\n        bytes_per_second: Speed in bytes per second\n        \n    Returns:\n        str: Formatted speed (e.g., \"5.2 MB/s\", \"1.8 GB/s\")\n    \"\"\"\n    try:\n        if not bytes_per_second or bytes_per_second <= 0:\n            return \"0 B/s\"\n        \n        # Use file size formatter and add /s\n        size_str = format_file_size(bytes_per_second)\n        return f\"{size_str}/s\"\n        \n    except Exception as e:\n        logger.error(f\"Speed formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_view_count(view_count: Union[int, None]) -> str:\n    \"\"\"\n    Format view count in human readable format\n    \n    Args:\n        view_count: Number of views\n        \n    Returns:\n        str: Formatted view count (e.g., \"1.2M\", \"5.6K\", \"1,234\")\n    \"\"\"\n    try:\n        if not view_count or view_count < 0:\n            return \"0\"\n        \n        view_count = int(view_count)\n        \n        if view_count >= 1_000_000_000:\n            return f\"{view_count / 1_000_000_000:.1f}B\"\n        elif view_count >= 1_000_000:\n            return f\"{view_count / 1_000_000:.1f}M\"\n        elif view_count >= 1_000:\n            return f\"{view_count / 1_000:.1f}K\"\n        else:\n            return f\"{view_count:,}\"\n        \n    except Exception as e:\n        logger.error(f\"View count formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_upload_time(seconds: Union[int, float, None]) -> str:\n    \"\"\"\n    Format upload/processing time in human readable format\n    \n    Args:\n        seconds: Time in seconds\n        \n    Returns:\n        str: Formatted time (e.g., \"2m 30s\", \"1h 15m\", \"45s\")\n    \"\"\"\n    try:\n        if not seconds or seconds < 0:\n            return \"0s\"\n        \n        seconds = int(seconds)\n        \n        # Calculate time components\n        hours = seconds // 3600\n        minutes = (seconds % 3600) // 60\n        secs = seconds % 60\n        \n        # Format based on duration\n        if hours > 0:\n            if minutes > 0:\n                return f\"{hours}h {minutes}m\"\n            else:\n                return f\"{hours}h\"\n        elif minutes > 0:\n            if secs > 0:\n                return f\"{minutes}m {secs}s\"\n            else:\n                return f\"{minutes}m\"\n        else:\n            return f\"{secs}s\"\n        \n    except Exception as e:\n        logger.error(f\"Upload time formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_uptime(seconds: Union[int, float, None]) -> str:\n    \"\"\"\n    Format system uptime in human readable format\n    \n    Args:\n        seconds: Uptime in seconds\n        \n    Returns:\n        str: Formatted uptime (e.g., \"2 days, 5 hours\", \"3 hours, 20 minutes\")\n    \"\"\"\n    try:\n        if not seconds or seconds < 0:\n            return \"Unknown\"\n        \n        seconds = int(seconds)\n        \n        # Calculate time components\n        days = seconds // 86400\n        hours = (seconds % 86400) // 3600\n        minutes = (seconds % 3600) // 60\n        \n        # Format based on duration\n        parts = []\n        \n        if days > 0:\n            parts.append(f\"{days} day{'s' if days != 1 else ''}\")\n        \n        if hours > 0:\n            parts.append(f\"{hours} hour{'s' if hours != 1 else ''}\")\n        \n        if minutes > 0 and days == 0:  # Don't show minutes if showing days\n            parts.append(f\"{minutes} minute{'s' if minutes != 1 else ''}\")\n        \n        if not parts:  # Less than a minute\n            return \"Less than a minute\"\n        \n        return \", \".join(parts)\n        \n    except Exception as e:\n        logger.error(f\"Uptime formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_percentage(value: Union[int, float, None], decimal_places: int = 1) -> str:\n    \"\"\"\n    Format percentage value\n    \n    Args:\n        value: Percentage value (0-100)\n        decimal_places: Number of decimal places\n        \n    Returns:\n        str: Formatted percentage (e.g., \"85.5%\", \"100%\")\n    \"\"\"\n    try:\n        if value is None:\n            return \"0%\"\n        \n        value = float(value)\n        \n        if decimal_places == 0:\n            return f\"{int(value)}%\"\n        else:\n            return f\"{value:.{decimal_places}f}%\"\n        \n    except Exception as e:\n        logger.error(f\"Percentage formatting error: {e}\")\n        return \"0%\"\n\ndef format_timestamp(timestamp: Union[datetime, float, int, str, None], format_type: str = 'relative') -> str:\n    \"\"\"\n    Format timestamp in various formats\n    \n    Args:\n        timestamp: Timestamp to format\n        format_type: Type of formatting ('relative', 'absolute', 'date', 'time')\n        \n    Returns:\n        str: Formatted timestamp\n    \"\"\"\n    try:\n        if not timestamp:\n            return \"Unknown\"\n        \n        # Convert to datetime if needed\n        if isinstance(timestamp, (int, float)):\n            dt = datetime.fromtimestamp(timestamp)\n        elif isinstance(timestamp, str):\n            # Try parsing ISO format\n            try:\n                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))\n            except:\n                return timestamp\n        elif isinstance(timestamp, datetime):\n            dt = timestamp\n        else:\n            return \"Unknown\"\n        \n        now = datetime.now(dt.tzinfo) if dt.tzinfo else datetime.now()\n        \n        if format_type == 'relative':\n            return format_relative_time(dt, now)\n        elif format_type == 'absolute':\n            return dt.strftime('%B %d, %Y at %I:%M %p')\n        elif format_type == 'date':\n            return dt.strftime('%B %d, %Y')\n        elif format_type == 'time':\n            return dt.strftime('%I:%M %p')\n        else:\n            return dt.strftime('%Y-%m-%d %H:%M:%S')\n        \n    except Exception as e:\n        logger.error(f\"Timestamp formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_relative_time(dt: datetime, now: datetime = None) -> str:\n    \"\"\"\n    Format relative time (e.g., \"2 hours ago\", \"in 5 minutes\")\n    \n    Args:\n        dt: Datetime to format\n        now: Current datetime (defaults to now)\n        \n    Returns:\n        str: Relative time string\n    \"\"\"\n    try:\n        if now is None:\n            now = datetime.now(dt.tzinfo) if dt.tzinfo else datetime.now()\n        \n        diff = now - dt\n        future = diff.total_seconds() < 0\n        \n        if future:\n            diff = dt - now\n            prefix = \"in \"\n            suffix = \"\"\n        else:\n            prefix = \"\"\n            suffix = \" ago\"\n        \n        seconds = abs(diff.total_seconds())\n        \n        # Format based on time difference\n        if seconds < 60:\n            return f\"{prefix}just now{suffix}\" if not future else \"in a moment\"\n        elif seconds < 3600:  # Less than 1 hour\n            minutes = int(seconds // 60)\n            unit = \"minute\" if minutes == 1 else \"minutes\"\n            return f\"{prefix}{minutes} {unit}{suffix}\"\n        elif seconds < 86400:  # Less than 1 day\n            hours = int(seconds // 3600)\n            unit = \"hour\" if hours == 1 else \"hours\"\n            return f\"{prefix}{hours} {unit}{suffix}\"\n        elif seconds < 2592000:  # Less than 30 days\n            days = int(seconds // 86400)\n            unit = \"day\" if days == 1 else \"days\"\n            return f\"{prefix}{days} {unit}{suffix}\"\n        elif seconds < 31536000:  # Less than 1 year\n            months = int(seconds // 2592000)\n            unit = \"month\" if months == 1 else \"months\"\n            return f\"{prefix}{months} {unit}{suffix}\"\n        else:\n            years = int(seconds // 31536000)\n            unit = \"year\" if years == 1 else \"years\"\n            return f\"{prefix}{years} {unit}{suffix}\"\n        \n    except Exception as e:\n        logger.error(f\"Relative time formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_quality_badge(quality: str) -> str:\n    \"\"\"\n    Format quality with appropriate badge/emoji\n    \n    Args:\n        quality: Quality string (e.g., \"1080p\", \"720p\")\n        \n    Returns:\n        str: Formatted quality with badge\n    \"\"\"\n    try:\n        if not quality:\n            return \"Unknown\"\n        \n        quality_lower = quality.lower()\n        \n        # Quality badges\n        if '4k' in quality_lower or '2160p' in quality_lower:\n            return f\"üèÜ {quality}\"\n        elif '1440p' in quality_lower or '2k' in quality_lower:\n            return f\"üíé {quality}\"\n        elif '1080p' in quality_lower or 'fhd' in quality_lower:\n            return f\"üî• {quality}\"\n        elif '720p' in quality_lower or 'hd' in quality_lower:\n            return f\"‚ú® {quality}\"\n        elif '480p' in quality_lower:\n            return f\"üì± {quality}\"\n        elif '360p' in quality_lower or '240p' in quality_lower:\n            return f\"üì∂ {quality}\"\n        else:\n            return quality\n        \n    except Exception as e:\n        logger.error(f\"Quality badge formatting error: {e}\")\n        return quality or \"Unknown\"\n\ndef format_platform_name(platform: str) -> str:\n    \"\"\"\n    Format platform name with proper capitalization and emoji\n    \n    Args:\n        platform: Platform name\n        \n    Returns:\n        str: Formatted platform name\n    \"\"\"\n    try:\n        if not platform:\n            return \"Unknown\"\n        \n        platform_lower = platform.lower()\n        \n        # Platform formatting with emojis\n        platform_map = {\n            'youtube': 'üî¥ YouTube',\n            'tiktok': '‚ö´ TikTok',\n            'instagram': 'üì∏ Instagram',\n            'facebook': 'üîµ Facebook',\n            'twitter': 'üê¶ Twitter',\n            'x': '‚ùå X (Twitter)',\n            'dailymotion': 'üü† Dailymotion',\n            'vimeo': 'üîµ Vimeo',\n            'twitch': 'üü£ Twitch',\n            'reddit': 'üî∏ Reddit',\n            'streamable': 'üé¨ Streamable'\n        }\n        \n        return platform_map.get(platform_lower, f\"üé¨ {platform.title()}\")\n        \n    except Exception as e:\n        logger.error(f\"Platform name formatting error: {e}\")\n        return platform or \"Unknown\"\n\ndef format_error_message(error: str, max_length: int = 100) -> str:\n    \"\"\"\n    Format error message for user display\n    \n    Args:\n        error: Error message\n        max_length: Maximum length of formatted message\n        \n    Returns:\n        str: Formatted error message\n    \"\"\"\n    try:\n        if not error:\n            return \"Unknown error\"\n        \n        # Clean up technical error messages\n        error = str(error)\n        \n        # Remove common technical prefixes\n        technical_prefixes = [\n            'ERROR: ',\n            'Exception: ',\n            'RuntimeError: ',\n            'ValueError: ',\n            'HTTPError: ',\n            'URLError: '\n        ]\n        \n        for prefix in technical_prefixes:\n            if error.startswith(prefix):\n                error = error[len(prefix):]\n                break\n        \n        # Truncate if too long\n        if len(error) > max_length:\n            error = error[:max_length - 3] + \"...\"\n        \n        # Capitalize first letter\n        error = error[0].upper() + error[1:] if error else \"\"\n        \n        return error\n        \n    except Exception as e:\n        logger.error(f\"Error message formatting error: {e}\")\n        return \"An error occurred\"\n\ndef format_progress_bar(\n    current: int, \n    total: int, \n    length: int = 20, \n    filled_char: str = '‚ñà', \n    empty_char: str = '‚ñë'\n) -> str:\n    \"\"\"\n    Create a visual progress bar\n    \n    Args:\n        current: Current progress value\n        total: Total value\n        length: Length of progress bar in characters\n        filled_char: Character for filled portion\n        empty_char: Character for empty portion\n        \n    Returns:\n        str: Formatted progress bar\n    \"\"\"\n    try:\n        if total <= 0:\n            percentage = 0\n        else:\n            percentage = min(100, max(0, (current / total) * 100))\n        \n        filled_length = int(length * percentage / 100)\n        empty_length = length - filled_length\n        \n        bar = filled_char * filled_length + empty_char * empty_length\n        \n        return f\"[{bar}] {percentage:.1f}%\"\n        \n    except Exception as e:\n        logger.error(f\"Progress bar formatting error: {e}\")\n        return f\"[{'‚ñë' * length}] 0.0%\"\n\ndef format_eta(seconds: Union[int, float, None]) -> str:\n    \"\"\"\n    Format estimated time of arrival\n    \n    Args:\n        seconds: ETA in seconds\n        \n    Returns:\n        str: Formatted ETA (e.g., \"5m 30s\", \"2h 15m\")\n    \"\"\"\n    try:\n        if not seconds or seconds <= 0:\n            return \"Unknown\"\n        \n        return format_upload_time(seconds)\n        \n    except Exception as e:\n        logger.error(f\"ETA formatting error: {e}\")\n        return \"Unknown\"\n\ndef format_number(number: Union[int, float, None], abbreviate: bool = False) -> str:\n    \"\"\"\n    Format numbers with thousand separators or abbreviations\n    \n    Args:\n        number: Number to format\n        abbreviate: Whether to abbreviate large numbers\n        \n    Returns:\n        str: Formatted number\n    \"\"\"\n    try:\n        if number is None:\n            return \"0\"\n        \n        number = float(number)\n        \n        if abbreviate:\n            if number >= 1_000_000_000:\n                return f\"{number / 1_000_000_000:.1f}B\"\n            elif number >= 1_000_000:\n                return f\"{number / 1_000_000:.1f}M\"\n            elif number >= 1_000:\n                return f\"{number / 1_000:.1f}K\"\n            else:\n                return f\"{int(number)}\"\n        else:\n            return f\"{int(number):,}\"\n        \n    except Exception as e:\n        logger.error(f\"Number formatting error: {e}\")\n        return \"0\"\n\ndef truncate_text(text: str, max_length: int, suffix: str = \"...\") -> str:\n    \"\"\"\n    Truncate text to specified length with suffix\n    \n    Args:\n        text: Text to truncate\n        max_length: Maximum length\n        suffix: Suffix to add when truncating\n        \n    Returns:\n        str: Truncated text\n    \"\"\"\n    try:\n        if not text:\n            return \"\"\n        \n        if len(text) <= max_length:\n            return text\n        \n        return text[:max_length - len(suffix)] + suffix\n        \n    except Exception as e:\n        logger.error(f\"Text truncation error: {e}\")\n        return text or \"\"\n\ndef format_success_rate(successful: int, total: int) -> str:\n    \"\"\"\n    Format success rate percentage\n    \n    Args:\n        successful: Number of successful operations\n        total: Total number of operations\n        \n    Returns:\n        str: Formatted success rate with color emoji\n    \"\"\"\n    try:\n        if total == 0:\n            return \"N/A\"\n        \n        rate = (successful / total) * 100\n        \n        # Add color indicators\n        if rate >= 95:\n            emoji = \"üü¢\"\n        elif rate >= 85:\n            emoji = \"üü°\"\n        elif rate >= 70:\n            emoji = \"üü†\"\n        else:\n            emoji = \"üî¥\"\n        \n        return f\"{emoji} {rate:.1f}%\"\n        \n    except Exception as e:\n        logger.error(f\"Success rate formatting error: {e}\")\n        return \"N/A\"\n","size_bytes":17598},"utils/helpers.py":{"content":"\"\"\"\nUtility helper functions for the video downloader bot\nCommon functions used across the application\n\"\"\"\n\nimport asyncio\nimport hashlib\nimport logging\nimport os\nimport psutil\nimport re\nimport time\nimport uuid\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional, Union\nfrom pathlib import Path\nimport json\n\nlogger = logging.getLogger(__name__)\n\ndef generate_task_id() -> str:\n    \"\"\"Generate unique task ID for tracking downloads/uploads\"\"\"\n    timestamp = str(int(time.time() * 1000))\n    random_part = str(uuid.uuid4())[:8]\n    return f\"task_{timestamp}_{random_part}\"\n\ndef format_file_size(size_bytes: int, detailed: bool = False) -> str:\n    \"\"\"Format file size in human readable format with optional details\"\"\"\n    if size_bytes == 0:\n        return \"0 B\"\n    \n    size_names = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n    original_size = size_bytes\n    i = 0\n    while size_bytes >= 1024.0 and i < len(size_names) - 1:\n        size_bytes /= 1024.0\n        i += 1\n    \n    if i == 0:\n        formatted = f\"{int(size_bytes)} {size_names[i]}\"\n    else:\n        formatted = f\"{size_bytes:.1f} {size_names[i]}\"\n    \n    if detailed and i > 0:\n        # Add exact bytes in parentheses for detailed view\n        formatted += f\" ({original_size:,} bytes)\"\n    \n    return formatted\n\ndef calculate_upload_speed(current: int, total_size: int, start_time: float = None) -> float:\n    \"\"\"Calculate upload/download speed in bytes per second\"\"\"\n    if start_time is None:\n        start_time = time.time()\n    \n    elapsed_time = time.time() - start_time\n    if elapsed_time <= 0:\n        return 0\n    \n    return current / elapsed_time\n\ndef calculate_eta(current: int, total: int, speed: float) -> int:\n    \"\"\"Calculate estimated time to completion in seconds\"\"\"\n    if speed <= 0 or current >= total:\n        return 0\n    \n    remaining_bytes = total - current\n    return int(remaining_bytes / speed)\n\ndef sanitize_filename(filename: str, max_length: int = 100) -> str:\n    \"\"\"Sanitize filename for safe file system usage\"\"\"\n    # Remove/replace invalid characters\n    filename = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n    filename = re.sub(r'[\\x00-\\x1f]', '', filename)  # Remove control characters\n    \n    # Remove multiple spaces and underscores\n    filename = re.sub(r'[_\\s]+', '_', filename)\n    \n    # Trim and remove leading/trailing periods and spaces\n    filename = filename.strip('. ')\n    \n    # Truncate if too long\n    if len(filename) > max_length:\n        name, ext = os.path.splitext(filename)\n        if ext:\n            filename = name[:max_length-len(ext)] + ext\n        else:\n            filename = filename[:max_length]\n    \n    # Ensure filename is not empty\n    if not filename:\n        filename = f\"untitled_{int(time.time())}\"\n    \n    return filename\n\ndef truncate_text(text: str, max_length: int, suffix: str = \"...\") -> str:\n    \"\"\"Truncate text to specified length with suffix\"\"\"\n    if not text:\n        return \"\"\n    \n    if len(text) <= max_length:\n        return text\n    \n    return text[:max_length - len(suffix)] + suffix\n\ndef get_file_hash(file_path: str, algorithm: str = 'md5') -> str:\n    \"\"\"Get file hash for deduplication\"\"\"\n    try:\n        hash_obj = hashlib.new(algorithm)\n        \n        with open(file_path, 'rb') as f:\n            while chunk := f.read(8192):\n                hash_obj.update(chunk)\n        \n        return hash_obj.hexdigest()\n        \n    except Exception as e:\n        logger.error(f\"Failed to calculate hash for {file_path}: {e}\")\n        return \"\"\n\ndef serialize_for_cache(data: Any) -> str:\n    \"\"\"Serialize data for Redis cache storage\"\"\"\n    try:\n        if isinstance(data, (str, int, float, bool)):\n            return str(data)\n        else:\n            return json.dumps(data, default=str, ensure_ascii=False)\n    except Exception as e:\n        logger.error(f\"Failed to serialize data for cache: {e}\")\n        return str(data)\n\ndef deserialize_from_cache(data: str) -> Any:\n    \"\"\"Deserialize data from Redis cache\"\"\"\n    try:\n        # Try to parse as JSON first\n        return json.loads(data)\n    except (json.JSONDecodeError, TypeError):\n        # Return as string if JSON parsing fails\n        return data\n\ndef get_system_stats() -> Dict[str, Any]:\n    \"\"\"Get current system statistics\"\"\"\n    try:\n        # CPU usage\n        cpu_percent = psutil.cpu_percent(interval=1)\n        \n        # Memory usage\n        memory = psutil.virtual_memory()\n        memory_percent = memory.percent\n        available_memory = memory.available\n        \n        # Disk usage\n        disk = psutil.disk_usage('/')\n        disk_percent = disk.percent\n        \n        # System uptime\n        boot_time = psutil.boot_time()\n        uptime = time.time() - boot_time\n        \n        return {\n            'cpu_percent': cpu_percent,\n            'memory_percent': memory_percent,\n            'available_memory': available_memory,\n            'disk_percent': disk_percent,\n            'uptime': uptime\n        }\n        \n    except Exception as e:\n        logger.error(f\"Failed to get system stats: {e}\")\n        return {}\n\ndef create_welcome_message(first_name: str = None) -> str:\n    \"\"\"Create personalized welcome message\"\"\"\n    from static.icons import Icons\n    \n    name = first_name if first_name else \"there\"\n    \n    return f\"\"\"\n{Icons.ROBOT} <b>Welcome to Ultra Video Downloader Bot{f', {name}' if first_name else ''}!</b>\n\n{Icons.ROCKET} <b>The fastest and most powerful video downloader on Telegram!</b>\n\n{Icons.FEATURES} <b>What I can do:</b>\n‚Ä¢ {Icons.DOWNLOAD} Download from 1500+ platforms\n‚Ä¢ {Icons.SPEED} Lightning-fast processing\n‚Ä¢ {Icons.QUALITY} Multiple quality options\n‚Ä¢ {Icons.LARGE_FILE} Up to 2GB file support\n‚Ä¢ {Icons.AUDIO} Audio extraction (MP3)\n‚Ä¢ {Icons.PROGRESS} Real-time progress tracking\n\n{Icons.SIMPLE} <b>Getting Started:</b>\nJust send me any video URL and I'll handle the rest!\n\n{Icons.PLATFORMS} <b>Supported:</b> YouTube, TikTok, Instagram, Facebook, Twitter, and many more!\n\n{Icons.TIP} <b>Pro Tip:</b> Use /help to see all features and commands.\n    \"\"\"\n\ndef create_error_message(error: Exception) -> str:\n    \"\"\"Create user-friendly error message\"\"\"\n    from static.icons import Icons\n    \n    error_type = type(error).__name__\n    error_str = str(error)\n    \n    # Map common errors to user-friendly messages\n    error_messages = {\n        'ValidationError': f\"{Icons.WARNING} Invalid input. Please check your request and try again.\",\n        'FileNotFoundError': f\"{Icons.ERROR} File not found. The requested content may have been removed.\",\n        'PermissionError': f\"{Icons.LOCK} Access denied. The content may be private or restricted.\",\n        'TimeoutError': f\"{Icons.TIME} Request timed out. Please try again in a few moments.\",\n        'ConnectionError': f\"{Icons.NETWORK} Network connection issue. Please check your connection and retry.\",\n        'ValueError': f\"{Icons.WARNING} Invalid value provided. Please check your input.\",\n    }\n    \n    if error_type in error_messages:\n        return error_messages[error_type]\n    elif 'private' in error_str.lower() or 'unavailable' in error_str.lower():\n        return f\"{Icons.LOCK} This content is private or unavailable.\"\n    elif 'copyright' in error_str.lower() or 'blocked' in error_str.lower():\n        return f\"{Icons.COPYRIGHT} This content is protected by copyright.\"\n    elif 'age' in error_str.lower() or 'restricted' in error_str.lower():\n        return f\"{Icons.RESTRICTED} This content has age restrictions.\"\n    else:\n        return f\"{Icons.ERROR} An unexpected error occurred. Please try again or contact support.\"\n\ndef create_format_selection_keyboard(video_info: Dict, video_id: str):\n    \"\"\"Create inline keyboard for format selection\"\"\"\n    from telegram import InlineKeyboardButton\n    \n    keyboard = []\n    \n    # Video formats\n    formats = video_info.get('formats', [])\n    if formats:\n        for fmt in formats[:6]:  # Limit to 6 formats\n            button_text = f\"{fmt['quality']} ({fmt['ext'].upper()}) - {fmt['file_size_str']}\"\n            callback_data = f\"format_{video_id}_video_{fmt['format_id']}\"\n            keyboard.append([InlineKeyboardButton(button_text, callback_data=callback_data)])\n    \n    # Audio formats\n    audio_formats = video_info.get('audio_formats', [])\n    if audio_formats:\n        for fmt in audio_formats[:3]:  # Limit to 3 audio formats\n            button_text = f\"MP3 {fmt['quality']} - {fmt['file_size_str']}\"\n            callback_data = f\"format_{video_id}_audio_{fmt['format_id']}\"\n            keyboard.append([InlineKeyboardButton(button_text, callback_data=callback_data)])\n    \n    return keyboard\n\ndef create_download_progress_message(progress: Dict, video_info: Dict) -> str:\n    \"\"\"Create animated formatted download progress message\"\"\"\n    from static.icons import Icons\n    import time\n    \n    title = truncate_text(video_info.get('title', 'Unknown'), 45)\n    current_str = progress.get('current_str', '0 B')\n    total_str = progress.get('total_str', '0 B')\n    percentage = progress.get('percentage', 0)\n    speed_str = progress.get('speed_str', '0 B/s')\n    eta_str = progress.get('eta_str', 'Unknown')\n    progress_bar = progress.get('progress_bar', '[‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.0%')\n    status = progress.get('status', 'unknown')\n    task_id = progress.get('task_id', '')\n    \n    # Animated status icons based on current status\n    status_configs = {\n        'downloading': {\n            'icon': Icons.DOWNLOAD_ANIMATION[int(time.time()) % len(Icons.DOWNLOAD_ANIMATION)],\n            'title': 'ÿ™ÿ≠ŸÖŸäŸÑ ÿ¨ÿßÿ±Ÿä',\n            'color': 'üü¶'\n        },\n        'uploading': {\n            'icon': Icons.UPLOAD_ANIMATION[int(time.time()) % len(Icons.UPLOAD_ANIMATION)],\n            'title': 'ÿ±ŸÅÿπ ÿ¨ÿßÿ±Ÿä',\n            'color': 'üü®'\n        },\n        'completed': {\n            'icon': Icons.PARTY,\n            'title': 'ÿ™ŸÖ ÿ®ŸÜÿ¨ÿßÿ≠!',\n            'color': 'üü©'\n        },\n        'failed': {\n            'icon': Icons.ERROR,\n            'title': 'ŸÅÿ¥ŸÑ',\n            'color': 'üü•'\n        },\n        'cancelled': {\n            'icon': Icons.STOP,\n            'title': 'ŸÖŸÑÿ∫Ÿä',\n            'color': '‚¨ú'\n        }\n    }\n    \n    config = status_configs.get(status, {\n        'icon': Icons.PROGRESS,\n        'title': status.title(),\n        'color': '‚¨ú'\n    })\n    \n    # Add motivational messages for different percentages\n    motivational = \"\"\n    if status == 'downloading' and percentage > 0:\n        if percentage < 25:\n            motivational = f\"{Icons.ROCKET} ÿßŸÑÿ®ÿØÿßŸäÿ© ÿØÿßÿ¶ŸÖÿßŸã ÿµÿπÿ®ÿ©!\"\n        elif percentage < 50:\n            motivational = f\"{Icons.MUSCLE} ŸÜÿµŸÅ ÿßŸÑÿ∑ÿ±ŸäŸÇ! ÿßÿ≥ÿ™ŸÖÿ±!\"\n        elif percentage < 75:\n            motivational = f\"{Icons.FIRE} ÿßŸÑÿ£ŸÖŸàÿ± ÿ™ÿ≥Ÿäÿ± ÿ®ÿ¥ŸÉŸÑ ÿ±ÿßÿ¶ÿπ!\"\n        elif percentage < 95:\n            motivational = f\"{Icons.LIGHTNING} ÿ™ŸÇÿ±Ÿäÿ®ÿßŸã ÿßŸÜÿ™ŸáŸäŸÜÿß!\"\n        else:\n            motivational = f\"{Icons.MAGIC} ÿßŸÑŸÑŸÖÿ≥ÿ© ÿßŸÑÿ£ÿÆŸäÿ±ÿ©...\"\n    \n    return f\"\"\"\n{config['color']} <b>{config['icon']} {config['title']}</b>\n\n{Icons.VIDEO} <b>ÿßŸÑÿπŸÜŸàÿßŸÜ:</b> {title}\n{Icons.MAGIC} <b>ÿßŸÑÿ™ŸÇÿØŸÖ:</b> {current_str} / {total_str}\n\n{progress_bar}\n\n{Icons.TURBO} <b>ÿßŸÑÿ≥ÿ±ÿπÿ©:</b> {speed_str}\n{Icons.CLOCK} <b>ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ™ÿ®ŸÇŸä:</b> {eta_str}\n\n{motivational}\n    \"\"\"\n\ndef setup_logging():\n    \"\"\"Setup logging configuration\"\"\"\n    from config.settings import settings\n    \n    # Create logs directory\n    os.makedirs(os.path.dirname(settings.LOG_FILE), exist_ok=True)\n    \n    # Configure logging\n    logging.basicConfig(\n        level=getattr(logging, settings.LOG_LEVEL.upper()),\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler(settings.LOG_FILE, encoding='utf-8'),\n            logging.StreamHandler()\n        ]\n    )\n    \n    # Set specific log levels for noisy modules\n    logging.getLogger('asyncio').setLevel(logging.WARNING)\n    logging.getLogger('telegram').setLevel(logging.WARNING)\n    logging.getLogger('httpx').setLevel(logging.WARNING)\n\nasync def cleanup_temp_files():\n    \"\"\"Clean up temporary files on startup\"\"\"\n    try:\n        from config.settings import settings\n        \n        temp_dir = Path(settings.TEMP_DIR)\n        if temp_dir.exists():\n            current_time = time.time()\n            max_age = settings.MAX_TEMP_AGE\n            \n            cleaned_count = 0\n            for file_path in temp_dir.rglob('*'):\n                if file_path.is_file():\n                    try:\n                        file_age = current_time - file_path.stat().st_ctime\n                        if file_age > max_age:\n                            file_path.unlink()\n                            cleaned_count += 1\n                    except Exception as e:\n                        logger.warning(f\"Failed to clean up file {file_path}: {e}\")\n            \n            if cleaned_count > 0:\n                logger.info(f\"üóëÔ∏è Cleaned up {cleaned_count} temporary files\")\n    \n    except Exception as e:\n        logger.error(f\"Failed to cleanup temp files: {e}\")\n\ndef validate_environment():\n    \"\"\"Validate required environment variables\"\"\"\n    from config.settings import settings\n    \n    required_vars = [\n        'BOT_TOKEN', 'API_ID', 'API_HASH', 'ALLOWED_CHAT_IDS', 'UPLOAD_CHAT_ID'\n    ]\n    \n    missing_vars = []\n    for var in required_vars:\n        if not getattr(settings, var, None):\n            missing_vars.append(var)\n    \n    if missing_vars:\n        logger.error(f\"‚ùå Missing required environment variables: {', '.join(missing_vars)}\")\n        return False\n    \n    return True\n\ndef format_bytes_per_second(bytes_per_sec: float) -> str:\n    \"\"\"Format speed in human readable format\"\"\"\n    return f\"{format_file_size(int(bytes_per_sec))}/s\"\n\ndef is_url_safe(url: str) -> bool:\n    \"\"\"Check if URL is safe to process\"\"\"\n    if not url:\n        return False\n    \n    # Check for malicious patterns\n    malicious_patterns = [\n        r'javascript:',\n        r'data:',\n        r'vbscript:',\n        r'file://',\n        r'ftp://',\n    ]\n    \n    url_lower = url.lower()\n    for pattern in malicious_patterns:\n        if re.search(pattern, url_lower):\n            return False\n    \n    return True\n\ndef get_platform_emoji(platform: str) -> str:\n    \"\"\"Get emoji for platform\"\"\"\n    platform_emojis = {\n        'youtube': 'üî¥',\n        'tiktok': '‚ö´',\n        'instagram': 'üì∏',\n        'facebook': 'üîµ',\n        'twitter': 'üê¶',\n        'x': '‚ùå',\n        'dailymotion': 'üü†',\n        'vimeo': 'üîµ',\n        'twitch': 'üü£'\n    }\n    \n    return platform_emojis.get(platform.lower(), 'üé¨')\n\nasync def run_with_timeout(coro, timeout: float):\n    \"\"\"Run coroutine with timeout\"\"\"\n    try:\n        return await asyncio.wait_for(coro, timeout=timeout)\n    except asyncio.TimeoutError:\n        raise TimeoutError(f\"Operation timed out after {timeout} seconds\")\n\ndef chunks(lst: List, n: int):\n    \"\"\"Yield successive n-sized chunks from list\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n\ndef safe_int(value: Any, default: int = 0) -> int:\n    \"\"\"Safely convert value to integer\"\"\"\n    try:\n        if value is None:\n            return default\n        return int(float(value))\n    except (ValueError, TypeError):\n        return default\n\ndef safe_float(value: Any, default: float = 0.0) -> float:\n    \"\"\"Safely convert value to float\"\"\"\n    try:\n        if value is None:\n            return default\n        return float(value)\n    except (ValueError, TypeError):\n        return default\n\ndef create_progress_bar(percentage: float, length: int = 20, filled: str = '‚ñà', empty: str = '‚ñë', animated: bool = True) -> str:\n    \"\"\"Create animated visual progress bar\"\"\"\n    from static.icons import Icons\n    import time\n    \n    filled_length = int(length * percentage / 100)\n    \n    if animated and percentage < 100:\n        # Add animation to the progress edge\n        spinner_frame = Icons.SPINNER_FRAMES[int(time.time() * 3) % len(Icons.SPINNER_FRAMES)]\n        if filled_length > 0:\n            bar = filled * (filled_length - 1) + spinner_frame + empty * (length - filled_length)\n        else:\n            bar = spinner_frame + empty * (length - 1)\n    else:\n        bar = filled * filled_length + empty * (length - filled_length)\n    \n    # Add percentage with special formatting\n    if percentage >= 100:\n        return f\"[{bar}] {Icons.SUCCESS} 100%\"\n    else:\n        return f\"[{bar}] {percentage:.1f}%\"\n\ndef get_mime_type(file_path: str) -> str:\n    \"\"\"Get MIME type of file\"\"\"\n    import mimetypes\n    mime_type, _ = mimetypes.guess_type(file_path)\n    return mime_type or 'application/octet-stream'\n\ndef is_video_file(file_path: str) -> bool:\n    \"\"\"Check if file is a video\"\"\"\n    video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.webm', '.flv', '.wmv', '.m4v'}\n    return Path(file_path).suffix.lower() in video_extensions\n\ndef is_audio_file(file_path: str) -> bool:\n    \"\"\"Check if file is audio\"\"\"\n    audio_extensions = {'.mp3', '.wav', '.aac', '.ogg', '.m4a', '.flac', '.wma'}\n    return Path(file_path).suffix.lower() in audio_extensions\n\ndef get_file_extension(url: str) -> str:\n    \"\"\"Extract file extension from URL\"\"\"\n    try:\n        from urllib.parse import urlparse\n        path = urlparse(url).path\n        return Path(path).suffix.lower()\n    except:\n        return ''\n\nclass RateLimiter:\n    \"\"\"Simple rate limiter for API calls\"\"\"\n    \n    def __init__(self, max_calls: int, time_window: int):\n        self.max_calls = max_calls\n        self.time_window = time_window\n        self.calls = []\n    \n    async def acquire(self) -> bool:\n        \"\"\"Check if call is allowed\"\"\"\n        now = time.time()\n        \n        # Remove old calls outside time window\n        self.calls = [call_time for call_time in self.calls if now - call_time < self.time_window]\n        \n        # Check if we can make another call\n        if len(self.calls) < self.max_calls:\n            self.calls.append(now)\n            return True\n        \n        return False\n    \n    def time_until_reset(self) -> float:\n        \"\"\"Get time until rate limit resets\"\"\"\n        if not self.calls:\n            return 0\n        \n        oldest_call = min(self.calls)\n        return max(0, self.time_window - (time.time() - oldest_call))\n","size_bytes":18347},"utils/validators.py":{"content":"\"\"\"\nURL validation and platform detection utilities\nValidates URLs and identifies supported video platforms\n\"\"\"\n\nimport re\nimport logging\nfrom typing import Optional, List, Dict, Any\nfrom urllib.parse import urlparse, parse_qs\nfrom dataclasses import dataclass\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass PlatformInfo:\n    \"\"\"Platform information data class\"\"\"\n    name: str\n    display_name: str\n    base_domains: List[str]\n    url_patterns: List[str]\n    supports_playlists: bool = False\n    requires_cookies: bool = False\n\n# Comprehensive platform definitions\nSUPPORTED_PLATFORMS = {\n    'youtube': PlatformInfo(\n        name='youtube',\n        display_name='YouTube',\n        base_domains=['youtube.com', 'youtu.be', 'm.youtube.com', 'www.youtube.com'],\n        url_patterns=[\n            r'(?:youtube\\.com/watch\\?v=|youtu\\.be/|youtube\\.com/embed/|youtube\\.com/v/)([a-zA-Z0-9_-]{11})',\n            r'youtube\\.com/playlist\\?list=([a-zA-Z0-9_-]+)',\n            r'youtube\\.com/channel/([a-zA-Z0-9_-]+)',\n            r'youtube\\.com/user/([a-zA-Z0-9_-]+)',\n            r'youtube\\.com/@([a-zA-Z0-9_.-]+)'\n        ],\n        supports_playlists=True\n    ),\n    'tiktok': PlatformInfo(\n        name='tiktok',\n        display_name='TikTok',\n        base_domains=['tiktok.com', 'www.tiktok.com', 'm.tiktok.com', 'vm.tiktok.com'],\n        url_patterns=[\n            r'tiktok\\.com/@([^/]+)/video/(\\d+)',\n            r'tiktok\\.com/t/([a-zA-Z0-9]+)',\n            r'vm\\.tiktok\\.com/([a-zA-Z0-9]+)',\n            r'tiktok\\.com/@([^/]+)'\n        ]\n    ),\n    'instagram': PlatformInfo(\n        name='instagram',\n        display_name='Instagram',\n        base_domains=['instagram.com', 'www.instagram.com', 'm.instagram.com'],\n        url_patterns=[\n            r'instagram\\.com/p/([a-zA-Z0-9_-]+)(?:\\?.*)?',\n            r'instagram\\.com/reel/([a-zA-Z0-9_-]+)(?:\\?.*)?',\n            r'instagram\\.com/tv/([a-zA-Z0-9_-]+)(?:\\?.*)?',\n            r'instagram\\.com/stories/([^/]+)/(\\d+)(?:\\?.*)?',\n            r'instagram\\.com/([^/]+)/?(?:\\?.*)?'\n        ]\n    ),\n    'facebook': PlatformInfo(\n        name='facebook',\n        display_name='Facebook',\n        base_domains=['facebook.com', 'www.facebook.com', 'm.facebook.com', 'fb.watch'],\n        url_patterns=[\n            r'facebook\\.com/watch/?\\?v=(\\d+)',\n            r'facebook\\.com/([^/]+)/videos/(\\d+)',\n            r'facebook\\.com/video\\.php\\?v=(\\d+)',\n            r'fb\\.watch/([a-zA-Z0-9_-]+)',\n            r'facebook\\.com/reel/(\\d+)(?:\\?.*)?',\n            r'facebook\\.com/share/r/([a-zA-Z0-9_-]+)/?(?:\\?.*)?',\n            r'facebook\\.com/share/v/([a-zA-Z0-9_-]+)/?(?:\\?.*)?'\n        ]\n    ),\n    'twitter': PlatformInfo(\n        name='twitter',\n        display_name='Twitter/X',\n        base_domains=['twitter.com', 'www.twitter.com', 'm.twitter.com', 'x.com', 'www.x.com'],\n        url_patterns=[\n            r'(?:twitter\\.com|x\\.com)/([^/]+)/status/(\\d+)',\n            r'(?:twitter\\.com|x\\.com)/i/web/status/(\\d+)',\n            r'(?:twitter\\.com|x\\.com)/([^/]+)/moments/(\\d+)'\n        ]\n    ),\n    'dailymotion': PlatformInfo(\n        name='dailymotion',\n        display_name='Dailymotion',\n        base_domains=['dailymotion.com', 'www.dailymotion.com', 'dai.ly'],\n        url_patterns=[\n            r'dailymotion\\.com/video/([a-zA-Z0-9]+)',\n            r'dai\\.ly/([a-zA-Z0-9]+)',\n            r'dailymotion\\.com/playlist/([a-zA-Z0-9]+)'\n        ],\n        supports_playlists=True\n    ),\n    'vimeo': PlatformInfo(\n        name='vimeo',\n        display_name='Vimeo',\n        base_domains=['vimeo.com', 'www.vimeo.com', 'player.vimeo.com'],\n        url_patterns=[\n            r'vimeo\\.com/(\\d+)',\n            r'vimeo\\.com/channels/([^/]+)/(\\d+)',\n            r'player\\.vimeo\\.com/video/(\\d+)'\n        ]\n    ),\n    'twitch': PlatformInfo(\n        name='twitch',\n        display_name='Twitch',\n        base_domains=['twitch.tv', 'www.twitch.tv', 'm.twitch.tv', 'clips.twitch.tv'],\n        url_patterns=[\n            r'twitch\\.tv/videos/(\\d+)',\n            r'twitch\\.tv/([^/]+)/clip/([a-zA-Z0-9_-]+)',\n            r'clips\\.twitch\\.tv/([a-zA-Z0-9_-]+)',\n            r'twitch\\.tv/([^/]+)'\n        ]\n    ),\n    'reddit': PlatformInfo(\n        name='reddit',\n        display_name='Reddit',\n        base_domains=['reddit.com', 'www.reddit.com', 'm.reddit.com', 'v.redd.it'],\n        url_patterns=[\n            r'reddit\\.com/r/([^/]+)/comments/([a-zA-Z0-9]+)',\n            r'v\\.redd\\.it/([a-zA-Z0-9]+)',\n            r'reddit\\.com/user/([^/]+)/comments/([a-zA-Z0-9]+)'\n        ]\n    ),\n    'streamable': PlatformInfo(\n        name='streamable',\n        display_name='Streamable',\n        base_domains=['streamable.com', 'www.streamable.com'],\n        url_patterns=[\n            r'streamable\\.com/([a-zA-Z0-9]+)'\n        ]\n    )\n}\n\ndef is_valid_url(url: str) -> bool:\n    \"\"\"\n    Validate if the provided string is a valid URL\n    \n    Args:\n        url: URL string to validate\n        \n    Returns:\n        bool: True if valid URL, False otherwise\n    \"\"\"\n    try:\n        if not url or not isinstance(url, str):\n            return False\n        \n        # Basic URL structure validation\n        if not url.startswith(('http://', 'https://')):\n            # Try adding https prefix\n            url = 'https://' + url.lstrip('/')\n        \n        # Parse URL\n        parsed = urlparse(url)\n        \n        # Check required components\n        if not parsed.netloc:\n            return False\n        \n        # Check for valid domain structure\n        domain_pattern = r'^[a-zA-Z0-9][a-zA-Z0-9-_.]*[a-zA-Z0-9]$'\n        if not re.match(domain_pattern, parsed.netloc.replace('www.', '')):\n            return False\n        \n        # Check for dangerous schemes\n        dangerous_schemes = ['javascript', 'data', 'vbscript', 'file']\n        if parsed.scheme.lower() in dangerous_schemes:\n            return False\n        \n        return True\n        \n    except Exception as e:\n        logger.debug(f\"URL validation error for '{url}': {e}\")\n        return False\n\ndef get_platform_from_url(url: str) -> Optional[str]:\n    \"\"\"\n    Identify the platform from a video URL\n    \n    Args:\n        url: Video URL to analyze\n        \n    Returns:\n        str or None: Platform name if recognized, None otherwise\n    \"\"\"\n    try:\n        if not is_valid_url(url):\n            return None\n        \n        # Parse URL\n        parsed = urlparse(url.lower())\n        domain = parsed.netloc\n        \n        # Remove common prefixes properly\n        if domain.startswith('www.'):\n            domain = domain[4:]\n        elif domain.startswith('m.'):\n            domain = domain[2:]\n        \n        # Check each platform\n        for platform_name, platform_info in SUPPORTED_PLATFORMS.items():\n            # Check domain match\n            for base_domain in platform_info.base_domains:\n                if domain == base_domain or domain.endswith('.' + base_domain):\n                    # Verify with URL patterns\n                    for pattern in platform_info.url_patterns:\n                        if re.search(pattern, url, re.IGNORECASE):\n                            return platform_name\n                    \n                    # If domain matches but no specific pattern, still return platform\n                    return platform_name\n        \n        return None\n        \n    except Exception as e:\n        logger.error(f\"Platform detection error for '{url}': {e}\")\n        return None\n\ndef get_platform_info(platform_name: str) -> Optional[PlatformInfo]:\n    \"\"\"\n    Get detailed information about a platform\n    \n    Args:\n        platform_name: Name of the platform\n        \n    Returns:\n        PlatformInfo or None: Platform information if found\n    \"\"\"\n    return SUPPORTED_PLATFORMS.get(platform_name.lower())\n\ndef extract_video_id(url: str, platform: str) -> Optional[str]:\n    \"\"\"\n    Extract video ID from URL for a specific platform\n    \n    Args:\n        url: Video URL\n        platform: Platform name\n        \n    Returns:\n        str or None: Video ID if found\n    \"\"\"\n    try:\n        platform_info = get_platform_info(platform)\n        if not platform_info:\n            return None\n        \n        for pattern in platform_info.url_patterns:\n            match = re.search(pattern, url, re.IGNORECASE)\n            if match:\n                # Return the first captured group (video ID)\n                return match.group(1) if match.groups() else None\n        \n        return None\n        \n    except Exception as e:\n        logger.error(f\"Video ID extraction error for '{url}': {e}\")\n        return None\n\ndef normalize_url(url: str) -> str:\n    \"\"\"\n    Normalize URL for consistent processing\n    \n    Args:\n        url: URL to normalize\n        \n    Returns:\n        str: Normalized URL\n    \"\"\"\n    try:\n        if not url:\n            return url\n        \n        # Add protocol if missing\n        if not url.startswith(('http://', 'https://')):\n            url = 'https://' + url.lstrip('/')\n        \n        # Parse and reconstruct\n        parsed = urlparse(url)\n        \n        # Normalize domain\n        domain = parsed.netloc.lower()\n        \n        # Remove unnecessary www prefix for some platforms\n        if domain.startswith('www.'):\n            domain = domain[4:]\n        \n        # Reconstruct URL\n        normalized = f\"{parsed.scheme}://{domain}{parsed.path}\"\n        \n        if parsed.query:\n            normalized += f\"?{parsed.query}\"\n        \n        if parsed.fragment:\n            normalized += f\"#{parsed.fragment}\"\n        \n        return normalized\n        \n    except Exception as e:\n        logger.error(f\"URL normalization error for '{url}': {e}\")\n        return url\n\ndef is_playlist_url(url: str, platform: str) -> bool:\n    \"\"\"\n    Check if URL is a playlist URL\n    \n    Args:\n        url: URL to check\n        platform: Platform name\n        \n    Returns:\n        bool: True if playlist URL\n    \"\"\"\n    try:\n        platform_info = get_platform_info(platform)\n        if not platform_info or not platform_info.supports_playlists:\n            return False\n        \n        # Platform-specific playlist detection\n        if platform == 'youtube':\n            return 'list=' in url or '/playlist' in url\n        elif platform == 'dailymotion':\n            return '/playlist/' in url\n        \n        return False\n        \n    except Exception as e:\n        logger.error(f\"Playlist detection error for '{url}': {e}\")\n        return False\n\ndef validate_platform_support(platform: str) -> bool:\n    \"\"\"\n    Check if platform is supported\n    \n    Args:\n        platform: Platform name to check\n        \n    Returns:\n        bool: True if supported\n    \"\"\"\n    return platform.lower() in SUPPORTED_PLATFORMS\n\ndef get_supported_platforms() -> List[Dict[str, Any]]:\n    \"\"\"\n    Get list of all supported platforms with their information\n    \n    Returns:\n        List of platform dictionaries\n    \"\"\"\n    return [\n        {\n            'name': info.name,\n            'display_name': info.display_name,\n            'base_domains': info.base_domains,\n            'supports_playlists': info.supports_playlists,\n            'requires_cookies': info.requires_cookies\n        }\n        for info in SUPPORTED_PLATFORMS.values()\n    ]\n\ndef extract_url_from_text(text: str) -> Optional[str]:\n    \"\"\"\n    Extract URL from text message\n    \n    Args:\n        text: Text that may contain URL\n        \n    Returns:\n        str or None: Extracted URL if found\n    \"\"\"\n    try:\n        # URL regex pattern\n        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n        \n        matches = re.findall(url_pattern, text)\n        if matches:\n            return matches[0]  # Return first URL found\n        \n        # Try to detect URLs without protocol\n        domain_pattern = r'(?:www\\.)?[a-zA-Z0-9][a-zA-Z0-9-]*[a-zA-Z0-9]*\\.(?:com|org|net|edu|gov|mil|int|co|io|ly|be|me|tv)'\n        \n        matches = re.findall(domain_pattern, text)\n        if matches:\n            url = matches[0]\n            if not url.startswith(('http://', 'https://')):\n                url = 'https://' + url\n            return url\n        \n        return None\n        \n    except Exception as e:\n        logger.error(f\"URL extraction error from text: {e}\")\n        return None\n\ndef validate_file_size_limit(file_size: int, max_size: int = 2 * 1024 * 1024 * 1024) -> bool:\n    \"\"\"\n    Validate if file size is within limits\n    \n    Args:\n        file_size: File size in bytes\n        max_size: Maximum allowed size in bytes (default 2GB)\n        \n    Returns:\n        bool: True if within limits\n    \"\"\"\n    return 0 < file_size <= max_size\n\ndef is_live_stream_url(url: str, platform: str) -> bool:\n    \"\"\"\n    Check if URL is for a live stream\n    \n    Args:\n        url: URL to check\n        platform: Platform name\n        \n    Returns:\n        bool: True if live stream URL\n    \"\"\"\n    try:\n        # Platform-specific live stream detection\n        if platform == 'youtube':\n            return '/watch' in url and 'live' in url.lower()\n        elif platform == 'twitch':\n            # Twitch channel URLs (not clips/videos) are typically live\n            return re.search(r'twitch\\.tv/([^/]+)/?$', url) is not None\n        elif platform == 'facebook':\n            return 'live' in url.lower()\n        \n        return False\n        \n    except Exception as e:\n        logger.error(f\"Live stream detection error for '{url}': {e}\")\n        return False\n\ndef sanitize_url(url: str) -> str:\n    \"\"\"\n    Sanitize URL for safe processing\n    \n    Args:\n        url: URL to sanitize\n        \n    Returns:\n        str: Sanitized URL\n    \"\"\"\n    try:\n        if not url:\n            return \"\"\n        \n        # Remove dangerous characters\n        dangerous_chars = ['<', '>', '\"', \"'\", '`', '\\n', '\\r', '\\t']\n        for char in dangerous_chars:\n            url = url.replace(char, '')\n        \n        # Limit length\n        if len(url) > 2048:  # Standard URL length limit\n            url = url[:2048]\n        \n        return url.strip()\n        \n    except Exception as e:\n        logger.error(f\"URL sanitization error: {e}\")\n        return \"\"\n\ndef get_platform_limitations(platform: str) -> Dict[str, Any]:\n    \"\"\"\n    Get platform-specific limitations and capabilities\n    \n    Args:\n        platform: Platform name\n        \n    Returns:\n        dict: Platform limitations and capabilities\n    \"\"\"\n    limitations = {\n        'youtube': {\n            'max_quality': '4K',\n            'audio_extraction': True,\n            'playlist_support': True,\n            'live_stream_support': False,\n            'age_restricted_content': False,\n            'private_content': False\n        },\n        'tiktok': {\n            'max_quality': '1080p',\n            'audio_extraction': True,\n            'playlist_support': False,\n            'live_stream_support': False,\n            'age_restricted_content': True,\n            'private_content': False\n        },\n        'instagram': {\n            'max_quality': '1080p',\n            'audio_extraction': True,\n            'playlist_support': False,\n            'live_stream_support': False,\n            'age_restricted_content': False,\n            'private_content': True\n        },\n        'facebook': {\n            'max_quality': '1080p',\n            'audio_extraction': True,\n            'playlist_support': False,\n            'live_stream_support': False,\n            'age_restricted_content': False,\n            'private_content': True\n        },\n        'twitter': {\n            'max_quality': '1080p',\n            'audio_extraction': True,\n            'playlist_support': False,\n            'live_stream_support': False,\n            'age_restricted_content': False,\n            'private_content': True\n        }\n    }\n    \n    return limitations.get(platform, {\n        'max_quality': '1080p',\n        'audio_extraction': True,\n        'playlist_support': False,\n        'live_stream_support': False,\n        'age_restricted_content': False,\n        'private_content': False\n    })\n","size_bytes":16010},"setup.sh":{"content":"#!/bin/bash\n\n# =================================\n# Ultra High-Performance Video Downloader Bot\n# Setup Script\n# =================================\n\nset -e\n\necho \"üöÄ Setting up Ultra High-Performance Video Downloader Bot...\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Function to print colored output\nprint_status() {\n    echo -e \"${BLUE}[INFO]${NC} $1\"\n}\n\nprint_success() {\n    echo -e \"${GREEN}[SUCCESS]${NC} $1\"\n}\n\nprint_warning() {\n    echo -e \"${YELLOW}[WARNING]${NC} $1\"\n}\n\nprint_error() {\n    echo -e \"${RED}[ERROR]${NC} $1\"\n}\n\n# Check if Docker is installed\nif ! command -v docker &> /dev/null; then\n    print_error \"Docker is not installed. Please install Docker first.\"\n    exit 1\nfi\n\n# Check if Docker Compose is installed\nif ! command -v docker-compose &> /dev/null; then\n    print_error \"Docker Compose is not installed. Please install Docker Compose first.\"\n    exit 1\nfi\n\n# Create .env file if it doesn't exist\nif [ ! -f .env ]; then\n    print_status \"Creating .env file from template...\"\n    cp .env.example .env\n    print_warning \"Please edit .env file with your actual configuration values\"\nelse\n    print_success \".env file already exists\"\nfi\n\n# Create necessary directories\nprint_status \"Creating necessary directories...\"\nmkdir -p temp logs downloads\n\n# Set proper permissions\nprint_status \"Setting up permissions...\"\nchmod +x setup.sh\nchmod 755 temp logs downloads\n\n# Build and start the services\nprint_status \"Building Docker images...\"\ndocker-compose build\n\nprint_status \"Starting services...\"\ndocker-compose up -d\n\n# Wait for services to be ready\nprint_status \"Waiting for services to be ready...\"\nsleep 10\n\n# Check if services are running\nif docker-compose ps | grep -q \"Up\"; then\n    print_success \"Services are running successfully!\"\n    \n    echo \"\"\n    echo \"üéâ Setup completed successfully!\"\n    echo \"\"\n    echo \"üìã Next steps:\"\n    echo \"1. Edit .env file with your bot token and configuration\"\n    echo \"2. Run: docker-compose restart video_bot\"\n    echo \"3. Check logs: docker-compose logs -f video_bot\"\n    echo \"\"\n    echo \"üåê Management interfaces:\"\n    echo \"- pgAdmin: http://localhost:8080\"\n    echo \"- Redis Commander: http://localhost:8081\"\n    echo \"\"\n    echo \"üìä To view logs:\"\n    echo \"docker-compose logs -f video_bot\"\n    echo \"\"\n    echo \"üõë To stop services:\"\n    echo \"docker-compose down\"\n    \nelse\n    print_error \"Some services failed to start. Check the logs:\"\n    print_error \"docker-compose logs\"\nfi","size_bytes":2547},"docs/ux_improvements.md":{"content":"# üöÄ 20 ŸÖŸäÿ≤ÿ© ŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ - Ultra Video Downloader Bot\n\n## üéØ **ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ™ŸÅÿßÿπŸÑ ŸàÿßŸÑŸàÿßÿ¨Ÿáÿ©**\n\n### 1. **üé¨ ŸÖÿπÿßŸäŸÜÿ© ÿßŸÑŸÅŸäÿØŸäŸà ÿßŸÑÿ∞ŸÉŸäÿ©**\n- ÿπÿ±ÿ∂ ŸÖÿπÿßŸäŸÜÿ© ÿ™ŸÑŸÇÿßÿ¶Ÿäÿ© ŸÖÿπ ÿµŸàÿ±ÿ© ŸÖÿµÿ∫ÿ±ÿ©\n- ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÅŸäÿØŸäŸà (ÿßŸÑÿπŸÜŸàÿßŸÜÿå ÿßŸÑŸÖÿØÿ©ÿå ÿßŸÑÿ≠ÿ¨ŸÖ) ŸÇÿ®ŸÑ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ\n- ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑÿ¨ŸàÿØÿ© ŸàÿßŸÑÿµŸäÿ∫ÿ© ÿ®ÿµŸàÿ±ÿ© ÿ™ŸÅÿßÿπŸÑŸäÿ©\n\n### 2. **üìä ÿ¥ÿ±Ÿäÿ∑ ÿ™ŸÇÿØŸÖ ŸÖÿ™ÿ≠ÿ±ŸÉ**\n- ÿ£ŸÜŸäŸÖŸäÿ¥ŸÜ ŸÖŸÑŸàŸÜ ŸÖÿ™ÿØÿ±ÿ¨ ÿ£ÿ´ŸÜÿßÿ° ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ\n- ÿ±ŸÖŸàÿ≤ ÿ™ÿπÿ®Ÿäÿ±Ÿäÿ© ŸÖÿ™ÿ≠ÿ±ŸÉÿ© (üî•‚ö°üí´‚ú®)\n- ÿπÿ±ÿ∂ ÿßŸÑÿ≥ÿ±ÿπÿ© ŸàÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ™ÿ®ŸÇŸä ÿ®ÿØŸÇÿ©\n\n### 3. **üí¨ ÿ±ÿ≥ÿßÿ¶ŸÑ ÿ™ŸÅÿßÿπŸÑŸäÿ© ÿ∞ŸÉŸäÿ©**\n- ÿ™ÿ±ÿ≠Ÿäÿ® ÿ¥ÿÆÿµŸä ÿ®ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ\n- ÿ±ÿ≥ÿßÿ¶ŸÑ ŸÜÿ¨ÿßÿ≠ ŸÖÿπ ÿßÿ≠ÿ™ŸÅÿßŸÑÿßÿ™ ÿ±ŸÇŸÖŸäÿ© üéâ\n- ÿ±ÿ≥ÿßÿ¶ŸÑ ÿÆÿ∑ÿ£ ŸÖŸÅŸäÿØÿ© ŸÖÿπ ÿßŸÇÿ™ÿ±ÿßÿ≠ÿßÿ™ ÿ≠ŸÑŸàŸÑ\n\n### 4. **üé≠ ŸÜÿ∏ÿßŸÖ ÿßŸÑÿ£ŸäŸÇŸàŸÜÿßÿ™ ÿßŸÑÿ™ŸÅÿßÿπŸÑŸäÿ©**\n- ÿ£ŸäŸÇŸàŸÜÿßÿ™ ŸÖÿ™ÿ≠ÿ±ŸÉÿ© ÿ≠ÿ≥ÿ® ÿßŸÑŸÖŸÜÿµÿ©\n- ÿ™ÿ£ÿ´Ÿäÿ±ÿßÿ™ ÿ®ÿµÿ±Ÿäÿ© ŸÑŸÑÿ≠ÿßŸÑÿßÿ™ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©\n- ÿ±ŸÖŸàÿ≤ ÿ™ÿπÿ®Ÿäÿ±Ÿäÿ© ÿ™ÿ™ÿ∫Ÿäÿ± ÿ≠ÿ≥ÿ® ÿßŸÑÿ≥ŸäÿßŸÇ\n\n## üîß **ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ£ÿØÿßÿ° ŸàÿßŸÑŸÉŸÅÿßÿ°ÿ©**\n\n### 5. **‚ö° ÿ™ÿ≠ŸÖŸäŸÑ ŸÖÿ™ÿπÿØÿØ ÿßŸÑŸÖÿ≥ÿßÿ±ÿßÿ™**\n- ÿ™ÿ≠ŸÖŸäŸÑ ÿπÿØÿ© ŸÅŸäÿØŸäŸàŸáÿßÿ™ ÿ®ÿßŸÑÿ™Ÿàÿßÿ≤Ÿä\n- ŸÇÿßÿ¶ŸÖÿ© ÿßŸÜÿ™ÿ∏ÿßÿ± ÿ∞ŸÉŸäÿ© ŸÑŸÑÿ™ÿ≠ŸÖŸäŸÑÿßÿ™\n- ÿ£ŸàŸÑŸàŸäÿ© ŸÑŸÑÿ™ÿ≠ŸÖŸäŸÑÿßÿ™ ÿ≠ÿ≥ÿ® ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸÑŸÅ\n\n### 6. **üß† ÿ∞ÿßŸÉÿ±ÿ© ÿ™ÿÆÿ≤ŸäŸÜ ÿ∞ŸÉŸäÿ©**\n- ÿ≠ŸÅÿ∏ ÿ™ŸÅÿ∂ŸäŸÑÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÑŸÑÿ¨ŸàÿØÿ©\n- ÿ™ÿÆÿ≤ŸäŸÜ ŸÖÿ§ŸÇÿ™ ŸÑŸÑŸÅŸäÿØŸäŸàŸáÿßÿ™ ÿßŸÑŸÖŸÉÿ±ÿ±ÿ©\n- ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿ®ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© ÿßŸÑÿ≥ÿ±Ÿäÿπÿ©\n\n### 7. **üì± ÿ™ÿ≠ÿ≥ŸäŸÜ ŸÑŸÑŸáŸàÿßÿ™ŸÅ ÿßŸÑŸÖÿ≠ŸÖŸàŸÑÿ©**\n- ÿ∂ÿ∫ÿ∑ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑŸÑŸÅŸäÿØŸäŸàŸáÿßÿ™ ÿßŸÑŸÉÿ®Ÿäÿ±ÿ©\n- ÿÆŸäÿßÿ±ÿßÿ™ ÿ¨ŸàÿØÿ© ŸÖÿ≠ÿ≥ŸÜÿ© ŸÑŸÑÿßÿ™ÿµÿßŸÑ ÿßŸÑÿ®ÿ∑Ÿäÿ°\n- ÿπÿ±ÿ∂ ŸÖÿ≠ÿ≥ŸÜ ŸÑŸÑÿ¥ÿßÿ¥ÿßÿ™ ÿßŸÑÿµÿ∫Ÿäÿ±ÿ©\n\n### 8. **üîÑ ÿßÿ≥ÿ™ÿ¶ŸÜÿßŸÅ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ**\n- ŸÖÿ™ÿßÿ®ÿπÿ© ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ ÿπŸÜÿØ ÿßŸÜŸÇÿ∑ÿßÿπ ÿßŸÑÿßÿ™ÿµÿßŸÑ\n- ÿ≠ŸÅÿ∏ ÿ™ŸÇÿØŸÖ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã\n- ÿ•ÿπÿßÿØÿ© ŸÖÿ≠ÿßŸàŸÑÿ© ÿ∞ŸÉŸäÿ© ÿπŸÜÿØ ÿßŸÑŸÅÿ¥ŸÑ\n\n## üéÆ **ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ™ÿ≠ŸÉŸÖ ÿßŸÑŸÖÿ™ŸÇÿØŸÖÿ©**\n\n### 9. **‚è±Ô∏è ÿ¨ÿØŸàŸÑÿ© ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑÿßÿ™**\n- ÿ®ÿ±ŸÖÿ¨ÿ© ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ ŸÅŸä ÿ£ŸàŸÇÿßÿ™ ŸÖÿ≠ÿØÿØÿ©\n- ÿ™ŸàŸÇŸäÿ™ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ ÿ≠ÿ≥ÿ® ÿ≥ÿ±ÿπÿ© ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™\n- ÿ™ÿ≠ŸÖŸäŸÑ ÿ™ŸÑŸÇÿßÿ¶Ÿä ÿπŸÜÿØ ÿßÿ™ÿµÿßŸÑ ÿßŸÑŸàÿßŸä ŸÅÿßŸä\n\n### 10. **üìã ŸÇŸàÿßÿ¶ŸÖ ÿßŸÑÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∞ŸÉŸäÿ©**\n- ÿ™ÿ≠ŸÖŸäŸÑ ŸÇŸàÿßÿ¶ŸÖ ÿ™ÿ¥ÿ∫ŸäŸÑ ŸÉÿßŸÖŸÑÿ© ÿ®ŸÜŸÇÿ±ÿ© Ÿàÿßÿ≠ÿØÿ©\n- ÿßÿÆÿ™Ÿäÿßÿ± ŸÅŸäÿØŸäŸàŸáÿßÿ™ ŸÖÿ≠ÿØÿØÿ© ŸÖŸÜ ÿßŸÑŸÇÿßÿ¶ŸÖÿ©\n- ŸÖÿπÿßŸäŸÜÿ© ŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑŸÇÿßÿ¶ŸÖÿ© ŸÇÿ®ŸÑ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ\n\n### 11. **üéØ ŸÅŸÑÿ™ÿ±ÿ© Ÿàÿ®ÿ≠ÿ´ ŸÖÿ™ŸÇÿØŸÖ**\n- ÿ®ÿ≠ÿ´ ŸÅŸä ŸÖÿ≠ŸÅŸàÿ∏ÿßÿ™ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ\n- ŸÅŸÑÿ™ÿ±ÿ© ÿ≠ÿ≥ÿ® ÿßŸÑŸÖŸÜÿµÿ© ÿ£Ÿà ÿßŸÑÿ™ÿßÿ±ŸäÿÆ\n- ÿπŸÑÿßŸÖÿßÿ™ ŸÖÿ±ÿ¨ÿπŸäÿ© ŸÑŸÑŸÅŸäÿØŸäŸàŸáÿßÿ™ ÿßŸÑŸÖŸÅÿ∂ŸÑÿ©\n\n### 12. **üìä ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿ¥ÿÆÿµŸäÿ©**\n- ÿπÿØÿØ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑÿßÿ™ ŸàÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿ∫ÿ±ŸÇ\n- ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ¥Ÿáÿ±Ÿäÿ©\n- ÿ™ÿ±ÿ™Ÿäÿ® ÿßŸÑŸÖŸÜÿµÿßÿ™ ÿßŸÑÿ£ŸÉÿ´ÿ± ÿßÿ≥ÿ™ÿÆÿØÿßŸÖÿßŸã\n\n## üõ°Ô∏è **ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ£ŸÖÿßŸÜ ŸàÿßŸÑÿÆÿµŸàÿµŸäÿ©**\n\n### 13. **üîí ÿ≠ŸÖÿßŸäÿ© ÿßŸÑÿÆÿµŸàÿµŸäÿ©**\n- ÿ≠ÿ∞ŸÅ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÖÿ§ŸÇÿ™ÿ©\n- ÿ™ÿ¥ŸÅŸäÿ± ÿ±Ÿàÿßÿ®ÿ∑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ\n- ÿπÿØŸÖ ÿ≠ŸÅÿ∏ ŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑŸÅŸäÿØŸäŸàŸáÿßÿ™ ÿßŸÑÿ¥ÿÆÿµŸäÿ©\n\n### 14. **‚ö†Ô∏è ÿ™ÿ≠ÿ∞Ÿäÿ±ÿßÿ™ ÿßŸÑÿ£ŸÖÿßŸÜ**\n- ÿ™ÿ≠ÿ∞Ÿäÿ±ÿßÿ™ ŸÑŸÑŸÖÿ≠ÿ™ŸàŸâ ŸÖÿ≠ŸÖŸä ÿßŸÑÿ≠ŸÇŸàŸÇ\n- ÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÑÿ≠ÿØŸàÿØ ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ\n- ÿ™ŸÜÿ®ŸäŸáÿßÿ™ ŸÑŸÑÿ±Ÿàÿßÿ®ÿ∑ ÿßŸÑŸÖÿ¥ÿ®ŸàŸáÿ©\n\n### 15. **üé´ ŸÜÿ∏ÿßŸÖ ÿßŸÑÿµŸÑÿßÿ≠Ÿäÿßÿ™**\n- ŸÖÿ≥ÿ™ŸàŸäÿßÿ™ ŸàÿµŸàŸÑ ŸÖÿÆÿ™ŸÑŸÅÿ© ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ\n- ÿ≠ÿØŸàÿØ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ ÿ≠ÿ≥ÿ® ŸÜŸàÿπ ÿßŸÑÿπÿ∂ŸàŸäÿ©\n- ŸÖŸäÿ≤ÿßÿ™ ÿÆÿßÿµÿ© ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿßŸÑŸÖŸÖŸäÿ≤ŸäŸÜ\n\n## üåü **ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ™ÿÆÿµŸäÿµ ŸàÿßŸÑÿ±ÿßÿ≠ÿ©**\n\n### 16. **üé® ÿ™ÿÆÿµŸäÿµ ÿßŸÑŸàÿßÿ¨Ÿáÿ©**\n- ÿßÿÆÿ™Ÿäÿßÿ± ŸÜŸÖÿ∑ ÿßŸÑÿ£ŸÑŸàÿßŸÜ ŸàÿßŸÑÿ´ŸäŸÖÿßÿ™\n- ÿ™ÿÆÿµŸäÿµ ÿ¥ŸÉŸÑ ÿ¥ÿ±Ÿäÿ∑ ÿßŸÑÿ™ŸÇÿØŸÖ\n- ÿßÿÆÿ™Ÿäÿßÿ± ŸÜŸàÿπ ÿßŸÑÿ£ŸÜŸäŸÖŸäÿ¥ŸÜ ÿßŸÑŸÖŸÅÿ∂ŸÑ\n\n### 17. **üîî ŸÜÿ∏ÿßŸÖ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ÿßŸÑŸÖÿ™ŸÇÿØŸÖ**\n- ÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÅŸàÿ±Ÿäÿ© ÿπŸÜÿØ ÿßŸÉÿ™ŸÖÿßŸÑ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ\n- ÿ™ŸÜÿ®ŸäŸáÿßÿ™ ŸÑŸÅÿ¥ŸÑ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑ ŸÖÿπ ÿßŸÑÿ£ÿ≥ÿ®ÿßÿ®\n- ÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÑŸÑÿ™ÿ≠ÿØŸäÿ´ÿßÿ™ ŸàÿßŸÑŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ©\n\n### 18. **üíæ ÿ•ÿØÿßÿ±ÿ© ÿßŸÑÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑÿ∞ŸÉŸäÿ©**\n- ÿπÿ±ÿ∂ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÖÿ≥ÿßÿ≠ÿ© ÿßŸÑÿ™ÿÆÿ≤ŸäŸÜ\n- ÿ™ŸÜÿ∏ŸäŸÅ ÿ™ŸÑŸÇÿßÿ¶Ÿä ŸÑŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÇÿØŸäŸÖÿ©\n- ÿ∂ÿ∫ÿ∑ ÿßŸÑŸÅŸäÿØŸäŸàŸáÿßÿ™ ŸÑÿ™ŸàŸÅŸäÿ± ÿßŸÑŸÖÿ≥ÿßÿ≠ÿ©\n\n### 19. **üåê ÿØÿπŸÖ ŸÖÿ™ÿπÿØÿØ ÿßŸÑŸÑÿ∫ÿßÿ™**\n- Ÿàÿßÿ¨Ÿáÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸàÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©\n- ÿ±ÿ≥ÿßÿ¶ŸÑ ÿÆÿ∑ÿ£ Ÿàÿßÿ∂ÿ≠ÿ© ÿ®ŸÑÿ∫ÿßÿ™ ŸÖÿ™ÿπÿØÿØÿ©\n- ÿ™ÿÆÿµŸäÿµ ÿßŸÑŸÑÿ∫ÿ© ÿ≠ÿ≥ÿ® ÿ™ŸÅÿ∂ŸäŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ\n\n### 20. **üé™ ŸÖŸÖŸäÿ≤ÿßÿ™ ÿ™ÿ±ŸÅŸäŸáŸäÿ©**\n- ÿ±ÿ≥ÿßÿ¶ŸÑ ÿßÿ≠ÿ™ŸÅÿßŸÑŸäÿ© ÿπŸÜÿØ ÿ•ŸÜÿ¨ÿßÿ≤ ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑÿßÿ™\n- ÿ™ÿ≠ÿØŸäÿßÿ™ ŸäŸàŸÖŸäÿ© ŸÑŸÑÿ™ÿ≠ŸÖŸäŸÑ\n- ŸÜÿ∏ÿßŸÖ ŸÜŸÇÿßÿ∑ ŸàŸÖŸÉÿßŸÅÿ¢ÿ™ ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ÿßŸÑŸÜÿ¥ÿ∑ŸäŸÜ\n\n---\n\n## üöÄ **ÿßŸÑŸÖŸäÿ≤ÿßÿ™ ÿßŸÑŸÖÿ∑ÿ®ŸÇÿ© ÿ≠ÿßŸÑŸäÿßŸã:**\n\n‚úÖ **ÿ¥ÿ±Ÿäÿ∑ ÿ™ŸÇÿØŸÖ ŸÖÿ™ÿ≠ÿ±ŸÉ ŸÖÿπ ÿ£ŸÜŸäŸÖŸäÿ¥ŸÜ ŸÖŸÑŸàŸÜ**\n‚úÖ **ÿ±ÿ≥ÿßÿ¶ŸÑ ÿ™ŸÅÿßÿπŸÑŸäÿ© ŸÖÿπ ÿ±ŸÖŸàÿ≤ ÿ™ÿπÿ®Ÿäÿ±Ÿäÿ© ŸÖÿ™ÿ≠ÿ±ŸÉÿ©**\n‚úÖ **Ÿàÿßÿ¨Ÿáÿ© ÿπÿ±ÿ®Ÿäÿ© ÿ¨ŸÖŸäŸÑÿ© Ÿàÿ≥ŸáŸÑÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ**\n‚úÖ **ŸÖÿπÿßŸäŸÜÿ© ÿßŸÑŸÅŸäÿØŸäŸà ŸÖÿπ ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑÿ¨ŸàÿØÿ©**\n‚úÖ **ÿØÿπŸÖ ÿ£ŸÉÿ´ÿ± ŸÖŸÜ 1500 ŸÖŸÜÿµÿ©**\n‚úÖ **ÿ™ÿ≠ŸÖŸäŸÑ ŸÖŸÑŸÅÿßÿ™ ÿ™ÿµŸÑ ÿ•ŸÑŸâ 2GB**\n‚úÖ **ŸÜÿ∏ÿßŸÖ ÿ™ÿÆÿ≤ŸäŸÜ ŸÖÿ§ŸÇÿ™ ÿ∞ŸÉŸä**\n‚úÖ **ÿ±ÿ≥ÿßÿ¶ŸÑ ÿÆÿ∑ÿ£ ŸÖŸÅŸäÿØÿ© ŸÖÿπ ÿ≠ŸÑŸàŸÑ**\n\n---\n\n## üéØ **ÿßŸÑÿÆÿ∑ÿ© ÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑŸäÿ©:**\n\nüîÑ **ŸÇŸäÿØ ÿßŸÑÿ™ÿ∑ŸàŸäÿ±:**\n- ŸÜÿ∏ÿßŸÖ ŸÇŸàÿßÿ¶ŸÖ ÿßŸÑÿ™ÿ¥ÿ∫ŸäŸÑ\n- ÿ¨ÿØŸàŸÑÿ© ÿßŸÑÿ™ÿ≠ŸÖŸäŸÑÿßÿ™\n- ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿ¥ÿÆÿµŸäÿ© ŸÖÿ™ŸÇÿØŸÖÿ©\n\nüìã **ŸÖÿÆÿ∑ÿ∑ ŸÑŸáÿß:**\n- ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ¨ŸàÿßŸÑ ÿßŸÑŸÖÿ±ÿßŸÅŸÇ\n- API ŸÑŸÑŸÖÿ∑Ÿàÿ±ŸäŸÜ\n- ÿ∞ŸÉÿßÿ° ÿßÿµÿ∑ŸÜÿßÿπŸä ŸÑÿßŸÇÿ™ÿ±ÿßÿ≠ ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ\n\n---\n\n*ÿ™ŸÖ ÿ™ÿ∑ŸàŸäÿ± Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÖŸäÿ≤ÿßÿ™ ŸÑÿ™ŸàŸÅŸäÿ± ÿ£ŸÅÿ∂ŸÑ ÿ™ÿ¨ÿ±ÿ®ÿ© ŸÖŸÖŸÉŸÜÿ© ŸÑŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸäŸÜ ŸÖÿπ ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿßŸÑÿ≥ÿ±ÿπÿ© ŸàÿßŸÑŸÖŸàÿ´ŸàŸÇŸäÿ©* üåü","size_bytes":5920},"utils/progress_animations.py":{"content":"\"\"\"\nEnhanced progress animations and interactive messages\nBeautiful progress bars with animations and dynamic content\n\"\"\"\n\nimport time\nimport asyncio\nfrom typing import Dict, List, Optional\nfrom static.icons import Icons\n\nclass ProgressAnimator:\n    \"\"\"Advanced progress animations with beautiful effects\"\"\"\n    \n    def __init__(self):\n        self.animation_states: Dict[str, int] = {}\n        self.last_update: Dict[str, float] = {}\n        \n    def get_animated_progress_bar(self, percentage: float, task_id: str = \"\", style: str = \"default\") -> str:\n        \"\"\"Create beautiful animated progress bar\"\"\"\n        current_time = time.time()\n        \n        # Update animation frame\n        if task_id not in self.animation_states:\n            self.animation_states[task_id] = 0\n        if task_id not in self.last_update:\n            self.last_update[task_id] = current_time\n            \n        # Update every 0.5 seconds for smooth animation\n        if current_time - self.last_update[task_id] > 0.5:\n            self.animation_states[task_id] = (self.animation_states[task_id] + 1) % 10\n            self.last_update[task_id] = current_time\n            \n        frame = self.animation_states[task_id]\n        \n        if style == \"rainbow\":\n            return self._create_rainbow_progress(percentage, frame)\n        elif style == \"fire\":\n            return self._create_fire_progress(percentage, frame)\n        elif style == \"pulse\":\n            return self._create_pulse_progress(percentage, frame)\n        else:\n            return self._create_default_progress(percentage, frame)\n    \n    def _create_default_progress(self, percentage: float, frame: int) -> str:\n        \"\"\"Ultra-modern animated progress bar with smooth movement\"\"\"\n        length = 25\n        filled = int(percentage / 100 * length)\n        \n        # Advanced animation characters with smooth movement\n        moving_chars = ['‚ñ∞', '‚ñ±', '‚ñ≤', '‚ñ∫', '‚óè', '‚óÜ', '‚òÖ', '‚ö°']\n        glow_chars = ['‚ú®', 'üí´', '‚≠ê', 'üåü', 'üíé', 'üî•', '‚ö°', 'üöÄ']\n        \n        # Moving animation character\n        moving_char = moving_chars[frame % len(moving_chars)]\n        glow_char = glow_chars[frame % len(glow_chars)]\n        \n        if percentage >= 100:\n            # Celebration animation for completion\n            celebration = ['üéâ', 'üéä', '‚ú®', 'üèÜ', 'üéØ', 'üíØ'][frame % 6]\n            full_bar = ''.join(['‚ñà'] * length)\n            return f\"‚ï≠{'‚îÄ' * (length + 2)}‚ïÆ\\n‚îÇ {full_bar} ‚îÇ {celebration} 100%\\n‚ï∞{'‚îÄ' * (length + 2)}‚ïØ\"\n        \n        elif filled > 0:\n            # Create smooth animated progress with glow effect\n            if filled >= length:\n                filled = length - 1\n            \n            # Add glow effect around the moving character\n            bar_parts = []\n            for i in range(length):\n                if i < filled - 1:\n                    bar_parts.append('‚ñà')\n                elif i == filled - 1:\n                    # Moving character with glow\n                    bar_parts.append(moving_char)\n                elif i == filled and frame % 3 == 0:\n                    # Occasional glow ahead\n                    bar_parts.append(glow_char)\n                else:\n                    bar_parts.append('‚ñë')\n            \n            bar = ''.join(bar_parts)\n        else:\n            # Starting animation\n            bar = moving_char + '‚ñë' * (length - 1)\n        \n        # Create beautiful bordered progress bar\n        progress_text = f\"‚ï≠{'‚îÄ' * (length + 2)}‚ïÆ\\n‚îÇ {bar} ‚îÇ {glow_char} {percentage:.1f}%\\n‚ï∞{'‚îÄ' * (length + 2)}‚ïØ\"\n        \n        return progress_text\n    \n    def _create_rainbow_progress(self, percentage: float, frame: int) -> str:\n        \"\"\"Ultra-vibrant rainbow progress bar with flowing colors\"\"\"\n        length = 25\n        filled = int(percentage / 100 * length)\n        \n        # Rainbow colors that flow and change\n        rainbow_sequence = ['üî¥', 'üü†', 'üü°', 'üü¢', 'üîµ', 'üü£', 'üü§', '‚ö´', '‚ö™']\n        rainbow_effects = ['üåà', 'üí´', '‚ú®', 'üé®', 'üé™', 'üé≠', 'üéä', 'üéâ']\n        \n        if percentage >= 100:\n            # Epic rainbow completion\n            rainbow_bar = ''.join(rainbow_sequence[i % len(rainbow_sequence)] for i in range(8))\n            celebration = rainbow_effects[frame % len(rainbow_effects)]\n            return f\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë {rainbow_bar} ‚ïë {celebration} 100%\n‚ïë    üåà RAINBOW COMPLETE! üåà    ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\"\"\"\n        \n        # Create flowing rainbow effect\n        rainbow_char = rainbow_sequence[(frame + filled) % len(rainbow_sequence)]\n        effect_char = rainbow_effects[frame % len(rainbow_effects)]\n        \n        if filled > 0:\n            # Create gradient rainbow bar\n            bar_parts = []\n            for i in range(length):\n                if i < filled - 1:\n                    bar_parts.append(rainbow_sequence[i % len(rainbow_sequence)])\n                elif i == filled - 1:\n                    bar_parts.append(rainbow_char)\n                else:\n                    bar_parts.append('‚ñë')\n            bar = ''.join(bar_parts)\n        else:\n            bar = rainbow_char + '‚ñë' * (length - 1)\n        \n        return f\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë {bar} ‚ïë {effect_char} {percentage:.1f}%\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\"\"\"\n    \n    def _create_fire_progress(self, percentage: float, frame: int) -> str:\n        \"\"\"Fire themed progress bar\"\"\"\n        length = 20\n        filled = int(percentage / 100 * length)\n        \n        fire_char = Icons.FIRE_FRAMES[frame % len(Icons.FIRE_FRAMES)]\n        \n        if percentage >= 100:\n            return f\"[{'üî•' * 6}] {Icons.ROCKET} 100%\"\n        elif filled > 0:\n            bar = '‚ñà' * (filled - 1) + fire_char + '‚ñë' * (length - filled)\n        else:\n            bar = fire_char + '‚ñë' * (length - 1)\n            \n        return f\"[{bar}] {fire_char} {percentage:.1f}%\"\n    \n    def _create_pulse_progress(self, percentage: float, frame: int) -> str:\n        \"\"\"Pulsing stars progress bar\"\"\"\n        length = 20\n        filled = int(percentage / 100 * length)\n        \n        pulse_char = Icons.PULSE_FRAMES[frame % len(Icons.PULSE_FRAMES)]\n        \n        if percentage >= 100:\n            return f\"[{'‚≠ê' * 6}] {Icons.MAGIC} 100%\"\n        elif filled > 0:\n            bar = '‚ñà' * (filled - 1) + pulse_char + '‚ñë' * (length - filled)\n        else:\n            bar = pulse_char + '‚ñë' * (length - 1)\n            \n        return f\"[{bar}] {pulse_char} {percentage:.1f}%\"\n\nclass InteractiveMessages:\n    \"\"\"Beautiful interactive messages with animations\"\"\"\n    \n    @staticmethod\n    def get_welcome_message(username: str = \"\") -> str:\n        \"\"\"Ultra-modern animated welcome message\"\"\"\n        user_part = f\" {username}\" if username else \"\"\n        frame_time = int(time.time() * 2) % 4\n        \n        # Animated title with changing effects\n        title_effects = ['üöÄ', '‚ö°', 'üî•', 'üí´']\n        current_effect = title_effects[frame_time]\n        \n        return f\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë  {current_effect} <b>WELCOME{user_part}!</b> {current_effect}\n‚ïë                                      ‚ïë\n‚ïë   üé¨ <b>ULTRA VIDEO DOWNLOADER BOT</b>   ‚ïë\n‚ïë         üíé <i>Premium Experience</i> üíé        ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nüåü <b>SUPPORTED PLATFORMS:</b>\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ üì∫ YouTube        ‚îÇ üì∏ Instagram     ‚îÇ\n‚îÇ üéµ TikTok         ‚îÇ üìò Facebook      ‚îÇ\n‚îÇ üê¶ Twitter/X      ‚îÇ üåê 1500+ Sites   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n‚ö° <b>ULTRA FEATURES:</b>\n‚ñ™Ô∏è Lightning-fast downloads up to 2GB\n‚ñ™Ô∏è 4K/HD quality with multiple formats\n‚ñ™Ô∏è Batch processing & queue management\n‚ñ™Ô∏è Real-time progress with animations\n‚ñ™Ô∏è Smart compression & optimization\n‚ñ™Ô∏è Instagram cookies & private access\n\nüéØ <b>READY TO START?</b>\nJust send any video link and watch the magic happen!\n\n‚ú® <i>Experience the future of video downloading...</i> ‚ú®\n        \"\"\"\n    \n    @staticmethod\n    def get_processing_message(platform: str, animated_progress: str) -> str:\n        \"\"\"Animated processing message\"\"\"\n        platform_icon = {\n            'youtube': Icons.YOUTUBE,\n            'instagram': Icons.INSTAGRAM,\n            'facebook': Icons.FACEBOOK,\n            'tiktok': Icons.TIKTOK,\n            'twitter': Icons.TWITTER\n        }.get(platform, Icons.VIDEO)\n        \n        return f\"\"\"\n{Icons.PROCESSING} <b>Processing...</b>\n\n{platform_icon} <b>Platform:</b> {platform.title()}\n{Icons.LIGHTNING} <b>Status:</b> Extracting video information\n\n{animated_progress}\n\n{Icons.MAGIC} <i>Preparing high-quality video for you...</i>\n        \"\"\"\n    \n    @staticmethod\n    def get_download_message(video_title: str, progress_bar: str, speed: str, eta: str, \n                           percentage: float = 0, current_size: str = \"\", total_size: str = \"\",\n                           instant_speed: str = \"\", speed_trend: str = \"stable\") -> str:\n        \"\"\"Ultra-modern real-time animated download progress message\"\"\"\n        frame = int(time.time() * 4) % 8  # Faster animation\n        \n        # Dynamic downloading animation based on real percentage\n        download_states = [\n            \"‚¨áÔ∏è INITIALIZING\", \"üì° CONNECTING\", \"üîÑ BUFFERING\", \"üì• DOWNLOADING\",\n            \"‚ö° ACCELERATING\", \"üöÄ TURBO MODE\", \"üí® ULTRA SPEED\", \"üî• MAX POWER\"\n        ]\n        \n        # Status based on real-time percentage\n        if percentage < 5:\n            status = download_states[0]\n        elif percentage < 15:\n            status = download_states[1]\n        elif percentage < 30:\n            status = download_states[2]\n        elif percentage < 50:\n            status = download_states[3]\n        elif percentage < 70:\n            status = download_states[4]\n        elif percentage < 85:\n            status = download_states[5]\n        elif percentage < 95:\n            status = download_states[6]\n        else:\n            status = download_states[7]\n        \n        # Real-time speed indicators with trend\n        speed_indicators = {\n            'increasing': ['üìà', 'üöÄ', '‚ö°', 'üí´'],\n            'decreasing': ['üìâ', 'üêå', '‚è≥', 'üò¥'],\n            'stable': ['üìä', '‚ö°', 'üîÑ', 'üí®'],\n            'unknown': ['‚ùì', 'üîç', 'üìä', '‚ö°']\n        }\n        \n        current_indicators = speed_indicators.get(speed_trend, speed_indicators['stable'])\n        speed_icon = current_indicators[frame % len(current_indicators)]\n        \n        # Progress percentage with visual feedback\n        progress_visual = \"‚ñ∞\" * int(percentage / 5) + \"‚ñ±\" * (20 - int(percentage / 5))\n        \n        # Real-time counters\n        size_info = f\"({current_size}/{total_size})\" if current_size and total_size else \"\"\n        instant_info = f\"üì∂ <b>NOW:</b> {instant_speed}\" if instant_speed else \"\"\n        \n        return f\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë                  {status}                  ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë                                                 ‚ïë\n‚ïë üé¨ <b>VIDEO:</b> {video_title[:40]}{'...' if len(video_title) > 40 else ''}\n‚ïë                                                 ‚ïë\n‚ïë {progress_bar}\n‚ïë üìè {progress_visual} {percentage:.1f}%\n‚ïë                                                 ‚ïë\n‚ïë {speed_icon} <b>AVG SPEED:</b> {speed}\n‚ïë {instant_info}\n‚ïë ‚è±Ô∏è <b>TIME LEFT:</b> {eta}\n‚ïë üìä <b>SIZE:</b> {size_info}\n‚ïë üìà <b>TREND:</b> {speed_trend.title()}\n‚ïë                                                 ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nüí° <i>Real-time optimization in progress...</i>\n‚ö° <i>Ultra-fast parallel downloading active...</i>\nüéØ <i>ETA calculated using smart algorithms...</i>\n        \"\"\"\n    \n    @staticmethod\n    def get_upload_message(video_title: str, progress_bar: str, speed: str, \n                         percentage: float = 0, current_size: str = \"\", total_size: str = \"\",\n                         eta: str = \"\", instant_speed: str = \"\", speed_trend: str = \"stable\") -> str:\n        \"\"\"Ultra-modern real-time animated upload progress message\"\"\"\n        frame = int(time.time() * 4) % 8  # Faster animation for uploads\n        \n        # Dynamic upload states based on real percentage\n        upload_states = [\n            \"üì§ PREPARING\", \"üîó CONNECTING\", \"üì° HANDSHAKE\", \"üì§ UPLOADING\",\n            \"üöÄ ACCELERATING\", \"‚ö° TURBO UPLOAD\", \"üí® BLAZING FAST\", \"üî• MAXIMUM SPEED\"\n        ]\n        \n        # Real-time status\n        if percentage < 5:\n            status = upload_states[0]\n        elif percentage < 15:\n            status = upload_states[1]\n        elif percentage < 25:\n            status = upload_states[2]\n        elif percentage < 50:\n            status = upload_states[3]\n        elif percentage < 70:\n            status = upload_states[4]\n        elif percentage < 85:\n            status = upload_states[5]\n        elif percentage < 95:\n            status = upload_states[6]\n        else:\n            status = upload_states[7]\n        \n        # Upload-specific animations\n        upload_indicators = {\n            'increasing': ['üöÄ', 'üìà', '‚ö°', 'üí´'],\n            'decreasing': ['üêå', 'üìâ', '‚è≥', 'üòÖ'],\n            'stable': ['üì§', 'üí®', 'üîÑ', '‚ö°'],\n            'unknown': ['‚ùì', 'üì°', 'üîç', 'üì§']\n        }\n        \n        current_indicators = upload_indicators.get(speed_trend, upload_indicators['stable'])\n        upload_icon = current_indicators[frame % len(current_indicators)]\n        \n        # Progress visualization for uploads\n        upload_visual = \"üü¶\" * int(percentage / 5) + \"‚¨ú\" * (20 - int(percentage / 5))\n        \n        # Size and time info\n        size_info = f\"({current_size}/{total_size})\" if current_size and total_size else \"\"\n        instant_info = f\"üì∂ <b>NOW:</b> {instant_speed}\" if instant_speed else \"\"\n        eta_info = f\"‚è±Ô∏è <b>TIME LEFT:</b> {eta}\" if eta else \"\"\n        \n        return f\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë                  {status}                  ‚ïë\n‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n‚ïë                                                 ‚ïë\n‚ïë üé¨ <b>VIDEO:</b> {video_title[:40]}{'...' if len(video_title) > 40 else ''}\n‚ïë                                                 ‚ïë\n‚ïë {progress_bar}\n‚ïë üì§ {upload_visual} {percentage:.1f}%\n‚ïë                                                 ‚ïë\n‚ïë {upload_icon} <b>AVG SPEED:</b> {speed}\n‚ïë {instant_info}\n‚ïë {eta_info}\n‚ïë üìä <b>SIZE:</b> {size_info}\n‚ïë üìà <b>TREND:</b> {speed_trend.title()}\n‚ïë                                                 ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nüöÄ <i>Ultra-fast Telethon upload technology...</i>\n‚ö° <i>Optimized chunking for maximum speed...</i>\nüéØ <i>Smart ETA calculation in real-time...</i>\n        \"\"\"\n    \n    @staticmethod\n    def get_success_message(video_title: str, file_size: str, total_time: str, avg_speed: str = \"\") -> str:\n        \"\"\"Epic animated success message with celebration\"\"\"\n        frame = int(time.time() * 2) % 6\n        \n        # Celebration animations\n        celebrations = ['üéâ', 'üéä', '‚ú®', 'üèÜ', 'üéØ', 'üíØ']\n        party_effects = ['ü•≥', 'üéà', 'üéÅ', 'üåü', 'üí´', 'üî•']\n        \n        celebration = celebrations[frame]\n        party = party_effects[frame]\n        \n        return f\"\"\"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n‚ïë          {celebration} SUCCESS! {celebration}          ‚ïë\n‚ïë                                           ‚ïë\n‚ïë      üèÜ DOWNLOAD COMPLETED! üèÜ      ‚ïë\n‚ïë           {party} PERFECT! {party}           ‚ïë\n‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nüìã <b>DOWNLOAD SUMMARY:</b>\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ üé¨ <b>Video:</b> {video_title[:30]}{'...' if len(video_title) > 30 else ''}\n‚îÇ üìÅ <b>Size:</b> {file_size}\n‚îÇ ‚è±Ô∏è <b>Time:</b> {total_time}\n{'‚îÇ ‚ö° <b>Speed:</b> ' + avg_speed if avg_speed else ''}\n‚îÇ ‚úÖ <b>Status:</b> Ready to Watch!\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nüéØ <b>WHAT'S NEXT?</b>\n‚ñ´Ô∏è Your video is ready in the chat above\n‚ñ´Ô∏è High quality and optimized for viewing\n‚ñ´Ô∏è Send another link for more downloads\n\nüåü <b>RATE YOUR EXPERIENCE:</b>\nDid we exceed your expectations? Share feedback!\n\nüöÄ <i>Thanks for choosing Ultra Video Downloader!</i>\nüí´ <i>Send another link to continue the magic...</i>\n        \"\"\"\n    \n    @staticmethod\n    def get_error_message(error_type: str, suggestion: str = \"\") -> str:\n        \"\"\"Animated error message with helpful suggestions\"\"\"\n        return f\"\"\"\n{Icons.ERROR} <b>Download Error Occurred</b>\n\n{Icons.WARNING} <b>Error Type:</b> {error_type}\n\n{Icons.INFO} <b>Suggested Solutions:</b>\n‚Ä¢ {Icons.REFRESH} Try again\n‚Ä¢ {Icons.CHECK} Make sure the link is correct\n‚Ä¢ {Icons.NETWORK} Check internet connection\n\n{suggestion}\n\n{Icons.HEART} <b>We're here to help!</b>\n        \"\"\"\n\n# Global animator instance\nprogress_animator = ProgressAnimator()","size_bytes":18755},"utils/cache_helpers.py":{"content":"\n\"\"\"\nCache helpers for faster bot operations\n\"\"\"\nimport time\nfrom typing import Any, Optional, Callable\nfrom functools import wraps\n\ndef cache_result(cache_manager, key: str, ttl: int = 300):\n    \"\"\"Decorator to cache function results\"\"\"\n    def decorator(func: Callable):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            # Try to get from cache first\n            cached_result = await cache_manager.get(key)\n            if cached_result is not None:\n                return cached_result\n            \n            # Execute function and cache result\n            result = await func(*args, **kwargs)\n            await cache_manager.set(key, result, expire=ttl)\n            return result\n        return wrapper\n    return decorator\n\nasync def quick_user_check(cache_manager, user_id: int) -> Optional[bool]:\n    \"\"\"Quick user authorization check from cache\"\"\"\n    cache_key = f\"quick_auth:{user_id}\"\n    return await cache_manager.get(cache_key)\n\nasync def set_quick_user_check(cache_manager, user_id: int, allowed: bool):\n    \"\"\"Set quick user authorization in cache\"\"\"\n    cache_key = f\"quick_auth:{user_id}\"\n    await cache_manager.set(cache_key, allowed, expire=300)  # 5 minutes\n\nasync def is_rate_limited(cache_manager, user_id: int) -> bool:\n    \"\"\"Quick rate limit check\"\"\"\n    rate_key = f\"rate_quick:{user_id}\"\n    last_request = await cache_manager.get(rate_key)\n    \n    if last_request:\n        time_diff = time.time() - float(last_request)\n        return time_diff < 0.5  # 500ms minimum between requests\n    \n    # Update last request time\n    await cache_manager.set(rate_key, str(time.time()), expire=60)\n    return False\n","size_bytes":1664}},"version":1}